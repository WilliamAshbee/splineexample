{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "examplespline-computationgraphworking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPisN5J3SF1lXRQFnU9rrqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/examplespline_computationgraphworking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GHlCQWuYHikr",
        "outputId": "cb6f5faf-06c5-43a9-a7a9-5de9124ffe25"
      },
      "source": [
        "import matplotlib.pylab as P\r\n",
        "import torch as T\r\n",
        "\r\n",
        "def h_poly_helper(tt):\r\n",
        "  A = T.tensor([\r\n",
        "      [1, 0, -3, 2],\r\n",
        "      [0, 1, -2, 1],\r\n",
        "      [0, 0, 3, -2],\r\n",
        "      [0, 0, -1, 1]\r\n",
        "      ], dtype=tt[-1].dtype)\r\n",
        "  return [\r\n",
        "    sum( A[i, j]*tt[j] for j in range(4) )\r\n",
        "    for i in range(4) ]\r\n",
        "\r\n",
        "def h_poly(t):\r\n",
        "  tt = [ None for _ in range(4) ]\r\n",
        "  tt[0] = 1\r\n",
        "  for i in range(1, 4):\r\n",
        "    tt[i] = tt[i-1]*t\r\n",
        "  return h_poly_helper(tt)\r\n",
        "\r\n",
        "def H_poly(t):\r\n",
        "  tt = [ None for _ in range(4) ]\r\n",
        "  tt[0] = t\r\n",
        "  for i in range(1, 4):\r\n",
        "    tt[i] = tt[i-1]*t*i/(i+1)\r\n",
        "  return h_poly_helper(tt)\r\n",
        "\r\n",
        "def interp(x, y, xs):\r\n",
        "  m = (y[1:] - y[:-1])/(x[1:] - x[:-1])\r\n",
        "  m = T.cat([m[[0]], (m[1:] + m[:-1])/2, m[[-1]]])\r\n",
        "  I = P.searchsorted(x[1:], xs)\r\n",
        "  dx = (x[I+1]-x[I])\r\n",
        "  hh = h_poly((xs-x[I])/dx)\r\n",
        "  return hh[0]*y[I] + hh[1]*m[I]*dx + hh[2]*y[I+1] + hh[3]*m[I+1]*dx\r\n",
        "\r\n",
        "def integ(x, y, xs):\r\n",
        "  m = (y[1:] - y[:-1])/(x[1:] - x[:-1])\r\n",
        "  m = T.cat([m[[0]], (m[1:] + m[:-1])/2, m[[-1]]])\r\n",
        "  I = P.searchsorted(x[1:], xs)\r\n",
        "  Y = T.zeros_like(y)\r\n",
        "  Y[1:] = (x[1:]-x[:-1])*(\r\n",
        "      (y[:-1]+y[1:])/2 + (m[:-1] - m[1:])*(x[1:]-x[:-1])/12\r\n",
        "      )\r\n",
        "  Y = Y.cumsum(0)\r\n",
        "  dx = (x[I+1]-x[I])\r\n",
        "  hh = H_poly((xs-x[I])/dx)\r\n",
        "  return Y[I] + dx*(\r\n",
        "      hh[0]*y[I] + hh[1]*m[I]*dx + hh[2]*y[I+1] + hh[3]*m[I+1]*dx\r\n",
        "      )\r\n",
        "\r\n",
        "# Example\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  x = T.linspace(0, 6, 7)\r\n",
        "  y = x.sin()\r\n",
        "  xs = T.linspace(0, 6, 101)\r\n",
        "  ys = interp(x, y, xs)\r\n",
        "  Ys = integ(x, y, xs)\r\n",
        "  P.scatter(x, y, label='Samples', color='purple')\r\n",
        "  P.plot(xs, ys, label='Interpolated curve')\r\n",
        "  P.plot(xs, xs.sin(), '--', label='True Curve')\r\n",
        "  P.plot(xs, Ys, label='Spline Integral')\r\n",
        "  P.plot(xs, 1-xs.cos(), '--', label='True Integral')\r\n",
        "  P.legend()\r\n",
        "  P.show()\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNJo4aGCHkT_"
      },
      "source": [
        "x = T.linspace(0,6,7)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ZTEzjWHzu7"
      },
      "source": [
        "y = x.sin()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6JlgC1qH3vm"
      },
      "source": [
        "xs = T.linspace(0, 6, 101)\r\n",
        "ys = interp(x, y, xs)\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W51vGAJQIyhr"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "class MLP(nn.Module):\r\n",
        "    def __init__(self,outclass = 101):\r\n",
        "        super(MLP, self).__init__()\r\n",
        "        self.layers = nn.Sequential(\r\n",
        "            nn.Linear(101, 100),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(100, 100),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(100, 100),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(100, outclass),\r\n",
        "            nn.Tanh()\r\n",
        "        )\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        # convert tensor (128, 1, 28, 28) --> (128, 1*28*28)\r\n",
        "        x = x.view(x.size(0), -1)\r\n",
        "        x = self.layers(x)\r\n",
        "        return x\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfHWObP3WSuF"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yFODT_oQBSs"
      },
      "source": [
        "#print(xs.shape)\r\n",
        "#a = torch.zeros(2,101)\r\n",
        "#model(a).shape"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iC3zZC_P7uB"
      },
      "source": [
        "model = MLP()\r\n",
        "learning_rate = .0001\r\n",
        "optimizer = T.optim.Adam(model.parameters(), lr=learning_rate)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUkloF2mTz6Z",
        "outputId": "eee2d574-d5f1-4d40-80d8-848e1e8bd6a3"
      },
      "source": [
        "for i in range(1000):\r\n",
        "  output = model(xs.unsqueeze(0))\r\n",
        "  loss = T.mean(T.abs(output-ys))\r\n",
        "  print('loss',loss)\r\n",
        "  loss.backward()\r\n",
        "  optimizer.step()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss tensor(0.6639, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6603, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6570, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6536, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6503, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6470, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6439, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6408, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6377, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6347, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6318, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6291, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6266, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6243, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6221, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6198, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6174, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6151, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6126, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6101, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6077, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6054, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6030, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.6005, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5979, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5952, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5926, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5898, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5869, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5838, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5807, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5774, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5740, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5704, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5667, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5628, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5588, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5546, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5503, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5459, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5417, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5377, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5335, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5292, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5248, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5203, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5155, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5105, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5054, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4949, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4897, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4844, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4791, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4736, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4677, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4616, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4554, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4493, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4432, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4372, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4310, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4247, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4184, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4119, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.4053, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3986, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3921, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3854, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3789, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3725, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3661, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3598, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3537, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3474, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3409, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3343, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3279, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3215, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3159, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3107, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3056, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.3012, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2978, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2947, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2919, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2890, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2862, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2833, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2805, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2775, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2748, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2720, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2690, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2661, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2635, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2608, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2578, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2547, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2514, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2484, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2455, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2429, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2402, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2372, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2344, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2315, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2283, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2235, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2222, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2206, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2188, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2172, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2161, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2154, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2151, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2156, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2160, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2163, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2167, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2176, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2182, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2191, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2202, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2211, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2218, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2226, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2240, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2263, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2275, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2289, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2301, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2312, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2321, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2328, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2338, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2355, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2372, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2386, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2404, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2419, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2437, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2453, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2468, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2481, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2492, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2506, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2517, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2530, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2548, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2564, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2581, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2599, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2614, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2626, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2636, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2646, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2657, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2671, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2684, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2694, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2702, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2709, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2714, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2715, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2717, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2718, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2716, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2709, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2708, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2707, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2702, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2694, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2683, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2667, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2648, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2626, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2599, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2572, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2554, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2533, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2509, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2480, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2452, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2426, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2404, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2387, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2378, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2383, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2390, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2418, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2450, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2478, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2504, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2525, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2552, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2583, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2612, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2637, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2658, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2676, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2699, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2723, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2742, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2761, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2780, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2796, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2809, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2818, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2827, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2836, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2842, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2846, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2847, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2850, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2855, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2858, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2859, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2864, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2866, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2865, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2862, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2862, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2868, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2879, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2888, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2902, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2914, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2924, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2932, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2937, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2940, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2941, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2940, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2936, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2935, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2935, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2933, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2933, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2939, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2945, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2949, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2951, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2952, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2951, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2948, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2943, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2936, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2928, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2917, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2905, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2890, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2874, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2857, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2838, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2821, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2802, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2782, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2762, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2743, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2723, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2701, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2682, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2664, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2652, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2639, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2635, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2634, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2634, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2636, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2636, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2639, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2639, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2639, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2637, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2633, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2633, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2634, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2635, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2633, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2630, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2630, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2629, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2626, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2620, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2614, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2605, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2594, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2582, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2567, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2552, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2534, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2495, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2476, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2459, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2441, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2425, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2411, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2402, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2394, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2387, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2380, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2375, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2369, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2362, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2353, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2344, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2333, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2326, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2320, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2314, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2309, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2304, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2298, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2291, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2282, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2272, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2263, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2242, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2230, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2216, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2201, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2187, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2171, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2155, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2137, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2117, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2096, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2073, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2049, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.2024, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1997, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1969, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1941, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1912, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1882, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1850, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1817, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1784, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1752, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1718, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1682, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1647, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1613, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1580, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1550, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1522, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1495, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1469, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1442, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1417, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1394, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1372, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1351, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1332, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1312, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1291, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1273, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1258, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1245, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1234, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1226, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1219, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1215, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1212, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1213, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1220, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1231, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1248, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1266, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1288, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1316, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1345, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1375, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1408, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1442, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1476, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1508, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1537, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1566, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1595, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1624, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1653, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1677, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1698, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1718, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1734, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1748, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1760, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1769, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1775, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1780, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1781, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1780, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1776, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1770, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1761, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1750, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1737, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1720, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1701, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1679, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1654, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1628, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1598, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1567, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1533, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1498, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1464, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1429, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1394, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1360, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1328, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1295, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1262, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1230, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1197, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1164, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1132, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1100, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1073, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1048, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1023, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1000, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0979, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0960, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0943, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0928, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0919, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0919, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0923, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0927, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0932, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0942, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0956, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0973, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0990, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1013, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1036, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1060, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1087, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1113, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1141, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1168, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1195, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1221, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1246, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1271, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1295, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1318, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1340, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1361, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1381, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1400, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1417, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1434, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1450, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1467, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1482, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1496, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1510, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1523, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1536, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1547, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1558, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1567, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1575, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1583, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1589, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1594, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1599, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1602, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1605, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1606, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1607, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1608, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1607, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1607, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1605, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1603, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1600, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1598, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1595, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1590, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1585, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1579, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1574, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1567, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1560, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1551, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1542, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1532, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1521, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1510, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1498, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1486, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1473, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1458, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1443, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1428, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1411, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1393, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1375, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1356, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1337, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1318, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1299, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1278, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1257, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1236, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1216, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1198, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1179, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1159, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1140, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1124, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1108, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1093, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1079, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1066, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1052, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1037, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1022, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1006, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0989, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0973, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0956, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0938, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0923, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0907, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0891, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0875, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0859, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0845, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0832, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0821, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0810, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0800, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0795, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0789, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0784, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0782, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0780, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0780, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0780, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0784, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0790, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0800, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0811, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0827, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0846, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0869, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0894, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0920, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0948, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0982, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1017, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1052, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1087, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1121, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1155, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1189, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1224, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1259, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1293, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1326, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1358, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1390, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1420, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1450, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1478, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1505, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1530, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1555, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1578, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1599, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1617, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1634, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1648, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1659, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1669, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1675, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1679, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1681, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1681, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1678, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1673, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1665, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1655, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1642, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1627, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1609, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1589, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1567, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1544, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1518, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1491, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1463, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1434, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1404, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1372, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1339, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1305, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1270, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1235, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1200, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1164, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1127, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1090, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1054, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1021, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0989, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0960, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0934, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0912, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0892, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0874, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0860, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0849, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0843, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0841, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0842, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0844, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0847, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0854, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0863, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0874, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0888, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0903, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0918, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0936, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0955, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0974, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0994, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1014, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1034, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1054, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1073, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1092, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1111, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1131, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1151, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1171, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1191, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1211, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1231, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1252, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1272, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1291, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1310, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1327, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1344, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1360, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1375, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1390, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1403, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1416, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1427, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1440, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1452, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1463, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1474, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1485, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1494, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1503, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1512, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1521, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1530, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1539, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1548, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1556, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1566, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1576, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1586, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1596, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1606, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1616, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1625, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1634, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1642, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1650, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1657, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1665, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1673, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1681, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1689, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1696, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1702, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1708, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1714, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1719, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1724, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1728, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1731, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1735, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1737, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1739, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1741, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1742, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1743, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1743, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1744, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1746, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1748, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1749, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1750, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1751, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1751, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1750, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1749, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1748, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1745, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1743, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1740, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1738, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1735, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1732, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1729, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1725, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1720, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1715, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1710, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1705, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1700, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1695, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1688, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1682, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1676, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1670, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1663, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1656, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1650, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1645, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1641, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1637, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1633, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1628, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1623, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1618, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1612, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1606, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1599, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1593, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1586, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1579, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1572, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1564, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1555, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1546, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1536, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1528, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1520, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1512, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1504, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1498, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1493, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1487, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1481, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1475, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1470, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1466, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1462, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1458, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1453, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1448, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1442, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1436, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1432, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1431, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1433, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1437, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1440, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1444, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1447, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1451, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1455, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1460, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1467, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1476, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1484, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1491, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1498, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1505, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1512, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1517, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1524, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1531, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1539, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1546, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1552, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1560, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1568, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1576, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1584, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1592, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1599, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1608, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1617, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1625, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1633, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1641, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1648, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1654, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1660, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1666, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1671, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1675, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1679, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1683, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1686, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1689, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1694, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1698, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1701, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1704, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1707, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1709, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1710, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1711, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1711, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1711, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1711, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1710, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1710, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1708, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1706, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1704, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1700, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1697, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1693, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1688, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1683, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1678, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1672, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1665, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1658, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1651, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1643, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1635, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1627, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1618, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1609, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1600, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1590, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1580, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1570, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1560, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1551, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1541, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1531, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1520, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1509, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1497, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1486, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1475, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1463, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1451, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1439, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1426, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1414, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1401, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1389, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1376, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1363, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1349, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1335, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1321, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1306, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1292, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1277, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1264, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1250, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1237, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1223, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1209, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1195, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1181, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1167, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1154, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1141, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1129, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1117, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1105, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1093, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1082, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1070, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1058, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1047, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1036, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1026, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1017, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1007, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0998, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0989, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0981, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0973, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0965, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0957, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0949, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0943, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0937, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0931, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0926, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0921, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0916, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0910, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0905, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0901, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0896, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0893, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0889, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0888, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0886, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0885, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0885, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0885, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0886, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0887, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0888, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0891, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0894, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0898, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0903, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0908, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0914, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0920, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0925, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0932, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0939, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0947, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0954, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0961, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0967, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0974, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0980, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0987, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0992, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0998, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1003, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1007, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1011, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1015, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1019, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1021, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1024, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1025, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1026, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1027, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1027, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1026, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1027, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1027, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1026, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1025, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1024, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1022, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1019, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1017, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1014, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1010, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1006, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.1001, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0996, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0990, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0984, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0977, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0970, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0963, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0955, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0947, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0938, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0929, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0920, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0910, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0901, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0891, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0881, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0871, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0861, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0851, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0842, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0832, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0822, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0812, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0802, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0793, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0783, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0773, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0764, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0755, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0746, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0737, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0729, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0721, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0714, grad_fn=<MeanBackward0>)\n",
            "loss tensor(0.0708, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HDQcGe1bW5k-",
        "outputId": "6dda4b5e-63a6-4aef-8bb6-9a0efdc00e4f"
      },
      "source": [
        "x = T.linspace(0, 6, 7)\r\n",
        "y = x.sin()\r\n",
        "xs = T.linspace(0, 6, 101)\r\n",
        "out = model(xs.unsqueeze(0)).squeeze().detach()\r\n",
        "print(xs.shape)\r\n",
        "ys = interp(x, y, xs)\r\n",
        "Ys = integ(x, y, xs)\r\n",
        "P.scatter(x, y, label='Samples', color='purple')\r\n",
        "P.plot(xs, ys, label='Interpolated curve')\r\n",
        "P.plot(xs, out.numpy(), label='Model output')\r\n",
        "P.plot(xs, xs.sin(), '--', label='True Curve')\r\n",
        "P.legend()\r\n",
        "P.show()\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([101])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF88HHftfkt8",
        "outputId": "276e7550-8a18-4ca9-a434-d18a68f6bfe9"
      },
      "source": [
        "oc = 25\r\n",
        "model = MLP(outclass=oc)\r\n",
        "optimizer = T.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
        "x = T.linspace(0, 6, 25)\r\n",
        "y = x.sin()\r\n",
        "modelin = T.linspace(0, 6, 101)\r\n",
        "xs = T.linspace(0, 6, 25)\r\n",
        "xoc = T.linspace(0, 6, oc)\r\n",
        "\r\n",
        "ys = interp(x, y, xs)\r\n",
        "print(xoc.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFyie73Xl2AH",
        "outputId": "5ea8833f-85be-4932-d122-ede86d6a799a"
      },
      "source": [
        "for i in range(1000):\r\n",
        "  output = model(modelin.unsqueeze(0)).squeeze()\r\n",
        "  print(output.shape)\r\n",
        "  yout = interp(xoc,output,xs)\r\n",
        "  loss = T.mean((yout-ys)**2)\r\n",
        "  print('loss',loss)\r\n",
        "  loss.backward()\r\n",
        "  optimizer.step()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25])\n",
            "loss tensor(0.5351, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.5258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.5175, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.5093, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4923, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4771, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4704, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4639, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4573, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4507, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4445, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4384, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4322, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4263, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4203, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4146, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4091, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.4035, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3978, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3919, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3859, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3799, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3737, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3676, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3616, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3555, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3494, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3433, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3370, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3307, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3242, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3177, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3111, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.3043, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2974, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2905, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2835, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2764, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2693, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2621, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2548, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2475, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2402, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2329, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2186, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2115, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2043, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1972, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1901, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1831, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1762, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1693, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1624, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1557, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1490, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1425, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1359, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1295, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1233, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1172, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1113, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1055, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1000, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0946, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0893, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0842, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0794, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0747, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0704, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0663, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0625, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0590, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0558, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0529, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0502, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0479, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0458, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0441, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0426, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0414, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0404, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0398, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0393, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0391, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0390, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0391, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0393, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0396, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0400, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0405, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0410, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0416, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0421, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0427, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0432, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0436, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0440, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0444, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0446, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0448, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0449, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0450, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0451, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0452, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0454, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0455, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0457, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0459, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0462, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0465, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0469, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0473, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0479, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0487, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0495, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0505, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0517, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0531, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0546, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0563, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0582, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0602, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0623, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0646, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0670, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0694, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0718, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0743, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0766, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0789, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0810, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0830, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0847, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0862, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0874, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0884, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0890, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0892, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0890, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0886, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0877, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0866, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0852, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0836, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0818, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0798, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0778, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0757, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0736, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0715, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0696, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0678, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0664, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0654, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0647, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0644, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0647, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0655, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0670, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0690, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0716, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0747, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0784, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0826, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0871, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0920, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.0971, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1023, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1075, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1126, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1176, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1224, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1269, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1310, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1348, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1383, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1414, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1442, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1468, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1491, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1511, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1530, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1547, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1562, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1577, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1589, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1601, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1611, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1620, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1627, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1634, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1638, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1641, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1642, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1641, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1638, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1632, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1625, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1614, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1602, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1586, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1569, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1550, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1528, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1505, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1480, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1454, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1427, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1400, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1374, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1349, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1327, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1308, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1292, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1280, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1273, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1271, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1275, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1283, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1296, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1312, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1330, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1347, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1363, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1377, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1389, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1398, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1404, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1407, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1408, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1406, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1404, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1403, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1405, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1412, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1423, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1440, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1464, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1494, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1531, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1573, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1620, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1671, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1724, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1779, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1835, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1890, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1944, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1995, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2042, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2085, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2122, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2151, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2173, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2189, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2197, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2197, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2188, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2172, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2150, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2121, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2089, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2054, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2019, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1983, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1950, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1920, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1894, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1872, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1852, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1835, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1822, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1812, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1805, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1801, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1800, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1803, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1808, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1818, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1832, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1852, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1876, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1904, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1937, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1972, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2010, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2049, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2086, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2122, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2154, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2183, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2207, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2226, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2239, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2248, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2251, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2247, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2239, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2229, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2218, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2207, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2197, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2188, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2183, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2181, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2182, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2187, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2195, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2205, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2215, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2227, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2238, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2248, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2265, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2271, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2276, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2280, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2283, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2285, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2286, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2286, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2285, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2284, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2282, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2279, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2276, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2272, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2266, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2260, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2242, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2231, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2219, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2204, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2188, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2169, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2149, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2125, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2099, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2072, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2043, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2016, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1989, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1966, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1947, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1935, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1929, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1931, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1941, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1957, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.1979, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2003, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2028, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2054, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2078, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2100, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2120, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2138, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2154, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2168, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2180, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2190, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2199, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2207, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2213, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2218, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2223, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2227, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2231, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2234, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2236, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2238, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2240, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2242, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2243, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2245, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2246, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2247, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2248, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2249, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2249, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2250, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2250, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2251, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2251, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2251, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2251, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2251, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2250, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2250, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2250, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2249, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2249, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2248, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2247, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2247, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2246, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2245, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2245, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2244, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2243, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2242, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2241, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2240, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2239, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2237, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2236, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2234, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2233, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2231, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2230, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2228, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2226, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2224, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2223, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2221, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2220, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2218, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2218, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2218, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2219, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2221, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2224, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2229, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2235, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2243, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2265, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2276, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2287, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2296, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2303, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2305, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2304, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2298, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2289, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2278, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2266, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2242, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2232, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2225, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2220, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2218, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2218, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2220, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2222, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2226, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2230, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2234, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2237, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2241, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2243, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2246, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2248, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2250, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2251, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2255, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2255, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2256, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2256, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2256, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2256, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2256, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2256, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2255, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2255, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2254, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2252, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2251, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2250, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2249, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2247, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2245, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2243, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2240, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2237, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2233, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2228, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2222, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2216, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2208, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2198, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2188, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2177, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2168, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2162, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2164, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2178, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2210, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2317, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2372, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2405, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2410, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2387, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2343, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2288, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2232, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2189, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2166, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2163, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2174, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2192, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2210, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2225, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2236, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2244, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2249, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2253, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2255, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2256, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2257, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "torch.Size([25])\n",
            "loss tensor(0.2258, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0UZiWhsCsY7v",
        "outputId": "02a52141-2514-4559-a713-a1b31170cea2"
      },
      "source": [
        "x = T.linspace(0, 6, 7)\r\n",
        "y = x.sin()\r\n",
        "xs = T.linspace(0, 6, 101)\r\n",
        "out = model(xs.unsqueeze(0)).squeeze()\r\n",
        "out = interp(xoc,output,xs).detach()\r\n",
        "print(xs.shape)\r\n",
        "ys = interp(x, y, xs)\r\n",
        "Ys = integ(x, y, xs)\r\n",
        "P.scatter(x, y, label='Samples', color='purple')\r\n",
        "P.plot(xs, ys, label='Interpolated gt curve')\r\n",
        "P.plot(xs, out.numpy(), label='learned spline interpolation')\r\n",
        "P.plot(xs, xs.sin(), '--', label='True Curve')\r\n",
        "P.legend()\r\n",
        "P.show()\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([101])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iTVfvA8e9JmjZddLNH2bNQ9oYCMlQ2IqK+DvRXUVAUF76gDME9EF4EURAVFJUhFBHZmwIFCi277FKgpXTQnTTP74+0pUALLc1szue6erVJnjznbih3Ts5zzn2EoihIkiRJ5Z/K2gFIkiRJliETviRJkoOQCV+SJMlByIQvSZLkIGTClyRJchBO1g6gOP7+/kpgYKC1w5AkSbIrBw4cuK4oSkBRj9lswg8MDCQiIsLaYUiSJNkVIcSF4h6TQzqSJEkOQiZ8SZIkByETviRJkoOQCV+SJMlByIQvSZLkIGTClyRJchAy4UuSJDkImfCLk5YAUcvg2jFrRyJZkyEXLh+Evd9B4hlrRyNJZWKzC6+s5tBi2P8DxEUCCvjUhrH7Qa2xdmSSJRkM8PcbEL0CslON9wUNh2E/WDcuSSoD2cMvzGCAde9BVir0mAj9PoGkc3D4N2tHJlnaqXVwYBHU6wXDFkCDfnBuB8gNgyQ7Jnv4hSXGGHtz/T6Glk8b/3NH/QnbPoPmI8DJxdoRSpagKLDjC/CuBUN/ALWT8e/i1Drj34h/fWtHKEkPRPbwC4s7ZPxetaXxuxDGnn7KJTj4s/Xikizr3Da4fAC6vG5M9gCB3fIe2269uCSpjGTCLyzuEGjcwL/hrfvq9oSaHWHHl6DLtF5skuXs+BI8KkOLJ2/d51cXPKvA+Z3Wi0uSykgm/MLiDkLl5rd6dWDs5fecBDevQMRC68UmWcal/cZefKexoNHeul8ICOxqTPhyHF+yUzLh58vVw5UjUK3V3Y8FdoE6IbD9C8hKsXRkkiXt+BJcfaD183c/VrsrpMdDwknLxyVJJiATfr6EE6DPvDV+f6eHpkLmDdj5tWXjkizn3HY49Q90eAVcPO5+PLCL8fv5HZaNS5JMRCb8fAUXbIvo4QNUDYagxyF8LqTEWi4uyTJ0mRA2zrjuotOrRR/jUxsqVJcJX7JbJkn4QoiFQoh4IUR0MY8LIcQsIUSMEOKIEKKYrGpFcQfBpQL41in+mF7vG8dvN8+wXFySZWz7FG6chQHfgMa16GOEMA7rnN9pXLMhSXbGVD38RUC/ezz+MFA/7ysUmGuidk0n7pCxF6+6x0viXRPav2RciHU1ynKxSeZ1NQp2zYLgp6FO93sfG9gVMhKNQ4CSZGdMsvBKUZTtQojAexwyCPhZURQFCBdCeAshqiiKcsUU7ZeZPhuuRkPHV+5/bNc34dAvsOhR44yegEZQoQogzB6mOZ3JSeZIdgKpudkAaFVOOAs1D7nXwlPljKIoCGHfv+PtFOMwTk4GxGwAN1/o8+H9n1Z4HL9SE/OGKEkmZqmVttWAS4Vux+bdd1vCF0KEYvwEQM2aNS0UGnDtKBh0xY/fF+bqDSOXGmvuJJyAw0sh56b5YzQBBTivcWK3q5ZwrZaTLs78eOUa1fS57KzgyRd+Pnc9JyRiKRgMzPOuwL/ubrTMyqZVVjYds7Lwz7X3YQ0Bzu6g9YZBc4xJ/358ahnn6F85bP7wJMnEbKq0gqIo84H5AG3atLHcZOc7V9jeT80Oxi8wjunrs80TlwlFJhxhwu73uZweB0ANj+o0923Cqc5PczDdi9QbCQzOSCUtw4kcPRgUHbnk8GmDAHw9XUhUDuGUs421GSdYlpuOQNCxcnvm9vgGlbDTa/9OLsZx+dKqUAXSrpk+HkkyM0sl/MtAjUK3q+fdZxviDoKrr3GMvrSEuH2Bjo0wKAa2x27HXeNO28ptqeFTl2oegbT1HUZach2iz2tYEZHGMiUOML4JuDip8PdQ46JRIXAGnDmSncaN9Bvk5FYEhgMGnN2uUqlyDAnJuWw7l0b72r6sPPM77Su3p55PPSv+1hbiXtG4EE+S7IylEv5qYKwQYinQHkixmfF7MJZCrtbqwXp7NsagGPjn3D/8EPUDMckxdK4SwvFzAaw5coX95weiKODurKdNYAUeblaZ+pU8aVDJk2o+rrg7q4scp1cUhbRsPRcSMzgdf5OTV9M4eKEZh44k8fyh/bi6ZOJc5ysM5NClaldebz2Ohr4Ni4iunPAIgKtHrB2FJJWaSRK+EOI3IATwF0LEApMBDYCiKPOAtcAjQAyQARSxjNFKFMU4Ha/2fWZn2IHI+Eg+2vsRx28cp4prIHX5P9ZvCWSdcpT6FT14rWd9QhoGEFTNCyd1yYdhhBB4ajU0q+ZFs2peBfdn5uQSceEG649e4++jk8h03sHO3J3sjBtOr+r9mNTpHfxd/c3xq1qXe0VIizdOzbzXrC5JsjGmmqUz8j6PK8AYU7RlcjlpoMsAz0rWjqTMTiSeIjY1AY+U/3DqeGP83LW81L0GQ1tWo34lT5O35+qspmv9ALrWD2DygCbsPtOFn8KPsfP6n2zU7yA7vj/v9G5N2r9n2TRxEykXU/Cq6UWvGb0IeirI5PFYjEclUHIhMwnc/awdjSSVmE1dtLWKtHjjdw/7S/iKorDm7BpyDXAzsTnfbvHhSuprNK8WwIQnatOvWWVcnNQWicVJraJbgwC6NejOpRtt+XH3KX7be5V/D28mwHkpwe6VqapUIOVCCmGhYQD2m/Q9Aozf0+Nlwpfsikz4+bMt7Czh38i6weRdk9kauxVNdhNunP0PrWv58vHQFnRvEGDVOfM1fN34oH8wo7tn8fzLCzgfco5db0dTMbwdXb6vBhk6Nk3cZL8J372i8XvaNajY2LqxSFIpyIRvhwn/4LWDvLHlTZKyksmKfxR/dR++eK4pPRpWtKnFURU9tbT79Tr1NvZlx7hoEjqG81fD2nT4tjWcseOqo/l/K2kJ1o1DkkpJJvyb9pXwzySd57l1ozDkeCMSXmVi9x481aEWmlJchLUkr5pecCGFAf9tyoHHAzjfN5ydb+bQZvnj9rt6t/CQjiTZEdvMEpaUdg1UTsYa6DZMURSOxqUw5qeLZMQNobPbdDa9+iTPda5ts8keoNeMXmjcNKgQtP2jEj0+7IV3RB+2t67Eq78dIj1bb+0QS0/rDWrnW9d/JMlOyB5+WrxxTNbGptdFLYkqmNmiaeTM5vEHuXTlIbxUdZk7ZDS9m9jHJ5L8cfr836WuUo0XQ3qys5obsyO/oNciZ/58/CNq+BRRf95WCQHuATLhS3ZHJvy0a+BR0dpR3CZqSRRhoWHoMnQkBGawfexGDOo06rh1Zsnobvi6O1s7xFIJeirorgu0zRWFk7rKbLmynIG/v8yvg2bSuIodzXjxqCiHdCS7Y1vdWmtIu2Zz4/ebJm5Cl6HjfHAWWyduw+Cio+4fA+kzG7tL9sURQjCrzxSeqj8GvWskj696kd1n7WhjmfzFV5JkR2TCT4u3uUVXKRdTONZZxf6xG8HgRPuvH6LVOhWpF+14ZksxJnQazfjgyaA9S+iGl9h//rq1QyoZDzmkI9kfx074hlzjx3Ib6uErisKJfoHs7dICTWxzek3rRs2jGiBvxks59HyLx/io01dUyO7LqB8PcCQ22doh3Z9HJUhPkDtfSXbFsRN+RiIoBptJ+Iqi8FbYasJbulDvRAoDptXC97ILABo3Db1m9LJyhOYzoEEvlj3zf3i5aXj610WEn79o7ZDuzb3irfIKkmQnHDvhFyy6sv5FW4NB4dUVK/k3cRr1mqzjy8da4FujAgjwquXFgPkD7HdlaglV9XZl3jONUAIWE7rhRaLi4qwdUvHkXHzJDjn2LB0bWWWrKAqvr1zN1pSPqODsx5LBn1HRvSItnm5u1bisoVmVqkzt8BmT947nmbUvETb8F6p7eVs7rLvJ8gqSHXLwHn5+4TTr9vCnrdvGpuSP8dBUYPngn6jobv1PHNY0tHFPXm02FZ3TBYYtDyU1K9PaId1NlleQ7JCDJ3zr9/B/3nOepWdno3VSs3TgQqp4VLFaLLYktM0gHq/1Jhnq4zz/5/cYDJbb8bJE5JCOZIccO+HfvAbOnsaNrK1gbdQVJq8+SjuPsfz86A8EegVaJQ5b9UGPZxle9TMOHK3DrM2nrR3O7QrKK8i9bSX7IcfwrTScc+hiIm+t/4bgmg/z3ZNd0GosU7fe3rz/UD+Skw4za8cO0jS7mdT9OWuHZCRE3uIrOaQj2Q/H7uGnWWcO/rWUTEat+S9q/795vleOTPb3IITgoyFBVKqxh6XnvmJJ1Bprh3SLR4Ac0pHsioMnfMv38LN0uTz++2fo3XczKPBpBjbobdH27ZFWo2bJ4M9R5dTgkwMfEBFnIxuIy/IKkp1x8IRv+R7+S8t/IdF5OUHeXZnW7W2Ltm3P6vj78GX3bzDo3Xhpw6tcz7CBEgyyvIJkZxw34esyITvFoj38X/edJSLtB/w1tVnw6JeohOO+/A+id8N6jKjxAdmGm7y14WtrhyPLK0h2x3EzjoU3Lz9xNZVpYSdpoLzJ4oFzcXVytUi75c2k3r1pzDvs3teBqFgrF5OT5RUkO+PACT9vOp1nZbM3lZKZzQt//ISH1onvnniY6p5Vzd5meaVSCeY/PhR/DzdG/7aNf89ttV4w+XPx5dRMyU7IhG+BIZ1nl39Cqtd8RvfTU9FTa/b2yjsfd2dmP9mKGy4reGf7eI4lHrNOIPmfDuVMHclOyIRv5iGdr3asJUa/nLquXXmhVT+ztuVIWtfy4flGr6LXufHSv6+Rkm2F4Z2CejpyLr5kHxw44ccDAtz8zdbE4biL/HhqOi5KJX4e+BlCCLO15YjefKgVtXNfJinnOm9sfheDYuGLp7K8gmRnHDjhXwN3f1CbZ7GxPtdA6LrxKKosvun5NRW0drRJt51QqwTzHh+CSBzI/vhdLD62xLIByPIKkp1x4IRv3jn4320/y/XLHXk8cDxdajUzWzuOrrqPG9N7vUR2fD+uXm5k2caFAPcAOaQj2Q3HTfg3r5rtgm3kpQRmbjxFv7o9eD/kKbO0Id0yKLga/ao/yfytCRy+lEiGLsNyjbv6QpYdbMkoSThywk+LBw/TT8lMSE/iuQ3D8fCP4MNBzeS4vYVMG9QUXw8nRv0bysSdk1AUC5VT1npBVvnbXF4qnxwz4SuKcYWku2kv2CqKwnNr3kavSmZs5xB83Z1Nen6peN5uznw2LJibSXXYeHEDK2NWWqZhmfAlO+KYCV+XCbnZ4OZr0tN+s+9nLmbtpYHmcV5o182k55buL6RhRR6r+zT69Dp8FP4JF1MtsBG6TPiSHXHMhJ+/FF5rur1SY5LOsvD4LFRZDfhh8HiTnVcqnYmPNsU34xly9PDu9gnoDXrzNqitAFmp5m1DkkzEsRO+q4/JTvnNzg3k5jozqd1UfN3lalprcXdx4oshIWTEDeZcUjzxGWaeI6/1guxUWUBNsguOmfDzZ1WYKOHHxKfxb3hNurh8wfCWcgqmtXWs68eTzQZy7fhYYhPM/Oar9QIUY9KXJBtnkoQvhOgnhDgphIgRQkwo4vHnhBAJQojIvK8XTdHuAzNhDz864Siv/vUrrs5qpg9qU+bzSabxbr9GVPOqwNvL9vO/g/PI0meZpyGtl/G7HMeX7ECZE74QQg3MAR4GmgAjhRBNijj0d0VRgvO+fihru2VSkPDLNoafnZvN2I1vc1H1M+89Uo8ATxcTBCeZgruLE5891pzYzFN8FzWHWYdmmachmfAlO2KKHn47IEZRlLOKouQAS4FBJjiv+Zioh//Z3lkk5lyinhjFiDa1TRCYZEqd6vozIigEXVJHFh9bTMTVCNM3IhO+ZEdMkfCrAZcK3Y7Nu+9Ow4QQR4QQy4QQNYo6kRAiVAgRIYSISEgw43L1zGRQOYHzg9e3OZxwmD9O/0JuSjtmDR4hF1jZqPceboR31mBUuX5M2jXJ9KtwZcKX7IilLtqGAYGKojQHNgA/FXWQoijzFUVpoyhKm4CAAPNFk5lk7N0/YJLOzs1m/Ob3MOi8+L+m46jl527iACVT8dRq+Ghwa25eeozLaXGmH9qRCV+yI6ZI+JeBwj326nn3FVAUJVFRlOy8mz8ArU3Q7oPLTCrTHHydTkXq1c74Z/6HMd3lrBxb17NRJQY07ETOtUG09X3UtCeXCV+yI6ZI+PuB+kKI2kIIZ+AJYHXhA4QQVQrdHAgcN0G7Dy6/h/8AFEVh5sbTJFwJ5ssBj+Hs5JgzW+3NBwOa4pHdjVnrUsg1KOQack1zYpcKxu8y4Ut2oMzZSlEUPTAW+BdjIv9DUZSjQohpQoiBeYe9JoQ4KoQ4DLwGPFfWdsskK/mBEr4uV8fw1U/zc9RfjGxXgzaBpi3NIJmPr7szkwc25XBsEsNXvMzMgzNNc2KVGpw95Tx8yS6YZPcPRVHWAmvvuO+DQj+/B7xnirZMIjMJAhqX+mnfR/3AyeQjuDm15d1+Fq69LpXZgOZVWHWoMnvi9JxJ/5k+tfoQFBBU9hPLejqSnXDM8YjM5FLPwY9JiuG7w/PRpQQzsccwvN1kJUx7I4Tgw8HNUN0YgFrxYvLuyegMurKfWCZ8yU44XsLP1Rs/fpdiSCfXkMvEnR9gyHWhifN/eKx1dTMGKJlTVW9X3u3bgpTYAZxOPs2i6EVlP6lM+JKdcLyEn/8fsxQJf+/VvRy7EUVOfH8+GdJRzrm3c0+1r0VLv86Q3pxfjy8lOzf7/k+6F62X3PVKsguOl/AfYJWti64R6efG8GzQUBpU8jRTYJKlqFSCT4YFkX11MPX17+OiLmNJDNnDl+yE4yb8Es7Dv5Bykff/Okoll/qMe6iBGQOTLKleRU/Gdg9mfVQ664/GcSb5zIOfTCZ8yU44XsIvRWnkTRc2MfCvgZxMieT9/k1wdzHJpCbJRozuXpeGlTyZsO1D/vPPMyRmJj7YibRexk1QZE18ycY5XsIv4ZBOui6d6eEfYciuRMdqrXi4mek3PJesy9lJxSfDgki+1o60nHS+jPjywU6krQAokHPTpPFJkqnJhF+M/x36H9ezEsi5NpQPBwXLC7XlVMuaPjzbph1Z17sRdjaM8CvhpT+JLK8g2QnHTfj5/0mLcDzxOEuO/0pOUnv+r10Itf1lcbTy7K0+DfHXPYIq158P93xY+lk7BQlfrraVbJsDJvxkY/0TdfHj8VEJR1HleuGXPYgxPepZMDjJGtxdnPhkaGvSLg8iOUPP1fSrpTuB7OFLdsIBE37SfVfZpia0Ivn0eKb0b4Ors9pCgUnW1K1BAIMahnDt2Fgy0ktZZ0kmfMlOOGjCL/o/9PXM64Sd3szMjafp0aAqvZtUsnBwkjW9/2gTvN20vLVsH3+c+BNFUUr2RJnwJTshE34hX0V8xcTd48khiSkDm8oLtQ7Gx92ZqQObcSp9Ox/uncaGCxtK9sT8NR0y4Us2zvESflZykYuuIq5GEHY2jKzr3RjdpZXcxcpBPRJUmR5VH8WQVZWP9n5Cui79/k+SNfElO+F4Cb+IHr7OoGN6+HRUub5UzH2EV0LqWik4ydqEEEwf3ALVjWEkZiXwbeS393+SOm9/ZJnwJRvnWAlfUYpM+EuOLeFMyhnS4vozbWBLtBp5odaRVayg5YPeD5OT1JbFx5YQkxRz/ye5VJAJX7J5jpXwc9LAoL8r4QuDB4bU1vSs2YOejeSFWgkea12d1hWeQp/WmIRU/f2fICtmSnbAsRJ+Zn4dndvH8MOP1CY3fgQf9G9ihaAkWySE4IuhnVDFP8fMdUkYDPeZsSMLqEl2wMES/u1lFQ5cO8CH2xfwT3QcY3vUo4avmxWDk2xNVW9XJvVvzL5L53hm9Tv3voCr9ZL72ko2z2ETvs6gY9qeD1kW8zO1A1z4v251rBubZJMeb1ODVnVURCb/y6fhs4o/UPbwJTvgsAn/t+O/cTblDOlxjzJjUCtcnOSFWuluQghmDx2EuNmOlWeWcjqpmLr5MuFLdsCxEn7eRbXrGPjfoTnkpjfk0boP0amev5UDk2xZVW9X3mr3OorBmXHrJxe9Ajc/4Zd0da4kWYFjJfy8Hv5XJxaTpc9BfWMwk/o3tXJQkj14pl1T6qgf41LWYV4Y/hZTVVOZGTiTqCVRxgO0XqAYjDPBJMlGOdYWTplJoHbBh85kXnPig15dCPAs436mkkMQQjCeh3glLpZDvkFUFxdJuZBCWGgYAEGNCq22dZH7Hku2yeF6+AatN79td6WZ5yM81b6WtSOS7Ejk5B10WFiPJN8AIjtXAUCXoWPTxE2ygJpkFxyqh7/y5hmi3VxITcrk46HtUalkcTSp5FIuplBLgcDzJ4l5YisBiS2peUxFysUUmfAlu+AwPfyU7BS+1F3msFrFi13r06hyBWuHJNkZr5rGpN5qy3VU2svse+EYeidhvF8mfMkOOEzC/+bAbG5i4LFkH15/qIG1w5HsUK8ZvdC4afCKd6HW5iDwO8GeJ3PpNaOXLJEs2QWHSPgnb5xk2ek/6J+qI6RqHVkcTXogQU8FMWD+ALxqedH6j5o4pflwpfMOUtsHyH1tJbvgEAl/6q5PMOhdeS01hcoVK1s7HMmOBT0VxOvnX2dazjQ+fWQqKpcE3lw3nyx13v4Jsocv2bByn/D1uQauX3gYbdITVNJn3Hc/W0kqqT61e/Biw/e5erk5M7dcAI2brJgp2bRynfANioHvd5zjVKw7n/boY7yziN2uJOlBjevwOCNa1+H7HafRaTxlD1+yaeU64U/f9TWzoz+gX9MAegVqjXfmj7VKkokM76TCre7nbDE4Y8iUPXzJdpXbhH8h5SLLYhbjpFIzbXDzWx+1ZcKXTKxxQG08tYL/+aiIvXbV2uFIUrFMkvCFEP2EECeFEDFCiAlFPO4ihPg97/G9QohAU7RblKglUcwMnMmIr1/FoKh4mpFU9NTe+qgtE75kYu4adya0f5NzWoVVOQlcupFh7ZAkqUhlTvhCCDUwB3gYaAKMFELcuXXUC0CSoij1gK+BT8vablGilkQRFhrGgWoXSK99Frfj7dG/fchY4Co/4cuLtpIZ9K/bn2bCnT98c5m0en/RFTUlycpM0cNvB8QoinJWUZQcYCkw6I5jBgE/5f28DOglhDB5XYNNEzeRlaXn8IiTKFk+hMyrfKvWiezhS2akEiomejYhRQ27r/3L+mPXrB2SJN3FFAm/GnCp0O3YvPuKPEZRFD2QAvjdeSIhRKgQIkIIEZGQkFDqQFIuppDhqUE5+QTNFnfD/aZScL9M+JK5NfOowS9XE6nj3Icpq4+Snl2Czc8lyYJs6qKtoijzFUVpoyhKm4CAgFI/36umF54pOQz57jyNd2puu5/MZFA5GedKS5I5aL1okZXBxwMbciUtka83nLR2RJJ0G1Mk/MtAjUK3q+fdV+QxQggnwAtINEHbt8mvdaLOvTV+qnHTGGudZOVVNDT9SJIkGWmNBflcNKfwbvA5Px9ex+lrN60clCTdYoqEvx+oL4SoLYRwBp4AVt9xzGrg2byfHwM2K2a4qlW41gkCvGp5MWD+AIKeCrqV8CXJXPIW9TVwCaCaZ2VcKoUxaVWkvIAr2Ywy18NXFEUvhBgL/AuogYWKohwVQkwDIhRFWQ0sAH4RQsQANzC+KZhF0FNBxgR/J5nwJXNzMfbwNTnpTGz/Hi9tfIlD8atZc6QuA1pUtXJwkmSiDVAURVkLrL3jvg8K/ZwFDDdFWw9MJnzJ3PL/vrJT6FTvIUKq92CbsoUP/+lAz0aDcHdxqP2GJBtkUxdtzSorRdbRkcxLW2hfW+Cddm/jpFZI4jCzNp+2YmCSZORgCV/28CUzuqMmfg3PGqwb9g+D6w5j4c5znE1Is2JwkuRQCT9ZJnzJvFxu7+EDVHSryNv9GuLiGs+0NdFWCkySjBwj4euyQJ8lE75kXs7uINSQffuuVwnZZ1DV+Jpd19ay+YRcgStZj2Mk/Pz/gDLhS+YkhHEc/46a+E38mtCqYitcK61n6t8RZOtzrRSg5OgcI+EXlFWQF20lM9N63bWvrRCC99pPAFUmV1Wr+HHXeevEJjk8B0v4socvmZnL3T18gIa+DXmi0QicfcKZvWMb8TezrBCc5OgcJOHnbX4iSyNL5qb1umsMP9+Y4DH4u1ZE7xTH5+tknR3J8hwk4csevmQhWq9i97X1cvHi38fW8mzzYSw7GMuRWLkdomRZjpHwM+X2hpKFFDGGX5iz2pkxPeri7XuaKWEHZZ0dyaIcI+HLHr5kKcWM4ReWmB2LvuICjmYuJ+zIFQsFJkmOlPDVzuCktXYkUnmn9YKcm2AofuplHe86DKk3BGffncxYv4XMHDlNU7IMx0n4sha+ZAn59XSKuXCb7/XWr+OmcSPVfRnztsVYIDBJcrSEL0nmdkc9neL4an15o/U4nNxjmH9wJXHJmRYITnJ0MuFLkikVUU+nOMMbDKdNxY4oBhWfrjth5sAkyaESvpyDL1lAQU38e/fwAdQqNT8+PJ8XWw1iVWQcBy4kmTk4ydZFLYliZuBMpqqmMjNwJlFLokx6fgdK+LKHL1mAtuQ9/Hz/160WvlXCmfT3BgwGOU3TUUUtiSIsNIyUCymgQMqFFMJCw0ya9B0k4cvSyJKFlHAMvzCDyMTJbyPnWcLyg7FmCkyydZsmbkKXoeNqdQ+uVvcAQJehY9PETSZro/wnfEWRPXzJcvKHDkvRw/fR+vBmmzdwcj/LxzuWkJatN1Nwki1LuZjCTS9nNg+tR3jvmhjErftNpfwnfH0W5ObIhC9Zhoun8XsJxvALG97wMepWaEJ2hVV8vSnSDIFJtk5bx4f1b8Qh/PbTc+UZVHmje141TZe7yn/Cl6tsJUtSa0DjXqoePoBKqPi42xRUTun8dno+FxMzzBSgZItyDQo7Qn0w1NpO9YTjVEjOBkDjpqHXjF4ma0cmfEkytSI2QSmJxn6NeanZOEgPZvrfx8wQmGSrPv3nGGc9f0eruNF7YzsQ4FXLiwHzBxD0VJDJ2nEy2ZlsVf5/PFkaWbKUe1TMvJ+xrV9ApMbw+b8n2Xn6Ol3q+5s4OMnW/H3kCj8e+RNt1QtM6vwhg58fbKmcMMYAACAASURBVLa2HKiHLxO+ZCElKKB2L892qo5/rX94Z8McdLkGEwYm2ZqY+Ju8vXwvblXW0TKgFYPqDjJre+U/4cvSyJKl3WMTlJJwd3ahTpVMUl1X8+2OCBMGJtmSm1k6Qn85gJvGnemdPmJKp8kIM9f7Kv8JP0smfMnCHnAMP58Qgq96TUUt4IdjX5Egt0MsdxRF4d3lR7iQmMrska0Y0KAndbzrmL1dB0j4ef/x8mucSJK53WcTlJKo7lmd/zQKBfejvL12iYkCk2zFz3susDb6EtWazeVszjqLtesYCd9JCxpZC1+ykPwx/DLuZjWu3Si81bXYn/oLhy4mmig4ydqiL6cw4+/jNGgYTpIulvre9S3WtmMkfDmcI1mS1gsMOuOivzLQqDTMfugztDdeYsrq47LOTjlwM0vHmF8P4u19nXjVOgbWHUi7Ku0s1r5M+JJkag9QQK04wZWb8H6fbhyOTebH8KNlPp9kPYqi8N6KKGKT0qhUdxVeLl683eZti8bgIAlfTsmULKignk7ZxvHzDQquSs3665l57DWupt40yTkly/sj4hJrjlzhqW6C2LQzvNfuPbwtnJscJOHLHr5kQaXYBKUkhBCMaT8QNAm88vdnJjmnZFkx8WlMWX2MzvX8mNLnUVYPWU3fwL4Wj8MBEr4sjSxZWMEmKKarcjii2UPUcu7GqezV/HV0n8nOK5lftj6X1347hNZZxQu9BCqVoIZnDbPPuS+KAyR82cOXLMyEY/iFzXtkCsLgzrTwyWTqsk16bsl8Pv3nJMeupDKs+yXGbX+RvVf2Wi2WMiV8IYSvEGKDEOJ03nefYo7LFUJE5n2tLkubpSJr4UvW8ACboJREda8Anqk/nmySmLV9j0nPLZnH1pPxLNx1juHt3Qm7NJ/2ldvTrrLlZuXcSShlmCsshPgMuKEoyidCiAmAj6Io7xZxXJqiKB6lOXebNm2UiIjbl5XrdDpiY2PJyirhdDfFACmxxotoWrnwSrKQQn93Wu+KVK9eHY1GY5pTKwrPLtpOxLlMNo7vTlVvV5OcVzK962nZ9Ju5A193DTWbLObI9cOsHLSSah7VzNquEOKAoihtinqsrNUyBwEheT//BGwF7kr4phIbG4unpyeBgYElG//S50B8DnjVAHdZdVCyEEWBKzko7hVJ1LkQGxtL7dq1TXJqIQQzBrWl99dbeGXVXP78z6toVKZ5M5FMR1EU3l12hNQsHc/3u8q8o+FMbD/R7Mn+fso6hl9JUZQreT9fBSoVc5xWCBEhhAgXQjxw7c+srCz8/PxKfrFDyTV+V6kftElJKj0hQKgRigE/P7+SfyItoRq+bgzplMkZfmTCxpkmPbdkGov3XmTTiXjee7gRtXy9CakRwuMNH7d2WPfv4QshNgKVi3hoYuEbiqIoQojixodqKYpyWQhRB9gshIhSFOVMEW2FAqEANWvWLC6e+4V8iyFvb1BV+S/7L9kYlRqUXLPNxJjWZyibF65lfdxi9l7uQ/tqLczSjlR6MfE3mfH3Mbo3COC5ToEIUZtHaz9qlVk5d7pvD19RlIcURWlWxNcq4JoQogpA3vf4Ys5xOe/7WYzDPi2LOW6+oihtFEVpExAQ8IC/UiGGvB6+kD18ycKE+tbfnxlo1Cq+6T0Vg96D1ze9S3aunLVjC3L0BsYtjcTN2YlurU/z56k/URTFJpI9lH1IZzXwbN7PzwKr7jxACOEjhHDJ+9kf6AxYZv82MwzpeHjc/9rzzJkzycgw/56kixYtYuzYsfc8ZuvWrezevbvU5w4MDOT69eslPv6vv/7i2DG5LV8BlXkTPkCHwBr08n+VNOUyEzbLBVm24MsNJzkal8r4R7yYG/U122O3Wzuk25Q14X8C9BZCnAYeyruNEKKNEOKHvGMaAxFCiMPAFuATRVEskxkM1hnDf5CEn5trnuTwoAm/tMyV8PV6vcnPaREqza0hRTP67NHhuKX3Jzy6KunZdvpalRN7ziQyf/tZRrStyporX+Hq5MqUTlNspncPZZyloyhKInDXluqKokQAL+b9vBsw3S68eaaGHeVY3H3mOefmGL+c95fonE2qVmDygKYlOnbr1q1MmTIFf39/oqOjad26NYsXL2b27NnExcXRo0cP/P392bJlC+vXr2fy5MlkZ2dTt25dfvzxRzw8PAgMDGTEiBFs2LCBd955h3nz5tGiRQu2bduGXq9n4cKFtGvXjhs3bjBq1CjOnj2Lm5sb8+fPp3nz5rfFExYWxvTp08nJycHPz48lS5aQmZnJvHnzUKvVBbE1atSI0aNHc/HiRcD45tS5c2cSExMZOXIkly9fpmPHjhQ3XXfBggV8+umneHt706JFC1xcXHjyySdZvXo127ZtY/r06Sxfvpy6desWPOfatWuMHj2as2fPAjB37lyqVq1K//79iY6OBuCLL74gLS2NKVOmEBISQnBwMDt37mTAgAEsXLiQc+fOoVKpSE9Pp1GjRpw9e5aLFy8yZswYEhIScHNz4/vvv6dRo0Yl+vczO7UTWCABazVqZj/8NiPm7+Hjf44zdWAT1HKSgsWlZOh4849Iavu5E1BzK2uPHeWrkK/wd7Wt2YHle6WtogDme3c9dOgQM2fO5NixY5w9e5Zdu3bx2muvUbVqVbZs2cKWLVu4fv0606dPZ+PGjRw8eJA2bdrw1VdfFZzDz8+PgwcP8sQTTwCQkZFBZGQk3377LaNGjQJg8uTJtGzZkiNHjvDRRx/xzDPP3BVLly5dCA8P59ChQzzxxBN89tlnBAYGMnr0aN544w0iIyPp2rUr48aN44033mD//v0sX76cF198EYCpU6fSpUsXjh49ypAhQwreEAqLi4vjww8/JDw8nF27dnHixAkAOnXqxMCBA/n888+JjIy8LdkDvPbaa3Tv3p3Dhw9z8OBBmja9/5tqTk4OERERTJ48meDgYLZt2wbAmjVr6Nu3LxqNhtDQUGbPns2BAwf44osveOWVV0ryz2YZKifjkKJi/j1p29X25YXOtfnz7FyeXzuu2DdryTwUReG/K6OIv5nNewMD+OX4IobWH0rvWr2tHdpd7Hb6Sol64jfOgy4dKpWs115a7dq1o3r16gAEBwdz/vx5unTpctsx4eHhHDt2jM6dOwPGRNaxY8eCx0eMGHHb8SNHjgSgW7dupKamkpyczM6dO1m+fDkAPXv2JDExkdTU2z/dxMbGMmLECK5cuUJOTk6x8743btx429BLamoqaWlpbN++nRUrVgDw6KOP4uNz96Lpffv20b17d3x9fQEYPnw4p06dus+rBJs3b+bnn38GQK1W4+XlRVJS0j2fU/h1GTFiBL///js9evRg6dKlvPLKK6SlpbF7926GDx9ecFx2tg1duMzvZVtgWAfgrb4N+fuiD4cSV7P0+ApGNhlmkXYlWH7wMn9HXeGdfg3p3aAecz3mEhwQbO2wimS3Cb9EFL1Zp2S6uLgU/KxWq4scb1YUhd69e/Pbb78VeQ53d/fbbt853lfS8b9XX32V8ePHM3DgwILhpqIYDAbCw8PRaq27A5iTkxMGw63e751z1Qu/LgMHDuS///0vN27c4MCBA/Ts2ZP09HS8vb2JjIy0WMylkr8YykIJX6tRM2/Am4xcE82n+z+mU/U21KpQyyJtO7ILielMXhVNu9o+9GlhHDDpVLWTlaMqXvke0jHkWmVKpqenJzdvGuuWd+jQgV27dhETEwNAenr6PXvFv//+OwA7d+7Ey8sLLy8vunbtypIlxn1Nt27dir+/PxUq3F4qIiUlhWrVjKv4fvrppyJjAejTpw+zZ88uuJ2fMLt168avv/4KwD///FNkD7xt27Zs27aNpKQk9Hp9waeOotoprFevXsydOxcwXpxOSUmhUqVKxMfHk5iYSHZ2NmvWrCn2NfHw8KBt27aMGzeO/v37o1arqVChArVr1+bPP/8EjG+shw8fLvYcFpff0ci13IXUFjV8earOBPR6Nf/3zzg5VdPMdLkGXv89ErVK0KvdGR4LG0pkvI12QPKU/4RvhQtYoaGh9OvXjx49ehAQEMCiRYsYOXIkzZs3p2PHjgVj30XRarW0bNmS0aNHs2DBAgCmTJnCgQMHaN68ORMmTLgtoeebMmUKw4cPp3Xr1vj737pQNGDAAFauXElwcDA7duxg1qxZRERE0Lx5c5o0acK8efMA43WC7du307RpU1asWFHkwrdq1arx3//+l3bt2tG5c2cCAwPx8jIWCnviiSf4/PPPadmyJWfO3L6m7ptvvmHLli0EBQXRunVrjh07hkaj4YMPPqBdu3b07t37vhdbR4wYweLFi28b6lmyZAkLFiygRYsWNG3alFWr7poVbD35Cd9CPfx87z7Unur654nLuMjmMwct2raj+WbjaQ5dTGZsPzfmR8+kQ9UONA9ofv8nWlGZiqeZU1HF044fP07jxo1LfpKrUcbCad41TBydeYSEhPDFF1/Qpk2RdY9sQlpaGh4eHuj1eoYMGcKoUaMYMmSItcOyPbl6uBYFFapx/FJi6f5uy+hyciYPz15LTe+KLH+5Ey5OctaOqe05k8iTP4QzpJUfp5ymk6nL5M+Bf+Kr9bV2aPcsnlZ+e/iKYrUefnk2ZcoUgoODadasGbVr12bw4AcujVS+WfiibWHVvF35fGhnoi+n8sqq+VxKvWTxGMqzpPQc3vg9kkA/N0TAci7dvMSn3T61iWR/P+X3oq1iABS7Svhbt261dgj39cUXX1g7BPsghHFYxwoJH6Bv08qM7OBL2I2pvLBuHauGLsXVSZZSLitFUXh3+RES07NZ8Uwn9iadobFfQ9pUtt1P5YWV3x6+rKMjWZsVEz7AlP7tqKp7kbiMc7y1+X05P98Eft5zgfXHrvFO3wYEVffmxaAXeTHoRWuHVWLlN+ErslKmZGVWTvguTmp+GfkMmtR+bL/yLz9GLbFaLOVB9OUUZvx9nC6NnFmb9Db7r5ZsBb8tKb8J30p1dCSpgMrJotMyi1Kpgpb5A98hN60xMw9+weWbV+7/JOkuN7N0jPn1IL4eKhT/n7mcdhkvF/vbOrX8J3w5pCNZi5V7+PnaBvrzdqsppMc+xbxNiXJop5SMpROiiU3KoFWrLRxJjGRqp6k08Glg7dBKrfwnfBP38EtSHtlSSlvCuCiFSyzPmzevoARCWXXqdP/VhrZcRtokr0VBPR3rJ9jnOzbhxdb9+SX8Ah+s+5t0Xbq1Q7Ibv4RfIOxwHA91OMmOq38T2jyUh2s/bO2wHkj5HeC28TH83Nxc1Grb+vQxevRok52rJCWZZ86cydNPP42bm1uJz2uu123r1q14eHgUvFGZ5LVQ5/3tWaCAWkm827cRsSnxrLz6BsfCWvPnkO9QifLb5zOFAxeS+HDNMXo1DsDbewe9K/RmTPAYa4f1wGwzG5bEPxOMC6uKk5udVxrZgxJXzKwcBA9/UuIQPv/8c/744w+ys7MZMmQIU6dOBWDw4MFcunSJrKwsxo0bR2hoKGD8dPDSSy+xceNG5syZQ79+/Rg3bhxr1qzB1dWVVatWUalSJRISEh64hHFubi4vvPACERERCCEYNWoUb7zxBiEhIUWWXi5sypQpeHh48NZbbxESEkL79u3ZsmULycnJLFiwgK5du5Kbm8uECRPYunUr2dnZjBkzhpdeeumuODw8PEhLS7PbMtKbNm0qeC0iIyMZPXo0GRkZ1K1bl4ULF+Lj41Psa1RAZVsJX6USzBzelYE/D+fUzV95ZsFbtJlek5SLKXjV9KLXjF4EPWXySuZ263paNmOWHKSKlytfPd6SCtq26Aw6u36TtN/I76egNLJ5yiOvX7+e06dPs2/fPiIjIzlw4ADbtxt3t1m4cCEHDhwgIiKCWbNmkZiYCBjr6LRv357Dhw/TpUsX0tPT6dChA4cPH6Zbt258//33AGUqYRwZGcnly5eJjo4mKiqK559/vuCxokov34ter2ffvn3MnDmz4M1swYIFeHl5sX//fvbv38/333/PuXPn7nkeeywjXdgzzzzDp59+ypEjRwgKCip4LYp7jQoUJHzz7nxVGhq1ij9HvoVHalcOazawrtsxUCDlQgphoWFELblHJ8qB6HMNvPbbIZJyrlG18U/c1F9DCIGz2tnaoZWJ/fbw79cTv3EedBlQqYlZml+/fj3r16+nZUvj9rxpaWmcPn2abt26MWvWLFauXAnApUuXOH36NH5+fqjVaoYNu1W21tnZmf79+wPQunVrNmzYAJSthHGdOnU4e/Ysr776Ko8++ih9+vQpeKyo0sv3MnTo0ILYzp8/X/B7HzlyhGXLlgHGom2nT58uthwz2GcZ6XwpKSkkJyfTvXt3AJ599tnbSjIX9RoVKKinYxs9/HweWg2DZtVn6YvXiO0ZTuS1gQSv16DL0LFp4ibZywdmrD3O7nOXqN18MRduJpGhN/+1Jkuw34R/P4rerFMyFUXhvffeu2s4Y+vWrWzcuJE9e/bg5uZGSEhIQelfrVZ72/izRqMpKH9cuLxyWUoY+/j4cPjwYf7991/mzZvHH3/8wcKFC4HSl17OL/9cODZFUZg9ezZ9+/YtcUz2WEa6pIp6jQrYYA8/X/aZVB6Z2oz1YwI51LI9zomxNDkQT8rFFGuHZnW/77/Ij7tPU7vZH6TorjLvoXl2OSOnKOV3SMfMdXT69u3LwoULSUtLA+Dy5cvEx8eTkpKCj48Pbm5unDhxgvDw8FKfuywljK9fv47BYGDYsGFMnz6dgwdvVUwsqvRyafXt25e5c+ei0+kAOHXqFOnpDzbjw5bLSOfz8vLCx8eHHTt2APDLL78U9Pbvy8bG8AvzqumFS6aKh7/2ouapFPY97M7OYWoq1LS/ueWmtP/8DSb9FUm1Bn+QqD/JjC4zaFel3f2faCfKbw/fkAtql/sf94D69OnD8ePHC4YdPDw8WLx4Mf369WPevHk0btyYhg0b0qFDh1Kfe9asWYwZM4bmzZuj1+vp1q0b8+bNY/LkyYwcOZKmTZvSqVOnIksYX758meeff75gc5GPP/644LH80ss6na6g119aL774IufPn6dVq1YoikJAQAB//fXXA50rv4x0/lh+fhnp/J2rpk+fToMGRfesivpdpkyZwqhRo2jevDlubm73LCPt4+NDz549C64/DBgwgMcee4xVq1bd9mYLxjeG/Iu2derU4ccffyzZLyiEcR2IDSb8XjN6ERYaBhk6Qv6K4e+O4Vx55AZ7OrzGGL0BZ6fy2xcszqUbGYz+5QDVfJ3w99PzeqP37Xb6ZXHKb3lkOyuNbG72UHq5pOzqd7l2zFgeuU3X+x9rYVFLotg0cRMpF1MQzVWEjVtPhkFPA8Pb/PhUf7zd7PsCZWncSM9h2NydJKZnseLlbtTyd0GTv2uZnblXeeTy2cNXFOMKR1lWQbI2tZNN9vABgp4Kuu0C7X9SnubJNc9yOutz+s/L5Kf/DKJugO0sNDSXLF0uL/wUzjWXn2jRwIla/r3tNtnfT/n83Jb/H0wm/AJbt261jx5xCdjV75K/2tYO1PaqzZL+i/Bx05LquoYhc3ax7VSCtcMyq1yDwthf93Midy7qCgfpEdi+3CZ7KK8JP79+iayjI1mbysnmpmXeSx2vOvzW/xf+HPoNVb1dee7HvczedBqDwTaHfssi16Aw/s/97Lr5JU4Vonm7zduENg+1dlhmVU4Tfn4dnfI5YiXZEVXekI4dJf3qntVpWKkiv4a2okbjJXyzZyX/93MEKRk6a4dmMgaDwnsrjvBv/Nc4eZ5gUvtJPNP07oV65U35zIiKLI0s2QiVE6BAVjK42f4WeIWpVHqq+UGysoSd127y8DepfD0imPZ1/KwdWpkoisKkVdH8ERHLk13/Q/emavoGlnxdiT0r3z18OaQjWVv+p8z0slU1tQZvrTcL+iyge/VuOFf6C533Xzzx/S4+//cEulz7+cRSmC7XwKilf7AsZhEvh9RlxiMPO0yyh3Kb8M1TKTMxMZHg4GCCg4OpXLky1apVK7idk5NjkjZ0Oh0TJkygfv36tGrVio4dO/LPP/+Y5NySFeT/DWbYX8IHcNO48XWPr3m68dNkuW2lUdP1zNlyhkH/20X0ZftalZuWpWPgz5+yP/sjAqpGMbpHlRKv0C4v5JBOKfj5+RWsei1cWTKfXq/HyalsL+n777/PlStXiI6OxsXFhWvXrrFt27YSP98UMUgmZMc9/HxOKifebfcuTfya0MSvCaeD3Zj4VzSD5uwitFsdxvWqj1Zj25+mLyQl8cTyt0jT7KOBR3t+GvA1ns6e1g7L4uw6Mzy/7vm77usb2JcnqnYjMzebV9bfvbnwoHqDGFxvMElZSYzfOv62x37sV8IVlIU899xzaLVaDh06ROfOnalQocJtbwTNmjVjzZo1BAYGsnjxYmbNmkVOTg7t27fn22+/va22TkZGRkH1yfwaLZUqVeLxxx8HbpUcBli2bBlr1qxh0aJFd8WwYsUKIiMj8fb2BqB+/frs3LkTlUpVZNllyYzU9t3DL2xA3QEA1PWGLYn/42Ssmrlb9YQdjmPiI43p16yyTfaYd8Uk8PKWZzBoLvNItef4pNcbdl3iuCzK529tyLXoDJ3Y2Fh27959WznfOx0/fpzff/+dXbt2ERkZiVqtLqj7ki8mJoaaNWveVf+ltDEMGjSooFrn3r17qVWrFpUqVSq27LJkRgU9/ETrxmFCeoMetUrhjH4lQW1/wUWbyMtLDjLy+3CbGubJ1ufwv82n+c+CfXhk9WZqu1l89tCbDpvswc57+MX2yG+cw9XJ7Z49dh+tzwP16IsyfPjw++7CtGnTJg4cOEDbtm0ByMzMpGLFiiZp/84YRowYwbRp03j++edZunRpQWnh4sou29K2jeWOUBm/ykEPP5+TyomPun5Etxrd+HDPh2T4fkTvOkPYF9mK/rN30qdJJcY9VJ+mVS1TiK1wiYj8jVyONo/ns4hPuHm1M48EDeSTYX3xcLHrdGcS5fMVUMxbKfNOhUv3Ojk5FRQuAwpKIyuKwrPPPntbMbM71atXj4sXL5KamlpkL7/wx+X88xYVQ8eOHYmJiSEhIYG//vqLSZMmAWUruyyVgVBDevlbsdovsB9tKrXhq4iv2Bq7jr/GhrL6wE1+2HmW9bOu0bNRRZ7tFEjXev6oVOYZ6olaEkVYaBi6vDUC5/RXefHMFDL0pyDXjxc6BvNu95Y2OdRkDeXzs42ZSyPfS2BgYEFJ4oMHDxZUY+zVqxfLli0jPj4egBs3bnDhwoXbnuvm5sYLL7zAuHHjCmb9JCQk8OeffwLG8fzjx49jMBgKhmyKIoRgyJAhjB8/nsaNG+PnZ5w3XVzZZcnMhMquL9rei7+rPx91/YiwwWHU9qnMa73q0af7JoZ0TuJwbDLPLtzHQ19tY/72M8QlZ5q8/U0TN6HL0JHsq+Xf16+yafo/pNc4i/eJLmwasYYJIYNlsi+kfPbwzVwa+V6GDRvGzz//TNOmTWnfvn1Bed8mTZowffp0+vTpg8FgQKPRMGfOHGrVqnXb86dPn86kSZNo0qQJWq0Wd3d3pk2bBsAnn3xC//79CQgIoE2bNgUXcIsyYsQI2rZty6JFiwruK67ssmRmaie4cdbaUZiVn6uxUxGfEc/J5GNcSP2HOs3q0Nu9H8dO1+ejtSf4aO0J2gb60LdpZTrX86dhJc8y9fzPJaSxvmUi8b0CuR5QGY2rCt/TabRcWocq51RU/FgOVd6pTOWRhRDDgSlAY6CdoigRxRzXD/gGUAM/KIpy353Cy1Qe+coRcPWRpZElm3A8ci+N/+oDb8WAR4C1wzE7vUHP2nNr+fX4rxxNPIqrkyufdvye6HNuhB2J49Q1Y0fFz92ZVrV8aFjJkwaVPQn0c8PX3Rk/dxdcndUYDAq5ikJ6tp645CyupmYScy2NXZeOcDR5DxnOEahdElCd6UHdDU1pcOQ6rhnGNThetbx4/fzr1nwZrMac5ZGjgaHAd/doXA3MAXoDscB+IcRqRVGOFfecMlEUi4/hS9I95W98fSUS6ve2biwW4KRyYmDdgQysO5Do69GsPL2SzrUa06OOM87+m9l1eR/uSm1uplTmdHwKm09qyM29PRUJAYpiQKjTQaVD0fkCCu51vkTlch08BTW0jeieMRj9rGSUlKsFz9W4aeg1o5eFf2v7UKaEryjKcbjvfqLtgBhFUc7mHbsUGASYKeHLOjqSjVE7AwLiDpUs4eekw7HVkHAc4k9A6mWzh2guzfK+iFwHgNYpmywnHVFiH3oB+EBdL8Hqm27ocg184JbNcSeFLKGQpAKDgKY6wfybWjQqwVyho3a2lq65TvhnXAZ+J/OdTNKuppGbk4vaWY1HZQ9cU/+Gudb7vcusYhMY9r3JT2uJMfxqwKVCt2OB9kUdKIQIBUKBIrfvKxEF0HqBk+uDPV+STE2owL++MeGXxIpQOLHG+EbhVx98ahnPUQ48m/eVpRg4oWRyQTFuZ6mt6IsWaKC/hkbJxgVBgNAQIJyopXGhgodxVez4Is7p6gOudSz1G1hIhSpmOe19E74QYiNQuYiHJiqKssqUwSiKMh+YD8Yx/Ac6idoJfMvbv75k96q2hHPb73/chd3GZN99AnR7+9ZK3XJGCwTnfRX2shVicST3/WtSFOWhMrZxGSh89bR63n2S5DiqBMOR3yH1SvG9N0WB9ZOgQjXo8nq5TfaS9Vjic+J+oL4QorYQwhl4AlhtgXYlyXZUbWn8fuUeax+OroDLB6DHRNDIIUnJ9MqU8IUQQ4QQsUBH4G8hxL9591cVQqwFUBRFD4wF/gWOA38oinK0bGFb14wZM2jatCnNmzcnODiYvXv3mq2tkJAQ7pyeKtmhykHGcfi4YhK+Phs2ToVKzaDFE5aNTXIYZZ2lsxK4a8mnoihxwCOFbq8F1palrQdRVI2NoKeCynTOPXv2sGbNGg4ePIiLiwvXltnY3wAAB+xJREFUr183WS18qRxz8QD/hsVfuN2/AJIvwNMr5AwzyWzKx6X/IuTX2Ei5kAIKpFxIISw0jKglUWU675UrV/D39y8oX+zv70/VqlWZNm0abdu2pVmzZoSGhpK/oC0kJIQ33niDNm3a0LhxY/bv38/QoUOpX79+QY2b8+fP06hRI5566ikaN27MY489RkZGxl1tr1+/no4dO9KqVSuGDx9esNJ2woQJNGnShObNm99Wn1+yMVVbGhP+nYsds9Ngx5dQuzvUk/PHJfMptwk/v8ZGYboMHZsmbirTefv06cOlS5do0KABr7zySsHmJGPHjmX//v1ER0eTmZnJmjVrCp7j7OxMREQEo0ePZtCgQcyZM4fo6GgWLVpEYqKxbO7Jkyd55ZVXOH78OBUqVODbb7+9rd3r168zffp0Nm7cyMGDB2nTpg1fffUViYmJrFy5kqNHj3LkyJGCNxHJBlVtCenxkBp3+/375hurafZ83zpxSQ6j3Cb8lItF1+Uu7v6S8vDw4MCBA8yfP5+AgABGjBjBokWL2LJlC+3btycoKIjNmzdz9OityxQDBw4EICgoiKZNm1KlShVcXFyoU6cOly4ZlyjUqFGjYDOSp59+mp07d97Wbnh4OMeOHaNz584EBwfz008/ceHCBby8vNBqtbzwwgusWLECNze3Mv1+khnlX7gtPKyTlQK7voH6faFGW+vEJTmMcjvvy6uml3E4p4j7y0qtVhMSEkJISAhBQUF89913HDlyhIiICGrUqMGUKVNuK1+cP/yjUqkKfs6/rdcba3/cuVr5ztuKotC7d29+++23u+LZt28fmzZtYtmyZfzvf/9j8+bNZf4dJTOo3MxYKjnuEDTub7wvfC5kJUOP/1o3NskhlNsefq8ZvdC4aW67zxQ1Nk6ePMnp06cLbkdGRtKwYUPAOJ6flpbGsmXLSn3eixcvsmfPHgB+/fVXunTpctvjHTp0YNeuXcTExACQnp7OqVOnSEtLIyUlhUceeYSvv/6aw4cPP+ivJpmbxtW4ZP54GBxbBUkXYM8caNQfqt65BEmSTK/c9vDzZ+OYepZOWloar776KsnJyTg5OVGvXj3mz5+Pt7c3zZo1o3LlygW7WpVGw4YNmTNnDqNGjaJJkya8/PLtaw4DAgJYtGgRI0eOJDvbuBx9+vTpeHp6MmjQILKyslAU5Z7bLEo2oPWzsOlD+OOZvDuE7N1LFlOm8sjmVKbyyHbm/Pnz9O/fn+joaGuHIpnBXX+3uXqI3Q8xG8C9InQYbb3gpHLHnOWRJUkqLbUT1Opo/JIkCyq3Y/j2JDAwUPbuJUkyO7tL+LY6BCVJRZF/r5ItsauEr9VqSUxMlP+JJLugKAqJiYlotVprhyJJgJ2N4VevXp3Y2FgSEhKsHYoklYhWq6V69erWDkOSADtL+BqNhtq1a1s7DEmSJLtkV0M6kiT9f3v382JVHYdx/P00GtX0w4USgyPpItq0SBE3hkRRGEm1LKhFmzYVRouoNtE/EO2CmDGMLAlNiIh+QEK1qHTMEB0LEcORYoyIso1UT4t7FhM0SOce+d7zvc8LhrnnDnN4Pgzzme/9nO+ZG9FeGn5ExJhIw4+IGBMje6etpPPAD0OcYjXwc0dxSqqlDkgto6qWWmqpA4ar5Sbba/7rCyPb8Icl6fBytxf3SS11QGoZVbXUUksdcPlqyUgnImJMpOFHRIyJmhv+a6UDdKSWOiC1jKpaaqmlDrhMtVQ7w4+IiH+reYUfERFLpOFHRIyJ6hq+pO2SvpN0StJzpfO0JWmXpEVJvf9H+ZLWSToo6YSk45J2ls7UhqSrJH0t6dumjpdKZxqWpAlJ30h6v3SWYUg6I+mYpKOSDl/6O0aXpFWS9kk6KWleUmfvlFPVDF/SBPA9cDewABwCHrZ9omiwFiRtAy4Ab9i+tXSeYUiaAqZsH5F0HTAHPNi3n4skAZO2L0haCXwB7LT9ZeForUl6BtgMXG97R+k8bUk6A2y23fsbryTtBj63PSPpSuAa2792ce7aVvhbgFO2T9u+COwFHiicqRXbnwG/lM7RBds/2j7SPP4dmAfWlk31/3ngQnO4svno7YpJ0jRwHzBTOksMSLoB2AbMAti+2FWzh/oa/lrg7JLjBXrYWGomaT2wEfiqbJJ2mhHIUWAR+MR2L+tovAI8C/xdOkgHDHwsaU7S46XDDGEDcB54vRm1zUia7OrktTX8GGGSrgX2A0/b/q10njZs/2X7NmAa2CKpl+M2STuARdtzpbN05Hbbm4B7gSeakWgfrQA2Aa/a3gj8AXR2LbK2hn8OWLfkeLp5LgprZt77gT223y2dZ1jNy+yDwPbSWVraCtzfzL73AndKerNspPZsn2s+LwIHGIx3+2gBWFjyynEfgz8Anait4R8Cbpa0obnY8RDwXuFMY6+52DkLzNt+uXSetiStkbSqeXw1g80BJ8umasf287anba9n8Hvyqe1HCsdqRdJksxmAZvxxD9DL3W22fwLOSrqleeouoLPNDb16i8NLsf2npCeBj4AJYJft44VjtSLpbeAOYLWkBeBF27NlU7W2FXgUONbMvwFesP1BwUxtTAG7m91gVwDv2O71dsZK3AgcGKwrWAG8ZfvDspGG8hSwp1m0ngYe6+rEVW3LjIiI5dU20omIiGWk4UdEjIk0/IiIMZGGHxExJtLwIyLGRBp+RMSYSMOPiBgT/wBCZiZo6oeYwwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afP-_-aAthde"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}