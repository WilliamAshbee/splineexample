{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_mcfixed.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNnwq+UdowDGt/ZASwQB3ec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/LSTM_mcfixed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GuTzOJ5E0oN"
      },
      "source": [
        "With progressive growing of the sequence, the loss drops more stably. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E5VVeE0nEn4"
      },
      "source": [
        "https://r2rt.com/non-zero-initial-states-for-recurrent-neural-networks.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPJLPR-jCBtx",
        "outputId": "4ada2338-4157-46cb-b46f-dda6ee0ce22e"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from skimage import filters\n",
        "import math\n",
        "\n",
        "global numpoints\n",
        "numpoints = 1000\n",
        "side = 32\n",
        "\n",
        "rows = torch.zeros(32,32)\n",
        "columns = torch.zeros(32,32)\n",
        "\n",
        "\n",
        "for i in range(32):\n",
        "    columns[:,i] = i\n",
        "    rows[i,:] = i\n",
        "\n",
        "\n",
        "def donut_matrix(length = 10):\n",
        "    radiusMax = side /3\n",
        "    w = 1\n",
        "    sigmas = [None, 1]\n",
        "    \n",
        "    canvas = torch.zeros((length,side, side))\n",
        "    r0 = torch.tensor(np.random.uniform(side/4, side/3, length))\n",
        "\n",
        "    radii = torch.zeros((length,numpoints))\n",
        "    radii[:, :] = r0.unsqueeze(1)\n",
        "    \n",
        "    ind = [x for x in range(numpoints)]\n",
        "\n",
        "    theta = torch.FloatTensor(ind)\n",
        "    theta *= math.pi*2.0/(float)(numpoints)\n",
        "    \n",
        "    for i in range(1,length):\n",
        "        a = np.random.uniform(1.0,3.0)*torch.sin(np.random.uniform(20.0)*theta+np.random.uniform(1000.0))\n",
        "        #a = 4.0*torch.sin(10.0*theta)\n",
        "        #print(a.shape,torch.max(a))\n",
        "        radii[i,:] += a\n",
        "        #print(radii.shape, torch.max(radii))\n",
        "    \n",
        "    assert torch.min(radii)>0\n",
        "    #print(radii.max(axis = 0)[0].shape)\n",
        "    rmaxs = radii.max(axis = 1)[0]\n",
        "    pmins = rmaxs+1.0\n",
        "    pmaxs = side-rmaxs-1.0\n",
        "    x0 = np.random.uniform(pmins,pmaxs)\n",
        "    y0 = np.random.uniform(pmins,pmaxs)\n",
        "    x0[:]=side/2\n",
        "    y0[:]=side/2\n",
        "    x0 = torch.tensor(x0)\n",
        "    y0 = torch.tensor(y0)\n",
        "    \n",
        "    x0 = x0.unsqueeze(1)\n",
        "    y0 = y0.unsqueeze(1)\n",
        "    #radii = torch.from_numpy(radii)\n",
        "    xrfactors = torch.cos(theta).unsqueeze(0)\n",
        "    yrfactors = torch.sin(theta).unsqueeze(0)\n",
        "    \n",
        "    print('x0_y0_r_xrf_yrf',x0.shape,y0.shape,radii.shape,xrfactors.shape,yrfactors.shape)\n",
        "\n",
        "    x = (x0+(xrfactors*radii))\n",
        "    y = (y0+(yrfactors*radii))\n",
        "    assert x.shape == (length,numpoints)\n",
        "    assert y.shape == (length,numpoints)\n",
        "    assert torch.sum(x[x>(side-1)])==0 \n",
        "    assert torch.sum(x[x<0])==0 \n",
        "    assert torch.sum(y[y>(side-1)])==0 \n",
        "    assert torch.sum(y[y<0])==0 \n",
        "    \n",
        "    points = torch.zeros(length,numpoints,2)\n",
        "    for l in range(length):\n",
        "        canvas[l,y[l,:].type(torch.LongTensor),x[l,:].type(torch.LongTensor)]=1.0\n",
        "        points[l,:,0] = x[l,:]#modified for lstm discriminator\n",
        "        points[l,:,1] = y[l,:]#modified for lstm discriminator \n",
        "    \n",
        "    \n",
        "    return {\n",
        "        'canvas': canvas, \n",
        "        'points':points.type(torch.FloatTensor)}\n",
        "\n",
        "\n",
        "def plot_all( sample = None, model = None, labels = None):\n",
        "    img = sample[:,:].squeeze().cpu().numpy()\n",
        "    #img = img.T\n",
        "    plt.imshow(img, cmap=plt.cm.gray_r)\n",
        "    if model != None:\n",
        "        with torch.no_grad():\n",
        "          global numpoints\n",
        "          sample = sample.unsqueeze(0).cuda()\n",
        "          labels = labels.unsqueeze(0).cuda()\n",
        "\n",
        "          #print('samplelabel',sample.shape,labels.shape)\n",
        "          h0 = None\n",
        "          c0 = None\n",
        "          X = []\n",
        "          Y = []\n",
        "          for i in range(11):\n",
        "            optimizer.zero_grad()\n",
        "            if i == 0:\n",
        "              out, h0, c0,o,output = model(sample,labels[:,0,:2],h0,c0,ind = i)\n",
        "            else:\n",
        "              out, h0, c0,o,output = model(sample,labels[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "              \n",
        "            X.extend(out.detach()[0,:,0].tolist())\n",
        "            Y.extend(out.detach()[0,:,1].tolist())\n",
        "\n",
        "          predres = len(X)\n",
        "\n",
        "          s = [.001 for x in range(predres)]\n",
        "          \n",
        "          assert len(s) == predres\n",
        "          c = ['red' for x in range(predres)]\n",
        "          assert len(c) == predres\n",
        "          #print(\"type\",type(X))\n",
        "          plt.scatter(X,Y,s = s,c = c)\n",
        "        #plt.gca().add_artist(ascatter)\n",
        "    else:\n",
        "        #print(labels.shape)\n",
        "        X = labels[:,0]\n",
        "        Y = labels[:,1]\n",
        "        #print(X.shape)\n",
        "        #print(Y.shape)\n",
        "        s = [.001 for x in range(numpoints)]\n",
        "        #print(len(s))\n",
        "        c = ['red' for x in range(numpoints)]\n",
        "        #print(len(c))\n",
        "        #ascatter = \n",
        "        plt.scatter(X.cpu().numpy(),Y.cpu().numpy(),s = s,c = c)\n",
        "        #plt.gca().add_artist(ascatter)\n",
        "\n",
        "class DonutDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Donut dataset.\"\"\"\n",
        "    def __init__(self, length = 10):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.length = length\n",
        "        self.values = donut_matrix(length)\n",
        "        assert self.values['canvas'].shape[0] == self.length\n",
        "        assert self.values['points'].shape[0] == self.length\n",
        "        \n",
        "        count = 0\n",
        "        for i in range(self.length):\n",
        "          a = self[i]\n",
        "          c = a[0]\n",
        "          for el in a[1]:\n",
        "            #print(c[(int)(el[1]),(int)(el[0])].item())\n",
        "            #assert c[(int)(el[1]),(int)(el[0])].item() == 1\n",
        "            y,x = (int)(el[1]),(int)(el[0])\n",
        "            if x < side-2 and x > 2 and y < side-2 and y > 2: \n",
        "              if c[y,x] != 1 and \\\n",
        "                c[y+1,x] != 1 and c[y+1,-1+x] != 1 and c[y+1,1+x] != 1 and \\\n",
        "                c[y-1,x] != 1 and c[y,-1+x] != 1 and c[y,1+x] != 1:\n",
        "                count+=1\n",
        "        assert count ==0\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        canvas = self.values[\"canvas\"]\n",
        "        \n",
        "        canvas = canvas[idx,:,:]\n",
        "        assert canvas.shape == (side,side)\n",
        "        \n",
        "        points = self.values[\"points\"]\n",
        "        points = points[idx,:]\n",
        "        #points = points.unsqueeze(1)\n",
        "        #z = torch.zeros(numpoints,1)\n",
        "        #print(z.shape)\n",
        "        #points = torch.cat([points,z], dim = 1)\n",
        "        \n",
        "        #print('points', points.shape)\n",
        "        return canvas, points\n",
        "    \n",
        "    @staticmethod\n",
        "    def displayCanvas(title,dataset, model):\n",
        "        #model.setBatchSize(batch_size = 1)\n",
        "        if model != None:\n",
        "          model = model.eval()\n",
        "        for i in range(100):\n",
        "            sample, labels = dataset[i]\n",
        "            plt.subplot(10,10,i+1)\n",
        "            plot_all(sample = sample,model=model, labels = labels)\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.savefig(title,dpi=450)\n",
        "        plt.clf()\n",
        "        plt.cla()\n",
        "        plt.close()#should free memory\n",
        "        print('open file: ',title)\n",
        "dataset = DonutDataset(length = 100)\n",
        "\n",
        "DonutDataset.displayCanvas('donut.png',dataset, model = None)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0_y0_r_xrf_yrf torch.Size([100, 1]) torch.Size([100, 1]) torch.Size([100, 1000]) torch.Size([1, 1000]) torch.Size([1, 1000])\n",
            "open file:  donut.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw7yd6GJX9rM",
        "outputId": "ffb779ff-acf0-46a4-ea6e-14b4da183bec"
      },
      "source": [
        "for i in range(100):\n",
        "  print(torch.sum(dataset[i][0]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(76.)\n",
            "tensor(92.)\n",
            "tensor(147.)\n",
            "tensor(121.)\n",
            "tensor(91.)\n",
            "tensor(77.)\n",
            "tensor(256.)\n",
            "tensor(171.)\n",
            "tensor(133.)\n",
            "tensor(130.)\n",
            "tensor(129.)\n",
            "tensor(86.)\n",
            "tensor(92.)\n",
            "tensor(172.)\n",
            "tensor(74.)\n",
            "tensor(74.)\n",
            "tensor(69.)\n",
            "tensor(84.)\n",
            "tensor(117.)\n",
            "tensor(102.)\n",
            "tensor(153.)\n",
            "tensor(135.)\n",
            "tensor(188.)\n",
            "tensor(215.)\n",
            "tensor(88.)\n",
            "tensor(75.)\n",
            "tensor(75.)\n",
            "tensor(196.)\n",
            "tensor(157.)\n",
            "tensor(190.)\n",
            "tensor(87.)\n",
            "tensor(103.)\n",
            "tensor(86.)\n",
            "tensor(108.)\n",
            "tensor(141.)\n",
            "tensor(115.)\n",
            "tensor(104.)\n",
            "tensor(89.)\n",
            "tensor(230.)\n",
            "tensor(258.)\n",
            "tensor(133.)\n",
            "tensor(145.)\n",
            "tensor(92.)\n",
            "tensor(79.)\n",
            "tensor(104.)\n",
            "tensor(139.)\n",
            "tensor(89.)\n",
            "tensor(177.)\n",
            "tensor(107.)\n",
            "tensor(119.)\n",
            "tensor(198.)\n",
            "tensor(125.)\n",
            "tensor(139.)\n",
            "tensor(110.)\n",
            "tensor(179.)\n",
            "tensor(111.)\n",
            "tensor(117.)\n",
            "tensor(240.)\n",
            "tensor(192.)\n",
            "tensor(157.)\n",
            "tensor(85.)\n",
            "tensor(95.)\n",
            "tensor(94.)\n",
            "tensor(98.)\n",
            "tensor(228.)\n",
            "tensor(215.)\n",
            "tensor(159.)\n",
            "tensor(180.)\n",
            "tensor(89.)\n",
            "tensor(103.)\n",
            "tensor(88.)\n",
            "tensor(72.)\n",
            "tensor(93.)\n",
            "tensor(243.)\n",
            "tensor(241.)\n",
            "tensor(110.)\n",
            "tensor(121.)\n",
            "tensor(74.)\n",
            "tensor(128.)\n",
            "tensor(102.)\n",
            "tensor(135.)\n",
            "tensor(164.)\n",
            "tensor(180.)\n",
            "tensor(96.)\n",
            "tensor(124.)\n",
            "tensor(91.)\n",
            "tensor(240.)\n",
            "tensor(84.)\n",
            "tensor(133.)\n",
            "tensor(82.)\n",
            "tensor(161.)\n",
            "tensor(92.)\n",
            "tensor(224.)\n",
            "tensor(92.)\n",
            "tensor(86.)\n",
            "tensor(176.)\n",
            "tensor(87.)\n",
            "tensor(160.)\n",
            "tensor(92.)\n",
            "tensor(183.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLdlZuLz1fPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63726f3-8dfa-4bfc-9041-fd05af2ee3f0"
      },
      "source": [
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 64\n",
        "test_dataset = DonutDataset(length = 64)\n",
        "loader_test = data.DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=test_dataset),\n",
        "    num_workers=4)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0_y0_r_xrf_yrf torch.Size([64, 1]) torch.Size([64, 1]) torch.Size([64, 1000]) torch.Size([1, 1000]) torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhiJIwh0PvXT",
        "outputId": "3a0b24cc-1fb8-43ca-9a1e-11d84fa000a6"
      },
      "source": [
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 64\n",
        "dataset = DonutDataset(length = 64*20)\n",
        "loader_train = data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=dataset),\n",
        "    num_workers=4)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0_y0_r_xrf_yrf torch.Size([1280, 1]) torch.Size([1280, 1]) torch.Size([1280, 1000]) torch.Size([1, 1000]) torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHTtTB_x75NA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.track = 0\n",
        "        # define the properties\n",
        "        self.embed_size = 2\n",
        "        self.hidden_size = 256\n",
        "        self.num_layers = 2\n",
        "        self.seq_len = 50\n",
        "        self.lm_len = 20\n",
        "        self.full_len = 1000\n",
        "        self.longtermMem = None\n",
        "        self.longtermMemP = None\n",
        "        self.lstm_cell = nn.LSTM(self.hidden_size, self.hidden_size,self.num_layers)\n",
        "\n",
        "        self.inject_image =  nn.Sequential(\n",
        "            nn.Linear(2*1000+1024+3*self.hidden_size,self.hidden_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        \n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Linear(2+self.hidden_size*4,10000),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(10000,2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.hi_1 = nn.Sequential(\n",
        "            nn.Linear(2+1024+self.hidden_size*2,self.hidden_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.hi_2 = nn.Sequential(\n",
        "            nn.Linear(2+1024+self.hidden_size*2,self.hidden_size),\n",
        "            nn.Tanh()\n",
        "        \n",
        "        )\n",
        "\n",
        "        self.ci_1 = nn.Sequential(\n",
        "            nn.Linear(2+1024+self.hidden_size*2,self.hidden_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.ci_2 = nn.Sequential(\n",
        "            nn.Linear(2+1024+self.hidden_size*2,self.hidden_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.alpha_1 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size,self.seq_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        \n",
        "        self.alpha_long1 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size,self.lm_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        \n",
        "\n",
        "        self.embs = None #= torch.empty((self.batch_size, 1000, self.hidden_size)).cuda()\n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "            \n",
        "        \n",
        "    def forward(self, features,p0,h0 = None, c0= None, ind = 0, o = None,output = None):\n",
        "        assert features != None\n",
        "        #assert captions != None\n",
        "        #print('featursescaptions2',features.shape,captions.shape)\n",
        "        #assert features.shape[0]==captions.shape[0]\n",
        "        assert len(features.shape) == 3\n",
        "        self.track +=1\n",
        "        batch_size = features.shape[0]\n",
        "        \n",
        "\n",
        "        #img_emb = torch.empty((batch_size, captions.size(1), self.hidden_size)).cuda()\n",
        "        \n",
        "        p0 = torch.flatten(p0[:,:2],start_dim=1)\n",
        "        \n",
        "\n",
        "        if o == None:\n",
        "          out = p0\n",
        "          self.longtermMem = torch.zeros(batch_size,self.lm_len,self.hidden_size).cuda()\n",
        "          self.embs = torch.empty((batch_size, self.seq_len, self.hidden_size)).cuda()\n",
        "          self.longtermMemP = torch.zeros(batch_size,1000,2).cuda()\n",
        "        else:\n",
        "          out = o\n",
        "\n",
        "        \n",
        "        if h0 == None and c0 == None:\n",
        "          combin_init = torch.cat([torch.flatten(features,start_dim=1),out,torch.zeros(batch_size,self.hidden_size).cuda(),torch.zeros(batch_size,self.hidden_size).cuda()],dim=1)\n",
        "          h_0_1 = self.hi_1(combin_init)  \n",
        "          h_0_2 = self.hi_2(combin_init)  \n",
        "          c_0_1 = self.ci_1(combin_init)  \n",
        "          c_0_2 = self.ci_2(combin_init)  \n",
        "          \n",
        "          h0 = torch.stack([h_0_1,h_0_2],dim = 0)\n",
        "          c0 = torch.stack([c_0_1,c_0_2],dim = 0)\n",
        "        #else:\n",
        "          #combin_init = torch.cat([torch.flatten(features,start_dim=1),out,output.view(batch_size,self.hidden_size),h0[0,:,:]],dim=1)\n",
        "          #h_0_1 = self.hi_1(combin_init)  \n",
        "          \n",
        "          #combin_init = torch.cat([torch.flatten(features,start_dim=1),out,output.view(batch_size,self.hidden_size),h0[1,:,:]],dim=1)\n",
        "          #h_0_2 = self.hi_2(combin_init)  \n",
        "          \n",
        "          #combin_init = torch.cat([torch.flatten(features,start_dim=1),out,output.view(batch_size,self.hidden_size),c0[0,:,:]],dim=1)\n",
        "          #c_0_1 = self.ci_1(combin_init)  \n",
        "          \n",
        "          #combin_init = torch.cat([torch.flatten(features,start_dim=1),out,output.view(batch_size,self.hidden_size),c0[1,:,:]],dim=1)\n",
        "          #c_0_2 = self.ci_2(combin_init)\n",
        "          \n",
        "          #h0 = torch.stack([h_0_1,h_0_2],dim = 0)\n",
        "          #c0 = torch.stack([c_0_1,c_0_2],dim = 0)\n",
        "        \n",
        "        hidden_state = h0\n",
        "        cell_state = c0\n",
        "        outputs = torch.empty((batch_size, self.seq_len, 2)).cuda()\n",
        "        \n",
        "        output = None\n",
        "\n",
        "        for t in range(self.seq_len):\n",
        "        \n",
        "            # for the first time step the input is the feature vector\n",
        "            if output == None:\n",
        "              output = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              outesread1 = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              outesreadl1 = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "            \n",
        "            #print('1',torch.flatten(features,start_dim=1).shape,torch.flatten(self.longtermMemP,start_dim=1).shape,output.squeeze().shape,)\n",
        "            \n",
        "            combin_lstm = torch.cat([torch.flatten(features,start_dim=1),torch.flatten(self.longtermMemP,start_dim=1),output.view(batch_size,self.hidden_size),outesread1,outesreadl1],dim=1)\n",
        "            combin_lstm = self.inject_image(combin_lstm)\n",
        "            \n",
        "            a1 = self.alpha_1(combin_lstm)\n",
        "            #print('a1',a1.shape,a1.unsqueeze(2).shape,self.embs.shape,outesread1.shape)\n",
        "            outesreada1 = self.embs.clone()*a1.unsqueeze(2)#clone\n",
        "            outesread1 = torch.sum(outesreada1,dim=1)\n",
        "            \n",
        "            #print('122',self.longtermMem.shape,outesread1.shape)\n",
        "            #print('ind',ind)\n",
        "            self.longtermMem[:, ind, :] = (outesread1).detach()\n",
        "            \n",
        "            al1 = self.alpha_long1(combin_lstm)\n",
        "            outesreadal1 = self.longtermMem.clone()*al1.unsqueeze(2)#clone\n",
        "            outesreadl1 = torch.sum(outesreadal1,dim=1)\n",
        "            \n",
        "            output, (hidden_state, cell_state) = self.lstm_cell(combin_lstm.unsqueeze(0), (hidden_state, cell_state))\n",
        "\n",
        "            outputs[:, t, :] = out\n",
        "            self.longtermMemP[:,50*ind+t,:] = out.detach()\n",
        "            \n",
        "            self.embs[:, t, :] = output.view(batch_size,self.hidden_size).clone().detach()\n",
        "            \n",
        "\n",
        "            \n",
        "            a1 = self.alpha_1(combin_lstm)\n",
        "            outesreada1 = self.embs.clone()*a1.unsqueeze(2)#clone\n",
        "            outesread1 = torch.sum(outesreada1,dim=1)\n",
        "            \n",
        "            self.longtermMem[:, ind, :] = (outesread1).detach()\n",
        "            \n",
        "            al1 = self.alpha_long1(combin_lstm)\n",
        "            outesreadal1 = self.longtermMem.clone()*al1.unsqueeze(2)#clone\n",
        "            outesreadl1 = torch.sum(outesreadal1,dim=1)\n",
        "            \n",
        "            \n",
        "\n",
        "            \n",
        "            combOut = torch.cat([combin_lstm, output.view(batch_size,self.hidden_size),out,outesread1,outesreadl1],dim=1)#,outesread],dim=1)\n",
        "            \n",
        "\n",
        "            out = self.fc_out(combOut)\n",
        "            out = out*32.0\n",
        "            # build the output tensor\n",
        "        \n",
        "        #self.embs = self.embs.detach().clone()\n",
        "        return outputs, hidden_state.detach(), cell_state.detach(), out.detach(),output.detach()#, captions\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQFUAWiTrbcv"
      },
      "source": [
        "#torch.stack([torch.zeros(64,10),torch.ones(64,10)],dim = 0)[0,:,:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xifd43C1tUXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f45b865-60aa-4bdc-8ba2-e307ec92f99c"
      },
      "source": [
        "a = torch.ones(64,256,50)\n",
        "b = torch.from_numpy(np.random.randn(50))\n",
        "c = a*b\n",
        "print(c[0,1,:])\n",
        "print(c[1,1,:])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.2895,  1.4533, -0.1549,  0.2255, -0.1193, -0.2180, -0.2221,  0.5888,\n",
            "        -0.4340,  0.4630, -0.5141,  0.5818,  0.7152, -1.3863,  0.5177,  0.4948,\n",
            "         0.4553,  1.7217, -0.9780,  0.0247,  0.2858,  0.9300, -0.3600, -0.0984,\n",
            "        -0.2104,  2.1738, -0.6221, -0.4916,  1.4020, -0.7003, -1.8666,  0.8654,\n",
            "        -0.3302,  0.6693, -0.0552, -0.4083,  0.4083, -1.2317, -1.4357,  0.6407,\n",
            "        -0.3556,  0.4375,  0.3853,  0.0066, -1.5084,  0.8754,  0.9280, -0.1872,\n",
            "         1.4183,  0.2169], dtype=torch.float64)\n",
            "tensor([-1.2895,  1.4533, -0.1549,  0.2255, -0.1193, -0.2180, -0.2221,  0.5888,\n",
            "        -0.4340,  0.4630, -0.5141,  0.5818,  0.7152, -1.3863,  0.5177,  0.4948,\n",
            "         0.4553,  1.7217, -0.9780,  0.0247,  0.2858,  0.9300, -0.3600, -0.0984,\n",
            "        -0.2104,  2.1738, -0.6221, -0.4916,  1.4020, -0.7003, -1.8666,  0.8654,\n",
            "        -0.3302,  0.6693, -0.0552, -0.4083,  0.4083, -1.2317, -1.4357,  0.6407,\n",
            "        -0.3556,  0.4375,  0.3853,  0.0066, -1.5084,  0.8754,  0.9280, -0.1872,\n",
            "         1.4183,  0.2169], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50cqsTMxQXEm"
      },
      "source": [
        "model = DecoderRNN().cuda()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32G-MJC_QcKP"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, betas = (.9,.999))#ideal\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60xL8p9QeQc-"
      },
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjpFwX8MQlPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d4df293-6f29-414b-8ff9-0d4e390620d6"
      },
      "source": [
        "model = model.train()\n",
        "for seql in range(3,12,4):\n",
        "  #seql = 19\n",
        "  for epoch in range (2):\n",
        "    loss = None\n",
        "    for x,y in loader_train:\n",
        "      h0 = None\n",
        "      c0 = None\n",
        "      for i in range(seql):\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "        loss = torch.mean((out-y[:,1+(50*i):1+(50*(i+1)),:2])**2)\n",
        "        #writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      #print(y[:,0,:2])\n",
        "      print('epoch',epoch,'seql',seql)\n",
        "      print(loss)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 seql 3\n",
            "tensor(21.3183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(45.5222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(10.1346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(11.9310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(5.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(6.5005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.9395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(7.1837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(5.0093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(6.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.8787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.5582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.4280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.2294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.2990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(4.0395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "tensor(3.7534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.9065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.9507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.9658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.6109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.7257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.6291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.9264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.8671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.5869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.9786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.4690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.7415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.6315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.6382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.5222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.5853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.5592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.1870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.5496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "tensor(3.4140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(5.2924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(36.1640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(30.9067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(180.5103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(11.7874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(7.2744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(12.1874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(9.5353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(5.4630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(4.7226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(4.1594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(4.4777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(6.4226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(4.0708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(3.1471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(3.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(2.9708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(3.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(3.2569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "tensor(3.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.9679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.9633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(3.0570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.7762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(3.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.9269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.9106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.8246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.6466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.5790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.7784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.7003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.6738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.5622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.9745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(3.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.8908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.8271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "tensor(2.9316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(8.2873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(32.0706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(29.6011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(6.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(14.6757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(6.8291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(11.9656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(17.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(12.9526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(6.4723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(5.6583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(3.3304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(4.3175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(4.0285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(2.9815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(3.4617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(2.1199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(2.5487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(2.3043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(2.5513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(2.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(2.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(2.1879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.9701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(2.0647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.9421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(2.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.8721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(2.0890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.9558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.7963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.8062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(2.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.6943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.8195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.9728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.9224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(2.0193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.8407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "tensor(1.8241, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWZWJn4i_R5x"
      },
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, betas = (.9,.999))#ideal\n",
        "\n",
        "for g in optimizer.param_groups:\n",
        "    g['lr'] = 0.0001\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV5RNgqjYMgZ",
        "outputId": "497e2767-f552-4d56-853f-53dc52b14148"
      },
      "source": [
        "\n",
        "model = model.train()\n",
        "#for seql in range(15,20,4):\n",
        "seql = 11\n",
        "for epoch in range (1):\n",
        "  loss = None\n",
        "  for x,y in loader_train:\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    for i in range(seql):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      if i == 0:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "      else:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "      loss = torch.mean((out-y[:,1+(50*i):1+(50*(i+1)),:2])**2)\n",
        "      writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #print(y[:,0,:2])\n",
        "    print('epoch',epoch,'seql',seql)\n",
        "    print(loss)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 seql 11\n",
            "tensor(1.9591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.8255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.8264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.8089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.8735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.8242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.9434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(2.1315, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuGEdcCjYLK5"
      },
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(),lr = 0.00001, betas = (.9,.999))#ideal\n",
        "for g in optimizer.param_groups:\n",
        "    g['lr'] = 0.00001\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXg-Ue7XkTAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5618c2-5de9-4f6b-d27c-fca327ad8b94"
      },
      "source": [
        "\n",
        "model = model.train()\n",
        "#for seql in range(15,20,4):\n",
        "seql = 11\n",
        "for epoch in range (1):\n",
        "  loss = None\n",
        "  for x,y in loader_train:\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    for i in range(seql):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      if i == 0:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "      else:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "      loss = torch.mean((out-y[:,1+(50*i):1+(50*(i+1)),:2])**2)\n",
        "      writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #print(y[:,0,:2])\n",
        "    print('epoch',epoch,'seql',seql)\n",
        "    print(loss)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 seql 11\n",
            "tensor(1.8475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.8441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.8155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.8466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.5634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.4796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.8042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.7004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "tensor(1.6233, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uo6uEemjScp"
      },
      "source": [
        "\n",
        "#optimizer.zero_grad()\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy5pDfQL_SRf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "2a04ce47-4a82-49c4-9e1c-12bab437f84a"
      },
      "source": [
        "\"\"\"model = model.train()\n",
        "for epoch in range (20):\n",
        "  loss = None\n",
        "  for x,y in loader_train:\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    for i in range(19):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      #print(x.shape,y.shape)\n",
        "      if i == 0:\n",
        "        out, h0, c0, o = model(x,y[:,i*50:50*(i+1),:2],h0,c0,ind = i)\n",
        "      else:\n",
        "        out, h0, c0, o = model(x,y[:,i*50:50*(i+1),:2],h0,c0,ind = i,o=o)\n",
        "        \n",
        "      loss = torch.mean((out-y[:,1+(50*i):1+(50*(i+1)),:2])**2)\n",
        "      writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #print(y[:,0,:2])\n",
        "    print('epoch',epoch)\n",
        "    print(loss)\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'model = model.train()\\nfor epoch in range (20):\\n  loss = None\\n  for x,y in loader_train:\\n    h0 = None\\n    c0 = None\\n    for i in range(19):\\n      x = x.cuda()\\n      y = y.cuda()\\n      \\n      optimizer.zero_grad()\\n      #print(x.shape,y.shape)\\n      if i == 0:\\n        out, h0, c0, o = model(x,y[:,i*50:50*(i+1),:2],h0,c0,ind = i)\\n      else:\\n        out, h0, c0, o = model(x,y[:,i*50:50*(i+1),:2],h0,c0,ind = i,o=o)\\n        \\n      loss = torch.mean((out-y[:,1+(50*i):1+(50*(i+1)),:2])**2)\\n      writer.add_scalar(\"Loss/train\", loss, epoch)\\n\\n      loss.backward()\\n      optimizer.step()\\n    #print(y[:,0,:2])\\n    print(\\'epoch\\',epoch)\\n    print(loss)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydanEA5r8zVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644d9db2-168b-45ea-d1c6-e3593d6974d6"
      },
      "source": [
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 32\n",
        "test_dataset = DonutDataset(length = 64*10)\n",
        "loader_test = data.DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=test_dataset),\n",
        "    num_workers=4)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0_y0_r_xrf_yrf torch.Size([640, 1]) torch.Size([640, 1]) torch.Size([640, 1000]) torch.Size([1, 1000]) torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyMGWQqsmfil"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EorbMkSA9DmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5ba1ad-eb22-4ab1-ec2f-1ed6923f0260"
      },
      "source": [
        "#model = model.eval()\n",
        "model = model.eval()\n",
        "with torch.no_grad():\n",
        "  for epoch in range (1):\n",
        "    loss = None\n",
        "    for x,y in loader_test:\n",
        "      h0 = None\n",
        "      c0 = None\n",
        "      seql = 11\n",
        "      loss = torch.zeros(seql)\n",
        "      for i in range(seql):\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        #print(x.shape,y.shape)\n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "          \n",
        "        loss[i] = torch.mean((out-y[:,1+(50*i):1+(50*(i+1)),:2])**2)\n",
        "        print(loss[i])\n",
        "        writer.add_scalar(\"Loss/val\", loss[i],i, epoch)\n",
        "        \n",
        "\n",
        "      #print(y[:,0,:2])\n",
        "      print('epoch',epoch)\n",
        "      print('test loss', torch.mean(loss))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(88.1316)\n",
            "tensor(5.0191)\n",
            "tensor(2.8130)\n",
            "tensor(1.6374)\n",
            "tensor(1.4348)\n",
            "tensor(1.6648)\n",
            "tensor(1.6568)\n",
            "tensor(1.8815)\n",
            "tensor(1.8203)\n",
            "tensor(2.4373)\n",
            "tensor(2.0038)\n",
            "epoch 0\n",
            "test loss tensor(10.0455)\n",
            "tensor(87.2928)\n",
            "tensor(4.6011)\n",
            "tensor(2.3368)\n",
            "tensor(1.5830)\n",
            "tensor(1.2786)\n",
            "tensor(1.5725)\n",
            "tensor(1.6518)\n",
            "tensor(2.0848)\n",
            "tensor(1.6403)\n",
            "tensor(2.0822)\n",
            "tensor(2.1918)\n",
            "epoch 0\n",
            "test loss tensor(9.8469)\n",
            "tensor(87.2399)\n",
            "tensor(4.6922)\n",
            "tensor(2.4241)\n",
            "tensor(1.6732)\n",
            "tensor(1.3023)\n",
            "tensor(1.3889)\n",
            "tensor(1.3976)\n",
            "tensor(1.9727)\n",
            "tensor(1.9776)\n",
            "tensor(2.0616)\n",
            "tensor(2.2286)\n",
            "epoch 0\n",
            "test loss tensor(9.8508)\n",
            "tensor(85.6565)\n",
            "tensor(4.9377)\n",
            "tensor(2.5447)\n",
            "tensor(1.7685)\n",
            "tensor(1.2545)\n",
            "tensor(2.0183)\n",
            "tensor(1.8809)\n",
            "tensor(2.4164)\n",
            "tensor(1.7244)\n",
            "tensor(2.1611)\n",
            "tensor(2.5248)\n",
            "epoch 0\n",
            "test loss tensor(9.8989)\n",
            "tensor(85.8297)\n",
            "tensor(4.3820)\n",
            "tensor(2.2922)\n",
            "tensor(1.4620)\n",
            "tensor(1.1682)\n",
            "tensor(1.5631)\n",
            "tensor(1.5772)\n",
            "tensor(1.8743)\n",
            "tensor(1.9052)\n",
            "tensor(2.3724)\n",
            "tensor(2.7437)\n",
            "epoch 0\n",
            "test loss tensor(9.7427)\n",
            "tensor(86.6645)\n",
            "tensor(4.6961)\n",
            "tensor(2.5992)\n",
            "tensor(1.7759)\n",
            "tensor(1.5956)\n",
            "tensor(1.7231)\n",
            "tensor(1.7373)\n",
            "tensor(2.0466)\n",
            "tensor(2.0104)\n",
            "tensor(2.3165)\n",
            "tensor(2.5078)\n",
            "epoch 0\n",
            "test loss tensor(9.9703)\n",
            "tensor(85.9935)\n",
            "tensor(4.5711)\n",
            "tensor(2.3802)\n",
            "tensor(1.3815)\n",
            "tensor(1.3558)\n",
            "tensor(1.5328)\n",
            "tensor(1.6842)\n",
            "tensor(2.0330)\n",
            "tensor(1.5506)\n",
            "tensor(2.0336)\n",
            "tensor(2.4444)\n",
            "epoch 0\n",
            "test loss tensor(9.7237)\n",
            "tensor(86.0413)\n",
            "tensor(4.6173)\n",
            "tensor(2.5400)\n",
            "tensor(1.6597)\n",
            "tensor(1.5987)\n",
            "tensor(1.5965)\n",
            "tensor(1.7039)\n",
            "tensor(1.8978)\n",
            "tensor(1.8278)\n",
            "tensor(2.5048)\n",
            "tensor(2.5231)\n",
            "epoch 0\n",
            "test loss tensor(9.8646)\n",
            "tensor(84.9235)\n",
            "tensor(4.3031)\n",
            "tensor(1.9894)\n",
            "tensor(1.3271)\n",
            "tensor(1.2522)\n",
            "tensor(1.3009)\n",
            "tensor(1.6953)\n",
            "tensor(2.0541)\n",
            "tensor(1.7629)\n",
            "tensor(2.1039)\n",
            "tensor(2.1211)\n",
            "epoch 0\n",
            "test loss tensor(9.5303)\n",
            "tensor(87.1010)\n",
            "tensor(4.1747)\n",
            "tensor(2.2057)\n",
            "tensor(1.7975)\n",
            "tensor(1.4196)\n",
            "tensor(1.5734)\n",
            "tensor(1.5434)\n",
            "tensor(1.7488)\n",
            "tensor(2.1879)\n",
            "tensor(1.9791)\n",
            "tensor(2.5405)\n",
            "epoch 0\n",
            "test loss tensor(9.8429)\n",
            "tensor(86.8387)\n",
            "tensor(3.8943)\n",
            "tensor(2.4630)\n",
            "tensor(1.6483)\n",
            "tensor(1.4853)\n",
            "tensor(1.4957)\n",
            "tensor(1.7148)\n",
            "tensor(2.2823)\n",
            "tensor(2.2053)\n",
            "tensor(2.4858)\n",
            "tensor(2.2859)\n",
            "epoch 0\n",
            "test loss tensor(9.8909)\n",
            "tensor(86.4252)\n",
            "tensor(4.8215)\n",
            "tensor(2.5593)\n",
            "tensor(1.5891)\n",
            "tensor(1.3159)\n",
            "tensor(1.6030)\n",
            "tensor(1.8196)\n",
            "tensor(1.7531)\n",
            "tensor(2.1512)\n",
            "tensor(2.2498)\n",
            "tensor(2.4380)\n",
            "epoch 0\n",
            "test loss tensor(9.8841)\n",
            "tensor(85.7035)\n",
            "tensor(4.6522)\n",
            "tensor(2.0616)\n",
            "tensor(1.4142)\n",
            "tensor(1.5033)\n",
            "tensor(1.4840)\n",
            "tensor(1.8578)\n",
            "tensor(2.4457)\n",
            "tensor(2.0899)\n",
            "tensor(2.3379)\n",
            "tensor(2.6193)\n",
            "epoch 0\n",
            "test loss tensor(9.8336)\n",
            "tensor(85.7297)\n",
            "tensor(5.0823)\n",
            "tensor(2.3659)\n",
            "tensor(1.4257)\n",
            "tensor(1.7045)\n",
            "tensor(1.5730)\n",
            "tensor(1.6314)\n",
            "tensor(2.0750)\n",
            "tensor(1.7974)\n",
            "tensor(2.6264)\n",
            "tensor(2.3561)\n",
            "epoch 0\n",
            "test loss tensor(9.8516)\n",
            "tensor(87.6303)\n",
            "tensor(4.5351)\n",
            "tensor(2.2439)\n",
            "tensor(1.6580)\n",
            "tensor(1.5529)\n",
            "tensor(1.4643)\n",
            "tensor(1.8339)\n",
            "tensor(2.2251)\n",
            "tensor(1.7557)\n",
            "tensor(2.0926)\n",
            "tensor(2.4710)\n",
            "epoch 0\n",
            "test loss tensor(9.9512)\n",
            "tensor(84.6905)\n",
            "tensor(4.3034)\n",
            "tensor(2.1822)\n",
            "tensor(1.4861)\n",
            "tensor(1.1468)\n",
            "tensor(1.6475)\n",
            "tensor(1.7238)\n",
            "tensor(1.9656)\n",
            "tensor(1.6503)\n",
            "tensor(2.2450)\n",
            "tensor(2.2180)\n",
            "epoch 0\n",
            "test loss tensor(9.5690)\n",
            "tensor(84.3279)\n",
            "tensor(4.4380)\n",
            "tensor(2.0147)\n",
            "tensor(1.2097)\n",
            "tensor(1.2412)\n",
            "tensor(1.2655)\n",
            "tensor(1.7111)\n",
            "tensor(1.5325)\n",
            "tensor(1.8314)\n",
            "tensor(2.2955)\n",
            "tensor(2.2696)\n",
            "epoch 0\n",
            "test loss tensor(9.4670)\n",
            "tensor(85.7994)\n",
            "tensor(4.1847)\n",
            "tensor(2.2347)\n",
            "tensor(1.2938)\n",
            "tensor(0.9299)\n",
            "tensor(1.2747)\n",
            "tensor(1.4383)\n",
            "tensor(1.7884)\n",
            "tensor(1.3836)\n",
            "tensor(1.7021)\n",
            "tensor(1.7898)\n",
            "epoch 0\n",
            "test loss tensor(9.4381)\n",
            "tensor(84.1323)\n",
            "tensor(4.4232)\n",
            "tensor(2.2200)\n",
            "tensor(1.2147)\n",
            "tensor(1.4516)\n",
            "tensor(1.4733)\n",
            "tensor(1.8641)\n",
            "tensor(2.1107)\n",
            "tensor(1.9635)\n",
            "tensor(2.0768)\n",
            "tensor(2.4266)\n",
            "epoch 0\n",
            "test loss tensor(9.5779)\n",
            "tensor(85.4485)\n",
            "tensor(4.3424)\n",
            "tensor(2.4162)\n",
            "tensor(1.5254)\n",
            "tensor(1.3367)\n",
            "tensor(1.4785)\n",
            "tensor(1.6619)\n",
            "tensor(1.8780)\n",
            "tensor(1.6519)\n",
            "tensor(2.4415)\n",
            "tensor(2.2209)\n",
            "epoch 0\n",
            "test loss tensor(9.6729)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AZseYD-Qotc"
      },
      "source": [
        "writer.flush()\n",
        "writer.close()\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qtXdY1gAgc"
      },
      "source": [
        "#%load_ext tensorboard"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7IqU3hQfmMa"
      },
      "source": [
        "#!kill 3285\n",
        "#%tensorboard --logdir runs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S6n0-Q4xAg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42556832-c8b9-4eee-82d1-1d273ded7ff5"
      },
      "source": [
        "pred_dataset = DonutDataset(length = 100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0_y0_r_xrf_yrf torch.Size([100, 1]) torch.Size([100, 1]) torch.Size([100, 1000]) torch.Size([1, 1000]) torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgr2Hthdsoak",
        "outputId": "6bc2e864-4bc4-4369-fdbd-00408bcf02c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 25 22:44:05 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    39W / 300W |   2355MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8vn01RqKGky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a7a2c6-ecae-4ba9-dda2-d1142f3fbcc2"
      },
      "source": [
        "with torch.no_grad():\n",
        "  model = model.eval()\n",
        "  DonutDataset.displayCanvas('lstmpredictions.png',pred_dataset, model = model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "open file:  lstmpredictions.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU7i4ppqFBLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d2d099-c515-4c64-b98e-2a27740fb125"
      },
      "source": [
        "with torch.no_grad():\n",
        "  model = model.eval()\n",
        "  DonutDataset.displayCanvas('trainlstmpredictions.png',dataset, model = model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "open file:  trainlstmpredictions.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j28U5Ae-LlZH",
        "outputId": "099d3bfe-158b-49c5-fdc0-19c81f52b538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstm_cell.weight_ih_l0\n",
            "lstm_cell.weight_hh_l0\n",
            "lstm_cell.bias_ih_l0\n",
            "lstm_cell.bias_hh_l0\n",
            "lstm_cell.weight_ih_l1\n",
            "lstm_cell.weight_hh_l1\n",
            "lstm_cell.bias_ih_l1\n",
            "lstm_cell.bias_hh_l1\n",
            "inject_image.0.weight\n",
            "inject_image.0.bias\n",
            "fc_out.0.weight\n",
            "fc_out.0.bias\n",
            "fc_out.3.weight\n",
            "fc_out.3.bias\n",
            "hi_1.0.weight\n",
            "hi_1.0.bias\n",
            "hi_2.0.weight\n",
            "hi_2.0.bias\n",
            "ci_1.0.weight\n",
            "ci_1.0.bias\n",
            "ci_2.0.weight\n",
            "ci_2.0.bias\n",
            "alpha_1.0.weight\n",
            "alpha_1.0.bias\n",
            "alpha_long1.0.weight\n",
            "alpha_long1.0.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWSvK_N0GvaF"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}