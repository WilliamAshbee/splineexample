{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_mcfixed.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMz97xaBvOKV99Ces5saklM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/LSTM_mcfixed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GuTzOJ5E0oN"
      },
      "source": [
        "With progressive growing of the sequence, the loss drops more stably. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp7036kWzHdc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E5VVeE0nEn4"
      },
      "source": [
        "https://r2rt.com/non-zero-initial-states-for-recurrent-neural-networks.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPJLPR-jCBtx"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from skimage import filters\n",
        "import math\n",
        "\n",
        "global numpoints\n",
        "numpoints = 1000\n",
        "side = 32\n",
        "\n",
        "rows = torch.zeros(32,32)\n",
        "columns = torch.zeros(32,32)\n",
        "\n",
        "\n",
        "for i in range(32):\n",
        "    columns[:,i] = i\n",
        "    rows[i,:] = i\n",
        "\n",
        "\n",
        "def donut_matrix(length = 10):\n",
        "\n",
        "    radiusMax = side /3\n",
        "    w = 1\n",
        "    sigmas = [None, 1]\n",
        "    \n",
        "    canvas = torch.zeros((length,side, side))\n",
        "    r0 = torch.tensor(np.random.uniform(side/4, side/3, length))\n",
        "\n",
        "    radii = torch.zeros((length,numpoints))\n",
        "    radii[:, :] = r0.unsqueeze(1)\n",
        "    \n",
        "    ind = [x for x in range(numpoints)]\n",
        "\n",
        "    theta = torch.FloatTensor(ind)\n",
        "    theta *= math.pi*2.0/(float)(numpoints)\n",
        "    \n",
        "    for i in range(1,length):\n",
        "        a = np.random.uniform(1.0,3.0)*torch.sin(np.random.uniform(20.0)*theta+np.random.uniform(1000.0))\n",
        "        #a = 4.0*torch.sin(10.0*theta)\n",
        "        #print(a.shape,torch.max(a))\n",
        "        radii[i,:] += a\n",
        "        #print(radii.shape, torch.max(radii))\n",
        "    \n",
        "    assert torch.min(radii)>0\n",
        "    #print(radii.max(axis = 0)[0].shape)\n",
        "    rmaxs = radii.max(axis = 1)[0]\n",
        "    pmins = rmaxs+1.0\n",
        "    pmaxs = side-rmaxs-1.0\n",
        "    x0 = np.random.uniform(pmins,pmaxs)\n",
        "    y0 = np.random.uniform(pmins,pmaxs)\n",
        "    x0[:]=side/2\n",
        "    y0[:]=side/2\n",
        "    x0 = torch.tensor(x0)\n",
        "    y0 = torch.tensor(y0)\n",
        "    \n",
        "    x0 = x0.unsqueeze(1)\n",
        "    y0 = y0.unsqueeze(1)\n",
        "    #radii = torch.from_numpy(radii)\n",
        "    xrfactors = torch.cos(theta).unsqueeze(0)\n",
        "    yrfactors = torch.sin(theta).unsqueeze(0)\n",
        "    \n",
        "    print('x0_y0_r_xrf_yrf',x0.shape,y0.shape,radii.shape,xrfactors.shape,yrfactors.shape)\n",
        "\n",
        "    x = (x0+(xrfactors*radii))\n",
        "    y = (y0+(yrfactors*radii))\n",
        "    assert x.shape == (length,numpoints)\n",
        "    assert y.shape == (length,numpoints)\n",
        "    assert torch.sum(x[x>(side-1)])==0 \n",
        "    assert torch.sum(x[x<0])==0 \n",
        "    assert torch.sum(y[y>(side-1)])==0 \n",
        "    assert torch.sum(y[y<0])==0 \n",
        "    \n",
        "    points = torch.zeros(length,numpoints,2)\n",
        "    for l in range(length):\n",
        "        canvas[l,y[l,:].type(torch.LongTensor),x[l,:].type(torch.LongTensor)]=1.0\n",
        "        points[l,:,0] = x[l,:]#modified for lstm discriminator\n",
        "        points[l,:,1] = y[l,:]#modified for lstm discriminator \n",
        "    \n",
        "    \n",
        "    return {\n",
        "        'canvas': canvas, \n",
        "        'points':points.type(torch.FloatTensor)}\n",
        "\n",
        "def plot_all_model( sample = None, label=None,fig=None,ax=None):\n",
        "    X = label[:,0]\n",
        "    Y = label[:,1]\n",
        "    img = sample[:,:].detach().squeeze().cpu().numpy()\n",
        "    ax.imshow(img, cmap=plt.cm.gray_r)\n",
        "    predres = 1000\n",
        "\n",
        "    s = [.001 for x in range(predres)]\n",
        "    \n",
        "    assert len(s) == predres\n",
        "    c = ['red' for x in range(predres)]\n",
        "    assert len(c) == predres\n",
        "    ax.scatter(X.detach().cpu().numpy(),Y.detach().cpu().numpy(),s = s,c = c)\n",
        "\n",
        "\n",
        "def getXYs(model=None,loader_disp = None):\n",
        "\n",
        "    outputs = torch.zeros(100,1000,2).cuda()\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    \n",
        "    for samples,labels in loader_disp:\n",
        "      for i in range(38):\n",
        "        optimizer.zero_grad()\n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(samples.cuda(),labels[:,0,:2].cuda(),h0,c0,ind = i)\n",
        "          outputs[:,i*25:(i+1)*25,:] = out.detach()\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(samples.cuda(),labels[:,0,:2].cuda(),h0,c0,ind = i,o = o,output=output)\n",
        "          outputs[:,i*25:(i+1)*25,:] = out.detach()\n",
        "\n",
        "      return samples, outputs\n",
        "\n",
        "\n",
        "          \n",
        "        \n",
        "\n",
        "def plot_all( sample = None, labels = None,fig = None,ax = None):\n",
        "    img = sample[:,:].squeeze().cpu().numpy()\n",
        "    ax.imshow(img, cmap=plt.cm.gray_r)\n",
        "    X = labels[:,0]\n",
        "    Y = labels[:,1]\n",
        "    s = [.001 for x in range(numpoints)]\n",
        "    c = ['red' for x in range(numpoints)]\n",
        "    ax.scatter(X.cpu().numpy(),Y.cpu().numpy(),s = s,c = c)\n",
        "    \n",
        "class DonutDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Donut dataset.\"\"\"\n",
        "    def __init__(self, length = 10):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.length = length\n",
        "        self.values = donut_matrix(length)\n",
        "        assert self.values['canvas'].shape[0] == self.length\n",
        "        assert self.values['points'].shape[0] == self.length\n",
        "        \n",
        "        count = 0\n",
        "        for i in range(self.length):\n",
        "          a = self[i]\n",
        "          c = a[0]\n",
        "          for el in a[1]:\n",
        "            #print(c[(int)(el[1]),(int)(el[0])].item())\n",
        "            #assert c[(int)(el[1]),(int)(el[0])].item() == 1\n",
        "            y,x = (int)(el[1]),(int)(el[0])\n",
        "            if x < side-2 and x > 2 and y < side-2 and y > 2: \n",
        "              if c[y,x] != 1 and \\\n",
        "                c[y+1,x] != 1 and c[y+1,-1+x] != 1 and c[y+1,1+x] != 1 and \\\n",
        "                c[y-1,x] != 1 and c[y,-1+x] != 1 and c[y,1+x] != 1:\n",
        "                count+=1\n",
        "        assert count ==0\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        canvas = self.values[\"canvas\"]\n",
        "        \n",
        "        canvas = canvas[idx,:,:]\n",
        "        assert canvas.shape == (side,side)\n",
        "        \n",
        "        points = self.values[\"points\"]\n",
        "        points = points[idx,:]\n",
        "        #points = points.unsqueeze(1)\n",
        "        #z = torch.zeros(numpoints,1)\n",
        "        #print(z.shape)\n",
        "        #points = torch.cat([points,z], dim = 1)\n",
        "        \n",
        "        #print('points', points.shape)\n",
        "        return canvas, points\n",
        "    \n",
        "    @staticmethod\n",
        "    def displayCanvas(title,dataset, model):\n",
        "        #model.setBatchSize(batch_size = 1)\n",
        "        fig = plt.figure()\n",
        "          \n",
        "        if model != None:\n",
        "          model = model.eval()\n",
        "          loader_disp = data.DataLoader(\n",
        "            dataset, \n",
        "            batch_size=100,\n",
        "            num_workers=2)\n",
        "          samples, outputs = getXYs(model=model,loader_disp = loader_disp)\n",
        "          for i in range(100):\n",
        "            ax = fig.add_subplot(10,10,i+1)\n",
        "            plot_all_model(samples[i,:,:],outputs[i,:,:],fig=fig,ax=ax)\n",
        "            plt.axis('off')\n",
        "\n",
        "        else:\n",
        "          for i in range(100):\n",
        "            sample, labels = dataset[i]\n",
        "            ax = fig.add_subplot(10,10,i+1)\n",
        "            plot_all(sample = sample,labels = labels,fig = fig, ax= ax)\n",
        "            plt.axis('off')\n",
        "\n",
        "        fig.savefig(title,dpi=450)\n",
        "        plt.close(fig) #where f is the figure\n",
        "        plt.clf()\n",
        "        plt.cla()\n",
        "        plt.close()#should free memory\n",
        "        print('open file: ',title)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xHhbWDJ7UUX",
        "outputId": "f69fd148-7fa7-48db-c045-23508de5de29"
      },
      "source": [
        "dataset = DonutDataset(length = 100)\n",
        "\n",
        "DonutDataset.displayCanvas('donut.png',dataset, model = None)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0_y0_r_xrf_yrf torch.Size([100, 1]) torch.Size([100, 1]) torch.Size([100, 1000]) torch.Size([1, 1000]) torch.Size([1, 1000])\n",
            "open file:  donut.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhiJIwh0PvXT",
        "outputId": "08670b9f-3c64-406e-f824-dbe254446814"
      },
      "source": [
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 500\n",
        "dataset = DonutDataset(length = 100*20)\n",
        "loader_train = data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=dataset),\n",
        "    num_workers=2)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0_y0_r_xrf_yrf torch.Size([2000, 1]) torch.Size([2000, 1]) torch.Size([2000, 1000]) torch.Size([1, 1000]) torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxcdCGtH0ps1",
        "outputId": "e58d6a0d-4875-4315-a1d8-e5a30a395551"
      },
      "source": [
        "mini_batch = 250\n",
        "test_dataset = DonutDataset(length = 1000)\n",
        "loader_test = data.DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=test_dataset),\n",
        "    num_workers=2)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0_y0_r_xrf_yrf torch.Size([1000, 1]) torch.Size([1000, 1]) torch.Size([1000, 1000]) torch.Size([1, 1000]) torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGogHY1o699q",
        "outputId": "f66467aa-857e-4975-a0ec-57688ade811b"
      },
      "source": [
        "pred_dataset = DonutDataset(length = 100)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0_y0_r_xrf_yrf torch.Size([100, 1]) torch.Size([100, 1]) torch.Size([100, 1000]) torch.Size([1, 1000]) torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHTtTB_x75NA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.track = 0\n",
        "        # define the properties\n",
        "        self.embed_size = 2\n",
        "        self.hidden_size = 512\n",
        "        self.num_layers = 2\n",
        "        self.seq_len = 25\n",
        "        self.full_len = 1000\n",
        "        self.lm_len = int(self.full_len/self.seq_len)\n",
        "        \n",
        "        self.longtermMem_lstm = None\n",
        "        \n",
        "        self.lstm_cell = nn.LSTM(self.hidden_size, self.hidden_size,self.num_layers)\n",
        "\n",
        "        self.inject_image_lstm =  nn.Sequential(\n",
        "            nn.Linear(2+1024+4*self.hidden_size,self.hidden_size),\n",
        "            #nn.Dropout(),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size,2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "\n",
        "        \n",
        "        self.alpha_long_lstm_r1 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size,int(self.full_len/self.seq_len)),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        \n",
        "        \n",
        "        self.alpha_1 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size,self.seq_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        self.alpha_start = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size,self.seq_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        self.embs = None\n",
        "        self.t0embs = None\n",
        "          \n",
        "\n",
        "    def forward(self, features,p0,h0 = None, c0= None, ind = 0, o = None,output = None):\n",
        "        \n",
        "        assert not torch.any(torch.isnan(features)).item()\n",
        "        assert features != None\n",
        "        assert len(features.shape) == 3\n",
        "        batch_size = features.shape[0]\n",
        "        \n",
        "        p0 = torch.flatten(p0[:,:2],start_dim=1)\n",
        "        \n",
        "        if o == None:\n",
        "          out = p0\n",
        "          self.longtermMem_lstm = torch.zeros(batch_size,int(self.full_len/self.seq_len),self.hidden_size,requires_grad=False).cuda()\n",
        "          self.embs = torch.zeros(batch_size,self.seq_len,self.hidden_size,requires_grad=False).cuda()\n",
        "          self.t0embs = torch.zeros(batch_size,self.seq_len,self.hidden_size,requires_grad=False).cuda()\n",
        "          self.track = 0\n",
        "        else:\n",
        "          out = o\n",
        "        \n",
        "        if h0 == None and c0 == None:\n",
        "          h0 = torch.zeros(self.num_layers,batch_size,self.hidden_size).cuda()\n",
        "          c0 = torch.zeros(self.num_layers,batch_size,self.hidden_size).cuda()\n",
        "\n",
        "        hidden_state = h0\n",
        "        cell_state = c0\n",
        "        outputs = torch.empty((batch_size, self.seq_len, 2)).cuda()\n",
        "        \n",
        "        output = None\n",
        "\n",
        "        for t in range(self.seq_len):\n",
        "          self.track +=1\n",
        "        \n",
        "            \n",
        "          if output == None:\n",
        "            output = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "            outesreadl1_lstm = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "            outesread1_lstm = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "            os_lstm = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "          else:\n",
        "            \n",
        "            al1_lstm = self.alpha_long_lstm_r1(output.view(batch_size,self.hidden_size))\n",
        "            outesreada1_lstm = self.longtermMem_lstm.clone()*al1_lstm.unsqueeze(2)#clone\n",
        "            outesreadl1_lstm = torch.sum(outesreada1_lstm,dim=1)\n",
        "\n",
        "            a1_lstm = self.alpha_1(output.view(batch_size,self.hidden_size))\n",
        "            outesread1_lstm = self.embs.clone()*a1_lstm.unsqueeze(2)#clone\n",
        "            outesread1_lstm = torch.sum(outesread1_lstm,dim=1)\n",
        "\n",
        "            as_lstm = self.alpha_start(output.view(batch_size,self.hidden_size))\n",
        "            os_lstm = self.t0embs.clone()*as_lstm.unsqueeze(2)#clone\n",
        "            os_lstm = torch.sum(os_lstm,dim=1)\n",
        "\n",
        "          combin_lstm = torch.cat([torch.flatten(features,start_dim=1),out,output.view(batch_size,self.hidden_size),outesreadl1_lstm,os_lstm,outesread1_lstm],dim=1)\n",
        "          combin_lstm = self.inject_image_lstm(combin_lstm)\n",
        "          \n",
        "          \n",
        "          output, (hidden_state, cell_state) = self.lstm_cell(combin_lstm.unsqueeze(0), (hidden_state, cell_state))\n",
        "          \n",
        "          self.embs[:,t,:] = output.view(batch_size,self.hidden_size).detach()\n",
        "          \n",
        "\n",
        "          out = self.fc_out(output.view(batch_size,self.hidden_size))\n",
        "          out = out*32.0\n",
        "          outputs[:, t, :] = out\n",
        "\n",
        "        self.longtermMem_lstm[:,ind,:] = output.view(batch_size,self.hidden_size).detach()\n",
        "        if self.track < self.seq_len+2:\n",
        "          self.t0embs = self.embs.clone() \n",
        "        return outputs, hidden_state.detach(), cell_state.detach(), out.detach(),output.detach()#, captions\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50cqsTMxQXEm"
      },
      "source": [
        "model = DecoderRNN().cuda()"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32G-MJC_QcKP"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, betas = (.9,.999))#ideal\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60xL8p9QeQc-"
      },
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjpFwX8MQlPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "620ec943-d3a7-4611-d33c-934faee70fea"
      },
      "source": [
        "for seql in range(3,23,4):\n",
        "  #seql = 19\n",
        "  for epoch in range (5):\n",
        "    loss = None\n",
        "    model = model.train()\n",
        "\n",
        "    for x,y in loader_train:\n",
        "      h0 = None\n",
        "      c0 = None\n",
        "      for i in range(seql):\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "        loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        #writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      #print(y[:,0,:2])\n",
        "      print('epoch',epoch,'seql',seql)\n",
        "      print('train loss', loss)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      model = model.eval()\n",
        "      for x,y in loader_test:\n",
        "        h0 = None\n",
        "        c0 = None\n",
        "        for i in range(seql):\n",
        "          x = x.cuda()\n",
        "          y = y.cuda()\n",
        "          \n",
        "          if i == 0:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "          else:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "          \n",
        "          loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        \n",
        "          assert not torch.any(torch.isnan(out)).item()\n",
        "          assert not torch.any(torch.isnan(y)).item()\n",
        "        \n",
        "        print('epoch',epoch,'seql',seql)\n",
        "        print('testloss',loss)\n",
        "  \n",
        "        "
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 seql 3\n",
            "train loss tensor(38.1546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "train loss tensor(23.0914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "train loss tensor(6.1264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "train loss tensor(4.3622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 3\n",
            "testloss tensor(7.3239, device='cuda:0')\n",
            "epoch 0 seql 3\n",
            "testloss tensor(6.6766, device='cuda:0')\n",
            "epoch 0 seql 3\n",
            "testloss tensor(6.9902, device='cuda:0')\n",
            "epoch 0 seql 3\n",
            "testloss tensor(7.5108, device='cuda:0')\n",
            "epoch 1 seql 3\n",
            "train loss tensor(8.1015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "train loss tensor(6.2420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "train loss tensor(4.1539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "train loss tensor(3.4631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 3\n",
            "testloss tensor(3.2349, device='cuda:0')\n",
            "epoch 1 seql 3\n",
            "testloss tensor(3.0304, device='cuda:0')\n",
            "epoch 1 seql 3\n",
            "testloss tensor(3.0957, device='cuda:0')\n",
            "epoch 1 seql 3\n",
            "testloss tensor(2.9584, device='cuda:0')\n",
            "epoch 2 seql 3\n",
            "train loss tensor(2.8610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 3\n",
            "train loss tensor(2.0484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 3\n",
            "train loss tensor(1.6696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 3\n",
            "train loss tensor(1.8225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 3\n",
            "testloss tensor(1.9014, device='cuda:0')\n",
            "epoch 2 seql 3\n",
            "testloss tensor(1.7910, device='cuda:0')\n",
            "epoch 2 seql 3\n",
            "testloss tensor(1.8836, device='cuda:0')\n",
            "epoch 2 seql 3\n",
            "testloss tensor(1.9279, device='cuda:0')\n",
            "epoch 3 seql 3\n",
            "train loss tensor(2.2318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 3\n",
            "train loss tensor(2.8201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 3\n",
            "train loss tensor(2.9411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 3\n",
            "train loss tensor(2.8164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 3\n",
            "testloss tensor(2.5456, device='cuda:0')\n",
            "epoch 3 seql 3\n",
            "testloss tensor(2.6958, device='cuda:0')\n",
            "epoch 3 seql 3\n",
            "testloss tensor(2.4636, device='cuda:0')\n",
            "epoch 3 seql 3\n",
            "testloss tensor(2.4675, device='cuda:0')\n",
            "epoch 4 seql 3\n",
            "train loss tensor(2.3325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 3\n",
            "train loss tensor(2.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 3\n",
            "train loss tensor(1.9646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 3\n",
            "train loss tensor(1.7224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 3\n",
            "testloss tensor(1.7911, device='cuda:0')\n",
            "epoch 4 seql 3\n",
            "testloss tensor(1.8581, device='cuda:0')\n",
            "epoch 4 seql 3\n",
            "testloss tensor(1.6678, device='cuda:0')\n",
            "epoch 4 seql 3\n",
            "testloss tensor(1.8822, device='cuda:0')\n",
            "epoch 0 seql 7\n",
            "train loss tensor(16.2868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "train loss tensor(6.1765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "train loss tensor(7.9724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "train loss tensor(11.0444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 7\n",
            "testloss tensor(10.2429, device='cuda:0')\n",
            "epoch 0 seql 7\n",
            "testloss tensor(10.3458, device='cuda:0')\n",
            "epoch 0 seql 7\n",
            "testloss tensor(10.4280, device='cuda:0')\n",
            "epoch 0 seql 7\n",
            "testloss tensor(10.1175, device='cuda:0')\n",
            "epoch 1 seql 7\n",
            "train loss tensor(11.0288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "train loss tensor(9.0431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "train loss tensor(8.0348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "train loss tensor(8.3928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 7\n",
            "testloss tensor(7.2402, device='cuda:0')\n",
            "epoch 1 seql 7\n",
            "testloss tensor(7.3563, device='cuda:0')\n",
            "epoch 1 seql 7\n",
            "testloss tensor(7.3504, device='cuda:0')\n",
            "epoch 1 seql 7\n",
            "testloss tensor(7.4070, device='cuda:0')\n",
            "epoch 2 seql 7\n",
            "train loss tensor(8.1592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 7\n",
            "train loss tensor(6.8170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 7\n",
            "train loss tensor(6.5640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 7\n",
            "train loss tensor(5.6046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 7\n",
            "testloss tensor(3.9104, device='cuda:0')\n",
            "epoch 2 seql 7\n",
            "testloss tensor(3.9843, device='cuda:0')\n",
            "epoch 2 seql 7\n",
            "testloss tensor(4.0178, device='cuda:0')\n",
            "epoch 2 seql 7\n",
            "testloss tensor(4.1029, device='cuda:0')\n",
            "epoch 3 seql 7\n",
            "train loss tensor(4.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 7\n",
            "train loss tensor(2.7823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 7\n",
            "train loss tensor(1.2507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 7\n",
            "train loss tensor(1.5215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 7\n",
            "testloss tensor(1.3345, device='cuda:0')\n",
            "epoch 3 seql 7\n",
            "testloss tensor(1.3439, device='cuda:0')\n",
            "epoch 3 seql 7\n",
            "testloss tensor(1.3661, device='cuda:0')\n",
            "epoch 3 seql 7\n",
            "testloss tensor(1.4975, device='cuda:0')\n",
            "epoch 4 seql 7\n",
            "train loss tensor(1.3494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 7\n",
            "train loss tensor(1.4854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 7\n",
            "train loss tensor(1.6254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 7\n",
            "train loss tensor(1.2849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 7\n",
            "testloss tensor(1.5190, device='cuda:0')\n",
            "epoch 4 seql 7\n",
            "testloss tensor(1.4270, device='cuda:0')\n",
            "epoch 4 seql 7\n",
            "testloss tensor(1.4415, device='cuda:0')\n",
            "epoch 4 seql 7\n",
            "testloss tensor(1.2978, device='cuda:0')\n",
            "epoch 0 seql 11\n",
            "train loss tensor(11.1289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "train loss tensor(28.3763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "train loss tensor(11.5082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "train loss tensor(7.1947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 11\n",
            "testloss tensor(3.3726, device='cuda:0')\n",
            "epoch 0 seql 11\n",
            "testloss tensor(3.3235, device='cuda:0')\n",
            "epoch 0 seql 11\n",
            "testloss tensor(3.2082, device='cuda:0')\n",
            "epoch 0 seql 11\n",
            "testloss tensor(3.3812, device='cuda:0')\n",
            "epoch 1 seql 11\n",
            "train loss tensor(23.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "train loss tensor(5.7189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "train loss tensor(7.7068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "train loss tensor(4.7936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 11\n",
            "testloss tensor(3.1487, device='cuda:0')\n",
            "epoch 1 seql 11\n",
            "testloss tensor(3.0544, device='cuda:0')\n",
            "epoch 1 seql 11\n",
            "testloss tensor(3.0590, device='cuda:0')\n",
            "epoch 1 seql 11\n",
            "testloss tensor(3.0772, device='cuda:0')\n",
            "epoch 2 seql 11\n",
            "train loss tensor(6.7806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 11\n",
            "train loss tensor(3.2160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 11\n",
            "train loss tensor(4.8244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 11\n",
            "train loss tensor(2.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 11\n",
            "testloss tensor(3.0461, device='cuda:0')\n",
            "epoch 2 seql 11\n",
            "testloss tensor(3.1701, device='cuda:0')\n",
            "epoch 2 seql 11\n",
            "testloss tensor(3.2806, device='cuda:0')\n",
            "epoch 2 seql 11\n",
            "testloss tensor(3.2568, device='cuda:0')\n",
            "epoch 3 seql 11\n",
            "train loss tensor(3.9528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 11\n",
            "train loss tensor(4.9001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 11\n",
            "train loss tensor(2.7888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 11\n",
            "train loss tensor(4.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 11\n",
            "testloss tensor(3.8854, device='cuda:0')\n",
            "epoch 3 seql 11\n",
            "testloss tensor(3.7815, device='cuda:0')\n",
            "epoch 3 seql 11\n",
            "testloss tensor(3.6962, device='cuda:0')\n",
            "epoch 3 seql 11\n",
            "testloss tensor(3.5792, device='cuda:0')\n",
            "epoch 4 seql 11\n",
            "train loss tensor(2.4216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 11\n",
            "train loss tensor(2.7042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 11\n",
            "train loss tensor(2.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 11\n",
            "train loss tensor(2.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 11\n",
            "testloss tensor(2.1304, device='cuda:0')\n",
            "epoch 4 seql 11\n",
            "testloss tensor(2.0664, device='cuda:0')\n",
            "epoch 4 seql 11\n",
            "testloss tensor(2.0604, device='cuda:0')\n",
            "epoch 4 seql 11\n",
            "testloss tensor(2.2409, device='cuda:0')\n",
            "epoch 0 seql 15\n",
            "train loss tensor(6.5962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 15\n",
            "train loss tensor(3.4282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 15\n",
            "train loss tensor(14.7091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 15\n",
            "train loss tensor(19.5677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 15\n",
            "testloss tensor(8.8272, device='cuda:0')\n",
            "epoch 0 seql 15\n",
            "testloss tensor(8.9710, device='cuda:0')\n",
            "epoch 0 seql 15\n",
            "testloss tensor(8.9605, device='cuda:0')\n",
            "epoch 0 seql 15\n",
            "testloss tensor(9.0365, device='cuda:0')\n",
            "epoch 1 seql 15\n",
            "train loss tensor(9.4246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 15\n",
            "train loss tensor(18.4830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 15\n",
            "train loss tensor(6.8770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 15\n",
            "train loss tensor(9.3139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 15\n",
            "testloss tensor(7.0798, device='cuda:0')\n",
            "epoch 1 seql 15\n",
            "testloss tensor(6.9522, device='cuda:0')\n",
            "epoch 1 seql 15\n",
            "testloss tensor(7.0114, device='cuda:0')\n",
            "epoch 1 seql 15\n",
            "testloss tensor(7.1494, device='cuda:0')\n",
            "epoch 2 seql 15\n",
            "train loss tensor(6.0271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 15\n",
            "train loss tensor(7.1763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 15\n",
            "train loss tensor(7.7948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 15\n",
            "train loss tensor(5.1840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 15\n",
            "testloss tensor(5.0666, device='cuda:0')\n",
            "epoch 2 seql 15\n",
            "testloss tensor(5.2999, device='cuda:0')\n",
            "epoch 2 seql 15\n",
            "testloss tensor(5.0298, device='cuda:0')\n",
            "epoch 2 seql 15\n",
            "testloss tensor(5.1387, device='cuda:0')\n",
            "epoch 3 seql 15\n",
            "train loss tensor(5.0369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 15\n",
            "train loss tensor(4.9809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 15\n",
            "train loss tensor(4.6693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 15\n",
            "train loss tensor(2.4673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 15\n",
            "testloss tensor(2.1111, device='cuda:0')\n",
            "epoch 3 seql 15\n",
            "testloss tensor(2.0357, device='cuda:0')\n",
            "epoch 3 seql 15\n",
            "testloss tensor(2.1358, device='cuda:0')\n",
            "epoch 3 seql 15\n",
            "testloss tensor(2.0514, device='cuda:0')\n",
            "epoch 4 seql 15\n",
            "train loss tensor(2.1829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 15\n",
            "train loss tensor(9.9026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 15\n",
            "train loss tensor(3.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 15\n",
            "train loss tensor(1.6637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 15\n",
            "testloss tensor(3.9430, device='cuda:0')\n",
            "epoch 4 seql 15\n",
            "testloss tensor(3.7792, device='cuda:0')\n",
            "epoch 4 seql 15\n",
            "testloss tensor(3.8538, device='cuda:0')\n",
            "epoch 4 seql 15\n",
            "testloss tensor(3.8710, device='cuda:0')\n",
            "epoch 0 seql 19\n",
            "train loss tensor(3.5411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 19\n",
            "train loss tensor(34.7771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 19\n",
            "train loss tensor(30.0305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 19\n",
            "train loss tensor(19.1153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 19\n",
            "testloss tensor(11.9137, device='cuda:0')\n",
            "epoch 0 seql 19\n",
            "testloss tensor(11.7341, device='cuda:0')\n",
            "epoch 0 seql 19\n",
            "testloss tensor(11.6484, device='cuda:0')\n",
            "epoch 0 seql 19\n",
            "testloss tensor(11.8274, device='cuda:0')\n",
            "epoch 1 seql 19\n",
            "train loss tensor(28.4673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 19\n",
            "train loss tensor(16.9131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 19\n",
            "train loss tensor(18.9355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 19\n",
            "train loss tensor(15.0606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 19\n",
            "testloss tensor(13.7136, device='cuda:0')\n",
            "epoch 1 seql 19\n",
            "testloss tensor(13.4593, device='cuda:0')\n",
            "epoch 1 seql 19\n",
            "testloss tensor(13.3940, device='cuda:0')\n",
            "epoch 1 seql 19\n",
            "testloss tensor(13.6997, device='cuda:0')\n",
            "epoch 2 seql 19\n",
            "train loss tensor(15.9273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 19\n",
            "train loss tensor(13.7273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 19\n",
            "train loss tensor(13.1230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 19\n",
            "train loss tensor(11.6836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 19\n",
            "testloss tensor(6.8916, device='cuda:0')\n",
            "epoch 2 seql 19\n",
            "testloss tensor(7.0786, device='cuda:0')\n",
            "epoch 2 seql 19\n",
            "testloss tensor(7.0424, device='cuda:0')\n",
            "epoch 2 seql 19\n",
            "testloss tensor(6.7919, device='cuda:0')\n",
            "epoch 3 seql 19\n",
            "train loss tensor(9.5469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 19\n",
            "train loss tensor(6.5802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 19\n",
            "train loss tensor(5.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 19\n",
            "train loss tensor(8.1918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 19\n",
            "testloss tensor(3.3298, device='cuda:0')\n",
            "epoch 3 seql 19\n",
            "testloss tensor(3.3749, device='cuda:0')\n",
            "epoch 3 seql 19\n",
            "testloss tensor(3.2882, device='cuda:0')\n",
            "epoch 3 seql 19\n",
            "testloss tensor(3.3154, device='cuda:0')\n",
            "epoch 4 seql 19\n",
            "train loss tensor(8.4951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 19\n",
            "train loss tensor(3.6378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 19\n",
            "train loss tensor(5.0171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 19\n",
            "train loss tensor(18.9617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 19\n",
            "testloss tensor(83.3141, device='cuda:0')\n",
            "epoch 4 seql 19\n",
            "testloss tensor(79.7088, device='cuda:0')\n",
            "epoch 4 seql 19\n",
            "testloss tensor(79.0348, device='cuda:0')\n",
            "epoch 4 seql 19\n",
            "testloss tensor(83.8572, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeBFueVv7BDD",
        "outputId": "3caf5472-ba34-4193-c462-6cbe630e642c"
      },
      "source": [
        "with torch.no_grad():\n",
        "  model = model.eval()\n",
        "  DonutDataset.displayCanvas('intermediate1.png',pred_dataset, model = model)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "open file:  intermediate1.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWZWJn4i_R5x"
      },
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, betas = (.9,.999))#ideal\n",
        "\n",
        "for g in optimizer.param_groups:\n",
        "    g['lr'] = 0.0001\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV5RNgqjYMgZ",
        "outputId": "d555b847-cd29-4d70-a6d7-10ed10cef794"
      },
      "source": [
        "#for seql in range(15,20,4):\n",
        "seql = 23\n",
        "for epoch in range (20):\n",
        "  model = model.train()\n",
        "  loss = None\n",
        "  for x,y in loader_train:\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    for i in range(seql):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      if i == 0:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "      else:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "      loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "      writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #print(y[:,0,:2])\n",
        "    print('epoch',epoch,'seql',seql)\n",
        "    print(loss)\n",
        "  with torch.no_grad():\n",
        "    model = model.eval()\n",
        "    for x,y in loader_test:\n",
        "      h0 = None\n",
        "      c0 = None\n",
        "      for i in range(seql):\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "        \n",
        "        loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "      \n",
        "        assert not torch.any(torch.isnan(out)).item()\n",
        "        assert not torch.any(torch.isnan(y)).item()\n",
        "      \n",
        "      print('epoch',epoch,'seql',seql)\n",
        "      print('testloss',loss)\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 seql 23\n",
            "tensor(18.2548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 23\n",
            "tensor(9.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 23\n",
            "tensor(7.5500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 23\n",
            "tensor(26.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 23\n",
            "testloss tensor(20.2984, device='cuda:0')\n",
            "epoch 0 seql 23\n",
            "testloss tensor(19.9428, device='cuda:0')\n",
            "epoch 0 seql 23\n",
            "testloss tensor(20.4935, device='cuda:0')\n",
            "epoch 0 seql 23\n",
            "testloss tensor(20.1979, device='cuda:0')\n",
            "epoch 1 seql 23\n",
            "tensor(21.8314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 23\n",
            "tensor(35.1705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 23\n",
            "tensor(22.6518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 23\n",
            "tensor(21.5655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 23\n",
            "testloss tensor(19.8061, device='cuda:0')\n",
            "epoch 1 seql 23\n",
            "testloss tensor(20.2249, device='cuda:0')\n",
            "epoch 1 seql 23\n",
            "testloss tensor(20.4176, device='cuda:0')\n",
            "epoch 1 seql 23\n",
            "testloss tensor(20.0612, device='cuda:0')\n",
            "epoch 2 seql 23\n",
            "tensor(20.2872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 23\n",
            "tensor(19.9046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 23\n",
            "tensor(18.4510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 23\n",
            "tensor(17.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 23\n",
            "testloss tensor(16.4598, device='cuda:0')\n",
            "epoch 2 seql 23\n",
            "testloss tensor(16.3062, device='cuda:0')\n",
            "epoch 2 seql 23\n",
            "testloss tensor(16.0092, device='cuda:0')\n",
            "epoch 2 seql 23\n",
            "testloss tensor(16.0204, device='cuda:0')\n",
            "epoch 3 seql 23\n",
            "tensor(16.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 23\n",
            "tensor(14.8767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 23\n",
            "tensor(13.3242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 23\n",
            "tensor(9.3149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 23\n",
            "testloss tensor(8.5708, device='cuda:0')\n",
            "epoch 3 seql 23\n",
            "testloss tensor(8.5858, device='cuda:0')\n",
            "epoch 3 seql 23\n",
            "testloss tensor(8.5028, device='cuda:0')\n",
            "epoch 3 seql 23\n",
            "testloss tensor(8.6385, device='cuda:0')\n",
            "epoch 4 seql 23\n",
            "tensor(5.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 23\n",
            "tensor(9.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 23\n",
            "tensor(10.6972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 23\n",
            "tensor(3.4598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 23\n",
            "testloss tensor(4.2991, device='cuda:0')\n",
            "epoch 4 seql 23\n",
            "testloss tensor(4.2283, device='cuda:0')\n",
            "epoch 4 seql 23\n",
            "testloss tensor(4.4129, device='cuda:0')\n",
            "epoch 4 seql 23\n",
            "testloss tensor(4.3080, device='cuda:0')\n",
            "epoch 5 seql 23\n",
            "tensor(4.0531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 5 seql 23\n",
            "tensor(4.6983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 5 seql 23\n",
            "tensor(3.0425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 5 seql 23\n",
            "tensor(2.8206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 5 seql 23\n",
            "testloss tensor(2.6976, device='cuda:0')\n",
            "epoch 5 seql 23\n",
            "testloss tensor(2.6902, device='cuda:0')\n",
            "epoch 5 seql 23\n",
            "testloss tensor(2.6941, device='cuda:0')\n",
            "epoch 5 seql 23\n",
            "testloss tensor(2.6814, device='cuda:0')\n",
            "epoch 6 seql 23\n",
            "tensor(3.3101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 6 seql 23\n",
            "tensor(2.3290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 6 seql 23\n",
            "tensor(2.2607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 6 seql 23\n",
            "tensor(5.6938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 6 seql 23\n",
            "testloss tensor(1.6573, device='cuda:0')\n",
            "epoch 6 seql 23\n",
            "testloss tensor(1.6609, device='cuda:0')\n",
            "epoch 6 seql 23\n",
            "testloss tensor(1.6653, device='cuda:0')\n",
            "epoch 6 seql 23\n",
            "testloss tensor(1.7223, device='cuda:0')\n",
            "epoch 7 seql 23\n",
            "tensor(2.2922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 7 seql 23\n",
            "tensor(1.8875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 7 seql 23\n",
            "tensor(4.0637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 7 seql 23\n",
            "tensor(2.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 7 seql 23\n",
            "testloss tensor(4.2485, device='cuda:0')\n",
            "epoch 7 seql 23\n",
            "testloss tensor(4.1814, device='cuda:0')\n",
            "epoch 7 seql 23\n",
            "testloss tensor(4.3645, device='cuda:0')\n",
            "epoch 7 seql 23\n",
            "testloss tensor(4.0546, device='cuda:0')\n",
            "epoch 8 seql 23\n",
            "tensor(1.6681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 8 seql 23\n",
            "tensor(1.7273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 8 seql 23\n",
            "tensor(2.7084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 8 seql 23\n",
            "tensor(2.3969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 8 seql 23\n",
            "testloss tensor(1.3992, device='cuda:0')\n",
            "epoch 8 seql 23\n",
            "testloss tensor(1.4288, device='cuda:0')\n",
            "epoch 8 seql 23\n",
            "testloss tensor(1.4339, device='cuda:0')\n",
            "epoch 8 seql 23\n",
            "testloss tensor(1.3428, device='cuda:0')\n",
            "epoch 9 seql 23\n",
            "tensor(1.4393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 9 seql 23\n",
            "tensor(3.2340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 9 seql 23\n",
            "tensor(4.5551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 9 seql 23\n",
            "tensor(3.5216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 9 seql 23\n",
            "testloss tensor(1.7021, device='cuda:0')\n",
            "epoch 9 seql 23\n",
            "testloss tensor(1.7473, device='cuda:0')\n",
            "epoch 9 seql 23\n",
            "testloss tensor(1.6814, device='cuda:0')\n",
            "epoch 9 seql 23\n",
            "testloss tensor(1.9149, device='cuda:0')\n",
            "epoch 10 seql 23\n",
            "tensor(6.7190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 10 seql 23\n",
            "tensor(3.3337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 10 seql 23\n",
            "tensor(5.3017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 10 seql 23\n",
            "tensor(1.3678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 10 seql 23\n",
            "testloss tensor(1.6693, device='cuda:0')\n",
            "epoch 10 seql 23\n",
            "testloss tensor(1.6803, device='cuda:0')\n",
            "epoch 10 seql 23\n",
            "testloss tensor(1.7052, device='cuda:0')\n",
            "epoch 10 seql 23\n",
            "testloss tensor(1.7170, device='cuda:0')\n",
            "epoch 11 seql 23\n",
            "tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 11 seql 23\n",
            "tensor(1.7450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 11 seql 23\n",
            "tensor(1.4912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 11 seql 23\n",
            "tensor(1.4136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 11 seql 23\n",
            "testloss tensor(1.4681, device='cuda:0')\n",
            "epoch 11 seql 23\n",
            "testloss tensor(1.4768, device='cuda:0')\n",
            "epoch 11 seql 23\n",
            "testloss tensor(1.3908, device='cuda:0')\n",
            "epoch 11 seql 23\n",
            "testloss tensor(1.4147, device='cuda:0')\n",
            "epoch 12 seql 23\n",
            "tensor(1.4161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 12 seql 23\n",
            "tensor(1.5012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 12 seql 23\n",
            "tensor(1.3739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 12 seql 23\n",
            "tensor(1.3226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 12 seql 23\n",
            "testloss tensor(1.3829, device='cuda:0')\n",
            "epoch 12 seql 23\n",
            "testloss tensor(1.2847, device='cuda:0')\n",
            "epoch 12 seql 23\n",
            "testloss tensor(1.4421, device='cuda:0')\n",
            "epoch 12 seql 23\n",
            "testloss tensor(1.3652, device='cuda:0')\n",
            "epoch 13 seql 23\n",
            "tensor(1.4072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 13 seql 23\n",
            "tensor(1.2877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 13 seql 23\n",
            "tensor(1.3735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 13 seql 23\n",
            "tensor(1.2841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 13 seql 23\n",
            "testloss tensor(1.3098, device='cuda:0')\n",
            "epoch 13 seql 23\n",
            "testloss tensor(1.3709, device='cuda:0')\n",
            "epoch 13 seql 23\n",
            "testloss tensor(1.2702, device='cuda:0')\n",
            "epoch 13 seql 23\n",
            "testloss tensor(1.3276, device='cuda:0')\n",
            "epoch 14 seql 23\n",
            "tensor(1.3198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 14 seql 23\n",
            "tensor(1.3359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 14 seql 23\n",
            "tensor(1.1948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 14 seql 23\n",
            "tensor(1.3180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 14 seql 23\n",
            "testloss tensor(1.2861, device='cuda:0')\n",
            "epoch 14 seql 23\n",
            "testloss tensor(1.3170, device='cuda:0')\n",
            "epoch 14 seql 23\n",
            "testloss tensor(1.3631, device='cuda:0')\n",
            "epoch 14 seql 23\n",
            "testloss tensor(1.3424, device='cuda:0')\n",
            "epoch 15 seql 23\n",
            "tensor(1.2423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 15 seql 23\n",
            "tensor(1.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 15 seql 23\n",
            "tensor(1.2778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 15 seql 23\n",
            "tensor(1.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 15 seql 23\n",
            "testloss tensor(1.2437, device='cuda:0')\n",
            "epoch 15 seql 23\n",
            "testloss tensor(1.2517, device='cuda:0')\n",
            "epoch 15 seql 23\n",
            "testloss tensor(1.1855, device='cuda:0')\n",
            "epoch 15 seql 23\n",
            "testloss tensor(1.1682, device='cuda:0')\n",
            "epoch 16 seql 23\n",
            "tensor(1.4634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 16 seql 23\n",
            "tensor(1.2518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 16 seql 23\n",
            "tensor(1.7797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 16 seql 23\n",
            "tensor(1.6223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 16 seql 23\n",
            "testloss tensor(1.2174, device='cuda:0')\n",
            "epoch 16 seql 23\n",
            "testloss tensor(1.2798, device='cuda:0')\n",
            "epoch 16 seql 23\n",
            "testloss tensor(1.2096, device='cuda:0')\n",
            "epoch 16 seql 23\n",
            "testloss tensor(1.1856, device='cuda:0')\n",
            "epoch 17 seql 23\n",
            "tensor(1.2420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 17 seql 23\n",
            "tensor(2.1248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 17 seql 23\n",
            "tensor(1.5356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 17 seql 23\n",
            "tensor(1.6276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 17 seql 23\n",
            "testloss tensor(1.2594, device='cuda:0')\n",
            "epoch 17 seql 23\n",
            "testloss tensor(1.3703, device='cuda:0')\n",
            "epoch 17 seql 23\n",
            "testloss tensor(1.2658, device='cuda:0')\n",
            "epoch 17 seql 23\n",
            "testloss tensor(1.3322, device='cuda:0')\n",
            "epoch 18 seql 23\n",
            "tensor(1.5470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 18 seql 23\n",
            "tensor(2.4628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 18 seql 23\n",
            "tensor(3.4743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 18 seql 23\n",
            "tensor(1.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 18 seql 23\n",
            "testloss tensor(1.6366, device='cuda:0')\n",
            "epoch 18 seql 23\n",
            "testloss tensor(1.7472, device='cuda:0')\n",
            "epoch 18 seql 23\n",
            "testloss tensor(1.9471, device='cuda:0')\n",
            "epoch 18 seql 23\n",
            "testloss tensor(1.7725, device='cuda:0')\n",
            "epoch 19 seql 23\n",
            "tensor(4.2651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 19 seql 23\n",
            "tensor(3.3879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 19 seql 23\n",
            "tensor(3.8905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 19 seql 23\n",
            "tensor(1.3292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 19 seql 23\n",
            "testloss tensor(1.3449, device='cuda:0')\n",
            "epoch 19 seql 23\n",
            "testloss tensor(1.4459, device='cuda:0')\n",
            "epoch 19 seql 23\n",
            "testloss tensor(1.3552, device='cuda:0')\n",
            "epoch 19 seql 23\n",
            "testloss tensor(1.4559, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XXOA0SE7-i6",
        "outputId": "20821118-ee82-436d-ccbe-d8649559e732"
      },
      "source": [
        "with torch.no_grad():\n",
        "  model = model.eval()\n",
        "  DonutDataset.displayCanvas('intermediate2.png',pred_dataset, model = model)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "open file:  intermediate2.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuGEdcCjYLK5"
      },
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(),lr = 0.00001, betas = (.9,.999))#ideal\n",
        "for g in optimizer.param_groups:\n",
        "    g['lr'] = 0.00001\n",
        "\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXg-Ue7XkTAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77b6ee1-0e65-4840-d9f4-5cc470491332"
      },
      "source": [
        "\n",
        "model = model.train()\n",
        "#for seql in range(15,20,4):\n",
        "seql = 23\n",
        "for epoch in range (40):\n",
        "  loss = None\n",
        "  model = model.train()\n",
        "  for x,y in loader_train:\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    for i in range(seql):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      if i == 0:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "      else:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "      loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "      writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #print(y[:,0,:2])\n",
        "    print('epoch',epoch,'seql',seql)\n",
        "    print(loss)\n",
        "  with torch.no_grad():\n",
        "      model = model.eval()\n",
        "      for x,y in loader_test:\n",
        "        h0 = None\n",
        "        c0 = None\n",
        "        for i in range(seql):\n",
        "          x = x.cuda()\n",
        "          y = y.cuda()\n",
        "          \n",
        "          if i == 0:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "          else:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "          \n",
        "          loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        \n",
        "          assert not torch.any(torch.isnan(out)).item()\n",
        "          assert not torch.any(torch.isnan(y)).item()\n",
        "        \n",
        "        print('epoch',epoch,'seql',seql)\n",
        "        print('testloss',loss)\n",
        "  \n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 seql 23\n",
            "tensor(3.0515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 23\n",
            "tensor(2.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 23\n",
            "tensor(2.2884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 23\n",
            "tensor(1.7687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 0 seql 23\n",
            "testloss tensor(1.8279, device='cuda:0')\n",
            "epoch 0 seql 23\n",
            "testloss tensor(1.7395, device='cuda:0')\n",
            "epoch 0 seql 23\n",
            "testloss tensor(1.8915, device='cuda:0')\n",
            "epoch 0 seql 23\n",
            "testloss tensor(1.9712, device='cuda:0')\n",
            "epoch 1 seql 23\n",
            "tensor(1.5816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 23\n",
            "tensor(1.5835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 23\n",
            "tensor(1.3482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 23\n",
            "tensor(1.3943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 1 seql 23\n",
            "testloss tensor(1.3256, device='cuda:0')\n",
            "epoch 1 seql 23\n",
            "testloss tensor(1.4861, device='cuda:0')\n",
            "epoch 1 seql 23\n",
            "testloss tensor(1.3527, device='cuda:0')\n",
            "epoch 1 seql 23\n",
            "testloss tensor(1.2936, device='cuda:0')\n",
            "epoch 2 seql 23\n",
            "tensor(1.3535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 23\n",
            "tensor(1.2371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 23\n",
            "tensor(1.3340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 23\n",
            "tensor(1.2393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 2 seql 23\n",
            "testloss tensor(1.2187, device='cuda:0')\n",
            "epoch 2 seql 23\n",
            "testloss tensor(1.3301, device='cuda:0')\n",
            "epoch 2 seql 23\n",
            "testloss tensor(1.2710, device='cuda:0')\n",
            "epoch 2 seql 23\n",
            "testloss tensor(1.2700, device='cuda:0')\n",
            "epoch 3 seql 23\n",
            "tensor(1.2411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 23\n",
            "tensor(1.2645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 23\n",
            "tensor(1.2617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 23\n",
            "tensor(1.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 3 seql 23\n",
            "testloss tensor(1.3057, device='cuda:0')\n",
            "epoch 3 seql 23\n",
            "testloss tensor(1.2423, device='cuda:0')\n",
            "epoch 3 seql 23\n",
            "testloss tensor(1.2186, device='cuda:0')\n",
            "epoch 3 seql 23\n",
            "testloss tensor(1.2644, device='cuda:0')\n",
            "epoch 4 seql 23\n",
            "tensor(1.1899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 23\n",
            "tensor(1.2354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 23\n",
            "tensor(1.3029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 23\n",
            "tensor(1.2750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 4 seql 23\n",
            "testloss tensor(1.2160, device='cuda:0')\n",
            "epoch 4 seql 23\n",
            "testloss tensor(1.3012, device='cuda:0')\n",
            "epoch 4 seql 23\n",
            "testloss tensor(1.2168, device='cuda:0')\n",
            "epoch 4 seql 23\n",
            "testloss tensor(1.2778, device='cuda:0')\n",
            "epoch 5 seql 23\n",
            "tensor(1.2706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 5 seql 23\n",
            "tensor(1.2796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 5 seql 23\n",
            "tensor(1.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 5 seql 23\n",
            "tensor(1.2157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 5 seql 23\n",
            "testloss tensor(1.2831, device='cuda:0')\n",
            "epoch 5 seql 23\n",
            "testloss tensor(1.2584, device='cuda:0')\n",
            "epoch 5 seql 23\n",
            "testloss tensor(1.2292, device='cuda:0')\n",
            "epoch 5 seql 23\n",
            "testloss tensor(1.2173, device='cuda:0')\n",
            "epoch 6 seql 23\n",
            "tensor(1.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 6 seql 23\n",
            "tensor(1.2576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 6 seql 23\n",
            "tensor(1.2542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 6 seql 23\n",
            "tensor(1.2302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 6 seql 23\n",
            "testloss tensor(1.2779, device='cuda:0')\n",
            "epoch 6 seql 23\n",
            "testloss tensor(1.2700, device='cuda:0')\n",
            "epoch 6 seql 23\n",
            "testloss tensor(1.1992, device='cuda:0')\n",
            "epoch 6 seql 23\n",
            "testloss tensor(1.2120, device='cuda:0')\n",
            "epoch 7 seql 23\n",
            "tensor(1.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 7 seql 23\n",
            "tensor(1.2468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 7 seql 23\n",
            "tensor(1.2810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 7 seql 23\n",
            "tensor(1.1980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 7 seql 23\n",
            "testloss tensor(1.2370, device='cuda:0')\n",
            "epoch 7 seql 23\n",
            "testloss tensor(1.2793, device='cuda:0')\n",
            "epoch 7 seql 23\n",
            "testloss tensor(1.1671, device='cuda:0')\n",
            "epoch 7 seql 23\n",
            "testloss tensor(1.2568, device='cuda:0')\n",
            "epoch 8 seql 23\n",
            "tensor(1.2695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 8 seql 23\n",
            "tensor(1.1851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 8 seql 23\n",
            "tensor(1.2589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 8 seql 23\n",
            "tensor(1.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 8 seql 23\n",
            "testloss tensor(1.1491, device='cuda:0')\n",
            "epoch 8 seql 23\n",
            "testloss tensor(1.3424, device='cuda:0')\n",
            "epoch 8 seql 23\n",
            "testloss tensor(1.2020, device='cuda:0')\n",
            "epoch 8 seql 23\n",
            "testloss tensor(1.2275, device='cuda:0')\n",
            "epoch 9 seql 23\n",
            "tensor(1.2475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 9 seql 23\n",
            "tensor(1.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 9 seql 23\n",
            "tensor(1.2266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 9 seql 23\n",
            "tensor(1.1764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 9 seql 23\n",
            "testloss tensor(1.2868, device='cuda:0')\n",
            "epoch 9 seql 23\n",
            "testloss tensor(1.1833, device='cuda:0')\n",
            "epoch 9 seql 23\n",
            "testloss tensor(1.1303, device='cuda:0')\n",
            "epoch 9 seql 23\n",
            "testloss tensor(1.2919, device='cuda:0')\n",
            "epoch 10 seql 23\n",
            "tensor(1.2224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 10 seql 23\n",
            "tensor(1.2373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 10 seql 23\n",
            "tensor(1.1872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 10 seql 23\n",
            "tensor(1.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 10 seql 23\n",
            "testloss tensor(1.2517, device='cuda:0')\n",
            "epoch 10 seql 23\n",
            "testloss tensor(1.1832, device='cuda:0')\n",
            "epoch 10 seql 23\n",
            "testloss tensor(1.2885, device='cuda:0')\n",
            "epoch 10 seql 23\n",
            "testloss tensor(1.1479, device='cuda:0')\n",
            "epoch 11 seql 23\n",
            "tensor(1.1701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 11 seql 23\n",
            "tensor(1.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 11 seql 23\n",
            "tensor(1.1851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 11 seql 23\n",
            "tensor(1.2679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 11 seql 23\n",
            "testloss tensor(1.2206, device='cuda:0')\n",
            "epoch 11 seql 23\n",
            "testloss tensor(1.1818, device='cuda:0')\n",
            "epoch 11 seql 23\n",
            "testloss tensor(1.2432, device='cuda:0')\n",
            "epoch 11 seql 23\n",
            "testloss tensor(1.2120, device='cuda:0')\n",
            "epoch 12 seql 23\n",
            "tensor(1.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 12 seql 23\n",
            "tensor(1.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 12 seql 23\n",
            "tensor(1.2155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 12 seql 23\n",
            "tensor(1.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 12 seql 23\n",
            "testloss tensor(1.1266, device='cuda:0')\n",
            "epoch 12 seql 23\n",
            "testloss tensor(1.2647, device='cuda:0')\n",
            "epoch 12 seql 23\n",
            "testloss tensor(1.2873, device='cuda:0')\n",
            "epoch 12 seql 23\n",
            "testloss tensor(1.1603, device='cuda:0')\n",
            "epoch 13 seql 23\n",
            "tensor(1.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 13 seql 23\n",
            "tensor(1.2109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 13 seql 23\n",
            "tensor(1.2156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 13 seql 23\n",
            "tensor(1.1780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "epoch 13 seql 23\n",
            "testloss tensor(1.2881, device='cuda:0')\n",
            "epoch 13 seql 23\n",
            "testloss tensor(1.1953, device='cuda:0')\n",
            "epoch 13 seql 23\n",
            "testloss tensor(1.2203, device='cuda:0')\n",
            "epoch 13 seql 23\n",
            "testloss tensor(1.1128, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AZseYD-Qotc"
      },
      "source": [
        "writer.flush()\n",
        "writer.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qtXdY1gAgc"
      },
      "source": [
        "#%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7IqU3hQfmMa"
      },
      "source": [
        "#!kill 3285\n",
        "#%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgr2Hthdsoak"
      },
      "source": [
        "#!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8vn01RqKGky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e958cb04-7898-419f-aae6-6ce386913133"
      },
      "source": [
        "with torch.no_grad():\n",
        "  model = model.eval()\n",
        "  DonutDataset.displayCanvas('lstmpredictions.png',pred_dataset, model = model)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "open file:  lstmpredictions.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j28U5Ae-LlZH"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWSvK_N0GvaF"
      },
      "source": [
        "with torch.no_grad():\n",
        "      model = model.eval()\n",
        "      for x,y in loader_test:\n",
        "        h0 = None\n",
        "        c0 = None\n",
        "        for i in range(seql):\n",
        "          x = x.cuda()\n",
        "          y = y.cuda()\n",
        "          \n",
        "          if i == 0:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "          else:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "          \n",
        "          loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        \n",
        "          assert not torch.any(torch.isnan(out)).item()\n",
        "          assert not torch.any(torch.isnan(y)).item()\n",
        "        \n",
        "        print('epoch',epoch,'seql',seql)\n",
        "        print('testloss',loss)\n",
        "  \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}