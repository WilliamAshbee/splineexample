{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvenSimplerToyProblem.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtzKCisM89MrdgdoHj3YlQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/EvenSimplerToyProblem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "I1qTYE48UUtk",
        "outputId": "91f169b6-e853-4323-f469-4a7b72007c93"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from skimage import filters\n",
        "import math\n",
        "\n",
        "global numpoints\n",
        "numpoints = 1\n",
        "side = 32\n",
        "\n",
        "rows = torch.zeros(32,32)\n",
        "columns = torch.zeros(32,32)\n",
        "\n",
        "\n",
        "for i in range(32):\n",
        "    columns[:,i] = i\n",
        "    rows[i,:] = i\n",
        "\n",
        "\n",
        "def point_matrix():\n",
        "    length = side**2\n",
        "    canvas = torch.zeros((length,side, side))\n",
        "    \n",
        "\n",
        "    x = torch.zeros(length,numpoints) \n",
        "    y = torch.zeros(length,numpoints)\n",
        "    assert x.shape == (length,numpoints)\n",
        "    assert y.shape == (length,numpoints)\n",
        "    \n",
        "    points = torch.zeros(length,2)\n",
        "    for j in range(side):\n",
        "      for i in range(side):\n",
        "        l = i*32+j\n",
        "        canvas[l,i,j] = 1.0\n",
        "        x[l] = i\n",
        "        y[l] = j\n",
        "\n",
        "        #points[l,:,0] = x[l,:]\n",
        "        #points[l,:,1] = y[l,:]\n",
        "        points[l,0] = i#modified for lstm discriminator\n",
        "        points[l,1] = j#modified for lstm discriminator \n",
        "    \n",
        "    \n",
        "    return {\n",
        "        'canvas': canvas, \n",
        "        'points':points.type(torch.FloatTensor)}\n",
        "\n",
        "\n",
        "def plot_all( sample = None, model = None, labels = None):\n",
        "    img = sample[:,:].squeeze().cpu().numpy()\n",
        "    #img = np.zeros((32,32))\n",
        "    #img[1,1] = 1\n",
        "    #img[31,1] = 1\n",
        "    #img[31,31] = 1\n",
        "    img = img.T\n",
        "    plt.imshow(img, cmap=plt.cm.gray_r)\n",
        "    if model != None:\n",
        "        with torch.no_grad():\n",
        "            global numpoints\n",
        "\n",
        "            print(\"sample\", sample.shape)\n",
        "            sample = sample.cuda()\n",
        "            sample = sample.unsqueeze(0)\n",
        "            print('hello',sample.shape)\n",
        "            pred = model(sample)\n",
        "            print('hello')\n",
        "            \n",
        "            print('pred', pred.shape)\n",
        "            predres = 1\n",
        "            X = pred[:,0]\n",
        "            Y = pred[:,1]\n",
        "            \n",
        "            s = [10 for x in range(predres)]\n",
        "            \n",
        "            assert len(s) == predres\n",
        "            c = ['red' for x in range(predres)]\n",
        "            assert len(c) == predres\n",
        "            Y = Y.cuda()\n",
        "            X = X.cuda()\n",
        "            print(\"type\",type(X))\n",
        "            ascatter = plt.scatter(X.cpu().numpy(),Y.cpu().numpy(),s = s,c = c)\n",
        "            plt.gca().add_artist(ascatter)\n",
        "    else:\n",
        "        #print(labels.shape)\n",
        "\n",
        "        X = labels[0]\n",
        "        Y = labels[1]\n",
        "        #print(X.shape)\n",
        "        #print(Y.shape)\n",
        "        print(X,Y)\n",
        "        s = [.1 for x in range(numpoints)]\n",
        "        #print(len(s))\n",
        "        c = ['red' for x in range(numpoints)]\n",
        "        #print(len(c))\n",
        "        ascatter = plt.scatter(X,Y,s = s,c = c)\n",
        "        plt.gca().add_artist(ascatter)\n",
        "\n",
        "class PointDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Donut dataset.\"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.length = side**2\n",
        "        self.values = point_matrix()\n",
        "        assert self.values['canvas'].shape[0] == self.length\n",
        "        assert self.values['points'].shape[0] == self.length\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        canvas = self.values[\"canvas\"]\n",
        "        \n",
        "        canvas = canvas[idx,:,:]\n",
        "        assert canvas.shape == (side,side)\n",
        "        points = self.values[\"points\"]\n",
        "        points = points[idx,:]\n",
        "        return canvas, points\n",
        "    \n",
        "    @staticmethod\n",
        "    def displayCanvas(title,dataset, model):\n",
        "        #model.setBatchSize(batch_size = 1)\n",
        "        for i in range(36):\n",
        "            sample, labels = dataset[i]\n",
        "            plt.subplot(6,6,i+1)\n",
        "            plot_all(sample = sample,model=model, labels = labels)\n",
        "            plt.axis('off')\n",
        "        plt.savefig(title,dpi=600)\n",
        "\n",
        "dataset = PointDataset()\n",
        "PointDataset.displayCanvas('donut.png',dataset, model = None)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.) tensor(0.)\n",
            "tensor(0.) tensor(1.)\n",
            "tensor(0.) tensor(2.)\n",
            "tensor(0.) tensor(3.)\n",
            "tensor(0.) tensor(4.)\n",
            "tensor(0.) tensor(5.)\n",
            "tensor(0.) tensor(6.)\n",
            "tensor(0.) tensor(7.)\n",
            "tensor(0.) tensor(8.)\n",
            "tensor(0.) tensor(9.)\n",
            "tensor(0.) tensor(10.)\n",
            "tensor(0.) tensor(11.)\n",
            "tensor(0.) tensor(12.)\n",
            "tensor(0.) tensor(13.)\n",
            "tensor(0.) tensor(14.)\n",
            "tensor(0.) tensor(15.)\n",
            "tensor(0.) tensor(16.)\n",
            "tensor(0.) tensor(17.)\n",
            "tensor(0.) tensor(18.)\n",
            "tensor(0.) tensor(19.)\n",
            "tensor(0.) tensor(20.)\n",
            "tensor(0.) tensor(21.)\n",
            "tensor(0.) tensor(22.)\n",
            "tensor(0.) tensor(23.)\n",
            "tensor(0.) tensor(24.)\n",
            "tensor(0.) tensor(25.)\n",
            "tensor(0.) tensor(26.)\n",
            "tensor(0.) tensor(27.)\n",
            "tensor(0.) tensor(28.)\n",
            "tensor(0.) tensor(29.)\n",
            "tensor(0.) tensor(30.)\n",
            "tensor(0.) tensor(31.)\n",
            "tensor(1.) tensor(0.)\n",
            "tensor(1.) tensor(1.)\n",
            "tensor(1.) tensor(2.)\n",
            "tensor(1.) tensor(3.)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IyF9OVbU6L9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.input_dim = 1024\n",
        "        self.hidden_dim = 2**11\n",
        "        self.midl=1\n",
        "        self.inLayer = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, (int)(self.input_dim)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "         )\n",
        "        self.midLayers1 = nn.Sequential(\n",
        "            nn.Linear((int)(self.input_dim), (int)(self.input_dim)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        )        \n",
        "        self.midLayers2 = nn.Sequential(\n",
        "            nn.Linear((int)(self.input_dim), (int)(self.input_dim)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        )        \n",
        "        self.out_layer = nn.Sequential(\n",
        "           nn.Linear((int)(self.input_dim), (int)(self.input_dim*2)),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        mini_batch = x.shape[0]\n",
        "        #x = x.squeeze()\n",
        "        #x = torch.flatten(x,start_dim=1)\n",
        "\n",
        "        #x = torch.cat([x,torch.flatten(points,start_dim=1)],dim=1)\n",
        "        \n",
        "        x = torch.flatten(x,start_dim=1)\n",
        "\n",
        "        assert x.shape == (mini_batch,self.input_dim)\n",
        "        out = self.inLayer(x)\n",
        "        \n",
        "        out = self.midLayers1(out)\n",
        "        out = self.midLayers2(out)\n",
        "        \n",
        "        out = self.out_layer(out)\n",
        "        out = 32*out\n",
        "\n",
        "        out = out.reshape(mini_batch,1024,2)\n",
        "        b = torch.zeros(128,2).cuda()\n",
        "        for i in range(mini_batch):\n",
        "          b[i,:] = torch.matmul(x[i,:],out[i,:,:])\n",
        "        \n",
        "        return b\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6XNChz2eKvr",
        "outputId": "ad1b58dd-8183-4aec-8201-6980ea7b6ad3"
      },
      "source": [
        "a = torch.zeros(128,1024)\n",
        "b = torch.zeros(1024,2)\n",
        "print(torch.matmul(a,b).shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlymtKDGWaEq"
      },
      "source": [
        "\n",
        "model = MLP().cuda()\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zb57sQfWfnl"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.00001, betas = (.9,.999))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC01l8__WiWW",
        "outputId": "0c41d20c-0a5e-44fa-a00b-e3dded0de9d0"
      },
      "source": [
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 128\n",
        "dataset = PointDataset()\n",
        "loader_train = data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=dataset),\n",
        "    num_workers=4)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWrrBVtrWvUS",
        "outputId": "8376394b-ad9a-4b34-93b1-f0472d4e3fee"
      },
      "source": [
        "epoch = 200\n",
        "for e in range(epoch):\n",
        "  for xin,yin in loader_train:\n",
        "    if xin.shape[0] != mini_batch:\n",
        "      print(xin.shape)\n",
        "      continue\n",
        "    xin = xin.cuda()\n",
        "    yin = yin.cuda()\n",
        "    out = model(xin)\n",
        "    #print(out.shape, yin.shape)\n",
        "    loss = torch.mean((out-yin)**2)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  print(e,'\\t', loss)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 \t tensor(1.8013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "1 \t tensor(1.5117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "2 \t tensor(1.4425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "3 \t tensor(1.7835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "4 \t tensor(1.7888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "5 \t tensor(1.6784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "6 \t tensor(1.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "7 \t tensor(1.5485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "8 \t tensor(1.4189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "9 \t tensor(1.5633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "10 \t tensor(1.3892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "11 \t tensor(1.5696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "12 \t tensor(1.9404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "13 \t tensor(1.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "14 \t tensor(1.6800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "15 \t tensor(1.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "16 \t tensor(1.4236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "17 \t tensor(1.3793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "18 \t tensor(1.6723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "19 \t tensor(1.4590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "20 \t tensor(1.4290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "21 \t tensor(1.7248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "22 \t tensor(1.5482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "23 \t tensor(1.5499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "24 \t tensor(1.5347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "25 \t tensor(1.4160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "26 \t tensor(1.4258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "27 \t tensor(1.5060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "28 \t tensor(1.2966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "29 \t tensor(1.4812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "30 \t tensor(1.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "31 \t tensor(1.5108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "32 \t tensor(1.3306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "33 \t tensor(1.2157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "34 \t tensor(1.2495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "35 \t tensor(1.4621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "36 \t tensor(1.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "37 \t tensor(1.3510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "38 \t tensor(1.5099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "39 \t tensor(1.4180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "40 \t tensor(1.4009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "41 \t tensor(1.5948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "42 \t tensor(1.5289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "43 \t tensor(1.4048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "44 \t tensor(1.3999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "45 \t tensor(1.5204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "46 \t tensor(1.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "47 \t tensor(1.3888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "48 \t tensor(1.3687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "49 \t tensor(1.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "50 \t tensor(1.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "51 \t tensor(1.3980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "52 \t tensor(1.5263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "53 \t tensor(1.4325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "54 \t tensor(1.4277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "55 \t tensor(1.1539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "56 \t tensor(1.2021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "57 \t tensor(1.2570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "58 \t tensor(1.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "59 \t tensor(1.2447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "60 \t tensor(1.4375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "61 \t tensor(1.4137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "62 \t tensor(1.2311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "63 \t tensor(1.2795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "64 \t tensor(1.1944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "65 \t tensor(1.3295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "66 \t tensor(1.2844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "67 \t tensor(1.2537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "68 \t tensor(1.2005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "69 \t tensor(1.0801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "70 \t tensor(1.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "71 \t tensor(1.2571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "72 \t tensor(1.3954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "73 \t tensor(1.2562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "74 \t tensor(1.3095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "75 \t tensor(1.1220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "76 \t tensor(1.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "77 \t tensor(1.2581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "78 \t tensor(1.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "79 \t tensor(1.3042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "80 \t tensor(1.2104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "81 \t tensor(1.2354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "82 \t tensor(1.5177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "83 \t tensor(1.2651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "84 \t tensor(1.2882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "85 \t tensor(1.3022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "86 \t tensor(1.2570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "87 \t tensor(1.1664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "88 \t tensor(1.0368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "89 \t tensor(1.0712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "90 \t tensor(1.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "91 \t tensor(1.1682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "92 \t tensor(1.1680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "93 \t tensor(1.2695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "94 \t tensor(0.9872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "95 \t tensor(1.0705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "96 \t tensor(1.3479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "97 \t tensor(1.1974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "98 \t tensor(1.4225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "99 \t tensor(1.2108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "100 \t tensor(1.0710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "101 \t tensor(1.1317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "102 \t tensor(0.9267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "103 \t tensor(1.2395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "104 \t tensor(1.3373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "105 \t tensor(1.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "106 \t tensor(1.1966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "107 \t tensor(1.0447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "108 \t tensor(1.0614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "109 \t tensor(1.0190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "110 \t tensor(1.1170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "111 \t tensor(1.2610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "112 \t tensor(1.0527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "113 \t tensor(1.1031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "114 \t tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "115 \t tensor(1.1429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "116 \t tensor(1.0472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "117 \t tensor(1.2292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "118 \t tensor(1.1195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "119 \t tensor(1.1240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "120 \t tensor(0.9511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "121 \t tensor(1.1571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "122 \t tensor(1.2239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "123 \t tensor(1.0859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "124 \t tensor(1.0767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "125 \t tensor(0.8957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "126 \t tensor(1.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "127 \t tensor(0.9815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "128 \t tensor(0.9958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "129 \t tensor(0.9479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "130 \t tensor(1.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "131 \t tensor(1.2933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "132 \t tensor(1.0161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "133 \t tensor(1.0080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "134 \t tensor(1.2132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "135 \t tensor(1.0265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "136 \t tensor(1.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "137 \t tensor(0.9518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "138 \t tensor(1.0907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "139 \t tensor(1.1423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "140 \t tensor(1.1050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "141 \t tensor(1.0314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "142 \t tensor(0.8937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "143 \t tensor(0.9666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "144 \t tensor(0.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "145 \t tensor(0.9571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "146 \t tensor(1.0483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "147 \t tensor(0.9194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "148 \t tensor(0.9867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "149 \t tensor(0.9123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "150 \t tensor(0.9400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "151 \t tensor(0.9638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "152 \t tensor(0.9842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "153 \t tensor(1.0938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "154 \t tensor(0.9907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "155 \t tensor(1.1306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "156 \t tensor(1.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "157 \t tensor(0.9057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "158 \t tensor(1.0220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "159 \t tensor(0.9281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "160 \t tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "161 \t tensor(0.9725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "162 \t tensor(0.9522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "163 \t tensor(1.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "164 \t tensor(1.1827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "165 \t tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "166 \t tensor(0.9521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "167 \t tensor(1.1113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "168 \t tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "169 \t tensor(1.0685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "170 \t tensor(1.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "171 \t tensor(0.9716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "172 \t tensor(0.9786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "173 \t tensor(1.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "174 \t tensor(0.7820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "175 \t tensor(1.1736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "176 \t tensor(0.9800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "177 \t tensor(1.0341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "178 \t tensor(1.0419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "179 \t tensor(0.8730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "180 \t tensor(1.1062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "181 \t tensor(0.8835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "182 \t tensor(0.9177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "183 \t tensor(0.8567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "184 \t tensor(0.9822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "185 \t tensor(0.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "186 \t tensor(1.0140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "187 \t tensor(0.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "188 \t tensor(1.0450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "189 \t tensor(0.9931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "190 \t tensor(1.0203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "191 \t tensor(0.9679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "192 \t tensor(0.9033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "193 \t tensor(1.0375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "194 \t tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "195 \t tensor(0.8807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "196 \t tensor(0.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "197 \t tensor(0.9138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "198 \t tensor(0.9358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "199 \t tensor(0.8915, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZkOklu9LW2_z",
        "outputId": "0771ac92-dab7-4aca-c20f-95a4ee049d3f"
      },
      "source": [
        "dataset = PointDataset()\n",
        "PointDataset.displayCanvas('donut.png',dataset, model = model)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([128, 2])\n",
            "type <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAADnCAYAAAB1wm/GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAKnElEQVR4nO3dS5LqVhYF0KMKdzwXER6JGUw1RfYqoVeTwSOxk8FU71ZDyUt4TotjP/TJe9eKIFTwHIF2Sbl19UNdKSUAeOxfa88AwFehMAGSFCZAksIESFKYAEk/Tf5r192fQl/+jHq3zLfc5FznqoH5c7aWMcL6OuMczP8N21yWRpjwlR0Oa89BUxQm1fjTGKSFMjmf156DpuQLs4UL3GX80v60D3U6VVmad0twv19rNpazoXV2ujBL+XjVTMY6lBLR9/efVTgC64ZhzDkMEcfj2rMzi9eIj4wbMn3SB76a/T7icrl/X5vjsdqivHqJGJfjdVluJG/34F7ytYcky5x1bCNnOxkPh3Fkud8v/YdmfX3aN9ycJe/7iLe32b/y+zn49EOFGRFt5JRxftbXp33DTWGuc+jh04x2yYHtGYa19hImGWGOWsgp4/ysr8+zyYyuwwRIUpgASQoTIElhAiQpTIAkhQmQpDABkhQmQJLCBEhSmABJChMgSWECJClMgCSFCZCkMAGSFCZAksIESFKYAEkKEyBJYQIkKUyApEdPjQTgnREmQJLCBEhSmABJChMgSWECJClMgKSfJv+16+6vOVr+EqRumW+5ybnOZVbz52wtY4T1dcY5mP8btrksjTABkvKF2cIF7jLWo4WcLWSM2FTO6V3yDc3orFrIKWM9Wsi50Yy5EebhELHbjVOARk2OMLuuizIMEafT+MHlMk6Px7nna3mHQ8T5HLHf15kP+GGTI8xSylgit75/X4HXrhs3CpfLOK15JG1vAf6xx7vk+/30+wq89P39BxVuFLquG0uyhQ2DjQIzmT7pE/Gxe1rz7up+/3G44fq+MqWUsURunc9VLc+mDiFFOIy0hlLK1Gttj+bvWa9ShqGUvh+ny1su43j+cXwtm3WZjH1/n7HvF4pXygx5Pn3FddnVvizX9el8uXD96niMeHure0t9PEYMQ0Tfj9MaszZwCKmU+s8tfDuEtLFDK493yanL8VhnUV61cAgpovrDSFs9tPLoERVrXz26zL25beSUcX7Lrq/rHcOcP+duV+42CH0/7gEu59OMRpjwVdW8t7DREbTCBLZno4dW7JKPWsgp4/ysr8+zyYzOkgMkKUyAJIUJkKQwAZIUJkCSwgRIUpgASQoTIElhAiQpTIAkhQmQpDABkhQmQJLCBEhSmABJj34PE4B3RpgASQoTIElhAiQpTIAkhQmQNP2Y3a67P4W+/Bn1ZZ7Cd5tznasG5s/ZWsYI6+uMczD/N2xzWRphAiTlC7OF6zVlrEcLOVvIGLGpnNO75Bua0Vm1kFPGerSQc6MZ7ZIDJClMgCSFCZCkMAGSFCZAksIESHpcmIdDxG43TgEaNnkd5mvXxcv1zeUyTo/HeecIYKMmR5gvfX//wfk857yspus6I2m+FuvrKqZ3yff76feVKMMQcTqNo+jTqcqVsOvef0ug9j+02vNFjNkqX183q5Qy9SplGErp+3G6vEfz95xX35cy3ow1vvp+sYDvlsg5LsPbnMsu09kz/uc22/L5yjOzTL5aWl831j2PZ3pdy6yA6xZJeWqWqWW57h+aInnSq4kNw0b/Jl1WFDGeyBqGiL4fp7We2Kr9EEvt+d69lFL9+vr76XT/wUbOnzx6zO7aPxmyzA+ytpFzzHg4jCvffr/0H9oyGdfLF2F9fZ7DocRtaS6/Yfg0o8IctZBTxvlZX59nkxs/hTlqIaeM87O+Ps8mMzqGCZCkMAGSFCZAksIESFKYAEkKEyBJYQIkKUyAJIUJkKQwAZIUJkDSo3vJAXhnhAmQpDABkhQmQJLCBEhSmABJP03+a9fdn0Jf/oz6Mr9gfZtznasG5s/ZWsYI6+uMczD/N2xzWRphAiQpTICkfGG2cIG7jPVoIWcLGSM2lXP6GOaGZnRWLeSUsR4t5NxoRrvkAEkKEyBJYQIkKUyAJIUJkKQwAZIUJkCSwgRIUpgASQoTIElhXh0OEbvdOAX4xPS95FeHQ8T5HLHfRxyPM8/SCg6HiNNp/N+XyzitMSfwQyZHmF3XfZTJ5TJOaxyBnc/T72thFA0/ZLIwSylNlMnrdVR5td+vMyNzamHDd2XDwEweH8P8vjwqLJOXUiKGIaLvx2mFu+O/Xw85XFW44YuIdjYMNgrrKKVMvUbDUErfj9NlPZq/Z73WNn/GYShl/JXB8VXhsoyIcT29zdn3yyVcan1tYFkuF+UvfTpfXSmTP9S59q94LvNQqTZylpVP3i2X8XY0vewewyLr6+9dV365/aDvI97elvjqq2WWZcSaJ5w/z/hXTVo23PIzvNYm4zMz1r5H1MAIM6651sv56XwZYY5ayCnj/JZbX1vYW9jtPi7zi1h6JP1pxtx1mMC2HI9Vnpy8s9/fF+YGTjgrTGCbrhuEDd00Y5d81EJOGednfX2eTWZ0LzlAksIESFKYAEkKEyDp0UkfAN4ZYQIkKUyAJIUJkKQwAZIUJkDS9L3kXXd/Cn35M+rL3Gp2m3Odqwbmz9laxgjr64xzMP83bHNZGmECJClMgKR8YbZwgbuM9WghZwsZIzaVc/oY5oZmdFYt5JSxHi3k3GhGu+QASQoTIElhAiQpTIAkhQmQpDABkhQmQJLCBEhSmABJChMgSWECJClMgCSFCZCkMAGSFCZAksIESFKYAEkKEyDpcWEeDhG73TgFaNjkM31euy5erm8ul3F6PM47RwAbNTnCfOn7+w/O5znnZTWvXWcUXQN7Q8xs+qmR+/3HyPL6vkIvEWPOikfRr103bgD3+yrzRUTE6TROK16OrKsr04+zLHE4jCPLdf7QumW+pfv4P6HvI97eFvna2zmY/xtuMg5DncuyheU4auHvcu3n7H6a8fFJn+NxXPFa2VpXOoq+U+mhlTsVL8fXrhtH05fLOK31EMQGD7FM75K3YhjW3Fovr9YyaWQ5vvT9/aGy87m6vFs94fx4l3xdy+3irGv+nIdDWblMmt2Ne7rDoXw7XhuxxiGW+XPuduVuo7D8IZZPMxphtuJ43MQWmie4LseaR9MbPeH8aIQJsI6ue42IXyPityjl5dF/vgSFCZDkXnKAJIUJkKQwAZIUJkDS48uKbm83i4hY7iTRUtdgvn/bTc5lT4Qtf/vnOif6lr01MmKNnJbl075hm8vSCBO+oG/1saHbBlvw9wqzhUuQas9Ye76rynN+G/5UfC/5tyU4DGvOxp3HhVnKx6tmtWesPV9EO+tqC79TOwyb3CjYJYev5vvbBDdy2+BTfb8R2MhGwb3k8NW4l3w1mVsj19q/WfYsef05195P9WtFz9NCzk3+SLLC/FB7zjb+yNZlWT7PJjM6hgmQpDABkhQmQJLCBEhSmABJChMgSWECJClMgCSFCZCkMAGSFCZAksIESFKYAEkKEyBJYQIkKUyAJIUJkKQwAZIUJkDSw8L8788/R+x2m3ku8GxayAj8kIeP2f33//43Pu7y+sjLGh/pGdFGRuCHPH5qZNfd/gd/RCm/zDpHa/nIWWvGTT6F78layBjRRs5NZvy7xzB/e8KMbF0LGYF/4OEueUQcI+LXiPgtSnmZeX7W9EfUnXHp57yvoYWMEW3k3GTGx7vkAESEy4oA0hQmQJLCBEhSmABJChMg6f+mEtiDqmuTYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLOXIFa6iD7w"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}