{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pixelcnn-playground.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLYxB43r/2M96gvTtlJ/Bl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/pixelcnn_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi46Kt7EGbVL"
      },
      "source": [
        "'''\n",
        "Code by Hrituraj Singh\n",
        "Indian Institute of Technology Roorkee\n",
        "'''\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import configparser\n",
        "import os\n",
        "\n",
        "def get_MNIST(path):\n",
        "    \"\"\"\n",
        "    Loads the train and test MNIST data and returns both after \n",
        "    trainsforming the images to tensors. Downloads the data if \n",
        "    not on local path\n",
        "    \"\"\"\n",
        "    assert os.path.exists(path), 'The dataloading path does not exist!'\n",
        "    train_data = datasets.MNIST(root=path,\n",
        "                                train=True,\n",
        "                                download=True,\n",
        "                                transform=transforms.ToTensor())\n",
        "    test_data = datasets.MNIST(root=path,\n",
        "                               train=False,\n",
        "                               download=True,\n",
        "                               transform=transforms.ToTensor())\n",
        "    return train_data, test_data\n",
        "\n",
        "\n",
        "def parse_config(filename):\n",
        "    config = configparser.ConfigParser()\n",
        "    config.read(filename)\n",
        "    output = {}\n",
        "    for section in config.sections():\n",
        "        output[section] = {}\n",
        "        for key in config[section]:\n",
        "            val_str = str(config[section][key])\n",
        "            if(len(val_str)>0):\n",
        "                val = parse_value_from_string(val_str) \n",
        "            else:\n",
        "                val = None\n",
        "            print(section, key,val_str, val)\n",
        "            output[section][key] = val\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def parse_value_from_string(val_str):\n",
        "    if(is_int(val_str)):\n",
        "        val = int(val_str)\n",
        "    elif(is_float(val_str)):\n",
        "        val = float(val_str)\n",
        "    elif(is_list(val_str)):\n",
        "        val = parse_list(val_str)\n",
        "    elif(is_bool(val_str)):\n",
        "        val = parse_bool(val_str)\n",
        "    else:\n",
        "        val = val_str\n",
        "    return val\n",
        "\n",
        "def is_int(val_str):\n",
        "    start_digit = 0\n",
        "    if(val_str[0] =='-'):\n",
        "        start_digit = 1\n",
        "    flag = True\n",
        "    for i in range(start_digit, len(val_str)):\n",
        "        if(str(val_str[i]) < '0' or str(val_str[i]) > '9'):\n",
        "            flag = False\n",
        "            break\n",
        "    return flag\n",
        "\n",
        "def is_float(val_str):\n",
        "    flag = False\n",
        "    if('.' in val_str and len(val_str.split('.'))==2):\n",
        "        if(is_int(val_str.split('.')[0]) and is_int(val_str.split('.')[1])):\n",
        "            flag = True\n",
        "        else:\n",
        "            flag = False\n",
        "    elif('e' in val_str and len(val_str.split('e'))==2):\n",
        "        if(is_int(val_str.split('e')[0]) and is_int(val_str.split('e')[1])):\n",
        "            flag = True\n",
        "        else:\n",
        "            flag = False       \n",
        "    else:\n",
        "        flag = False\n",
        "    return flag \n",
        "\n",
        "def is_bool(var_str):\n",
        "    if( var_str=='True' or var_str == 'true' or var_str =='False' or var_str=='false'):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def parse_bool(var_str):\n",
        "    if(var_str=='True' or var_str == 'true' ):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "     \n",
        "def is_list(val_str):\n",
        "    if(val_str[0] == '[' and val_str[-1] == ']'):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def parse_list(val_str):\n",
        "    sub_str = val_str[1:-1]\n",
        "    splits = sub_str.split(',')\n",
        "    output = []\n",
        "    for item in splits:\n",
        "        item = item.strip()\n",
        "        if(is_int(item)):\n",
        "            output.append(int(item))\n",
        "        elif(is_float(item)):\n",
        "            output.append(float(item))\n",
        "        elif(is_bool(item)):\n",
        "            output.append(parse_bool(item))\n",
        "        else:\n",
        "            output.append(item)\n",
        "    return output\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjJC_FCIANEm"
      },
      "source": [
        "'''\n",
        "https://github.com/singh-hrituraj/PixelCNN-Pytorch/blob/master/MaskedCNN.py\n",
        "Code by Hrituraj Singh\n",
        "Indian Institute of Technology Roorkee\n",
        "'''\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "\n",
        "class MaskedCNN(nn.Conv2d):\n",
        "\t\"\"\"\n",
        "\tImplementation of Masked CNN Class as explained in A Oord et. al. \n",
        "\tTaken from https://github.com/jzbontar/pixelcnn-pytorch\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self, mask_type, *args, **kwargs):\n",
        "\t\tself.mask_type = mask_type\n",
        "\t\tassert mask_type in ['A', 'B'], \"Unknown Mask Type\"\n",
        "\t\tsuper(MaskedCNN, self).__init__(*args, **kwargs)\n",
        "\t\tself.register_buffer('mask', self.weight.data.clone())\n",
        "\n",
        "\t\t_, depth, height, width = self.weight.size()\n",
        "\t\tself.mask.fill_(1)\n",
        "\t\tif mask_type =='A':\n",
        "\t\t\tself.mask[:,:,height//2,width//2:] = 0\n",
        "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
        "\t\telse:\n",
        "\t\t\tself.mask[:,:,height//2,width//2+1:] = 0\n",
        "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
        "\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tself.weight.data*=self.mask\n",
        "\t\treturn super(MaskedCNN, self).forward(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#from MaskedCNN import MaskedCNN\n",
        "import torch.nn as nn\n",
        "\n",
        "class PixelCNN(nn.Module):\n",
        "\t\"\"\"\n",
        "\tNetwork of PixelCNN as described in A Oord et. al. \n",
        "\t\"\"\"\n",
        "\tdef __init__(self, no_layers=8, kernel = 7, channels=64, device=None):\n",
        "\t\tsuper(PixelCNN, self).__init__()\n",
        "\t\tself.no_layers = no_layers\n",
        "\t\tself.kernel = kernel\n",
        "\t\tself.channels = channels\n",
        "\t\tself.layers = {}\n",
        "\t\tself.device = device\n",
        "\n",
        "\t\tself.Conv2d_1 = MaskedCNN('A',1,channels, kernel, 1, kernel//2, bias=False)\n",
        "\t\tself.BatchNorm2d_1 = nn.BatchNorm2d(channels)\n",
        "\t\tself.ReLU_1= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv2d_2 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
        "\t\tself.BatchNorm2d_2 = nn.BatchNorm2d(channels)\n",
        "\t\tself.ReLU_2= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv2d_3 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
        "\t\tself.BatchNorm2d_3 = nn.BatchNorm2d(channels)\n",
        "\t\tself.ReLU_3= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv2d_4 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
        "\t\tself.BatchNorm2d_4 = nn.BatchNorm2d(channels)\n",
        "\t\tself.ReLU_4= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv2d_5 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
        "\t\tself.BatchNorm2d_5 = nn.BatchNorm2d(channels)\n",
        "\t\tself.ReLU_5= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv2d_6 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
        "\t\tself.BatchNorm2d_6 = nn.BatchNorm2d(channels)\n",
        "\t\tself.ReLU_6= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv2d_7 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
        "\t\tself.BatchNorm2d_7 = nn.BatchNorm2d(channels)\n",
        "\t\tself.ReLU_7= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv2d_8 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
        "\t\tself.BatchNorm2d_8 = nn.BatchNorm2d(channels)\n",
        "\t\tself.ReLU_8= nn.ReLU(True)\n",
        "\n",
        "\t\tself.out = nn.Conv2d(channels, 256, 1)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.Conv2d_1(x)\n",
        "\t\tx = self.BatchNorm2d_1(x)\n",
        "\t\tx = self.ReLU_1(x)\n",
        "\n",
        "\t\tx = self.Conv2d_2(x)\n",
        "\t\tx = self.BatchNorm2d_2(x)\n",
        "\t\tx = self.ReLU_2(x)\n",
        "\n",
        "\t\tx = self.Conv2d_3(x)\n",
        "\t\tx = self.BatchNorm2d_3(x)\n",
        "\t\tx = self.ReLU_3(x)\n",
        "\n",
        "\t\tx = self.Conv2d_4(x)\n",
        "\t\tx = self.BatchNorm2d_4(x)\n",
        "\t\tx = self.ReLU_4(x)\n",
        "\n",
        "\t\tx = self.Conv2d_5(x)\n",
        "\t\tx = self.BatchNorm2d_5(x)\n",
        "\t\tx = self.ReLU_5(x)\n",
        "\n",
        "\t\tx = self.Conv2d_6(x)\n",
        "\t\tx = self.BatchNorm2d_6(x)\n",
        "\t\tx = self.ReLU_6(x)\n",
        "\n",
        "\t\tx = self.Conv2d_7(x)\n",
        "\t\tx = self.BatchNorm2d_7(x)\n",
        "\t\tx = self.ReLU_7(x)\n",
        "\n",
        "\t\tx = self.Conv2d_8(x)\n",
        "\t\tx = self.BatchNorm2d_8(x)\n",
        "\t\tx = self.ReLU_8(x)\n",
        "\n",
        "\t\treturn self.out(x)\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-ZFeel3DuL8"
      },
      "source": [
        "model = PixelCNN()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGeWJPXIEGD1"
      },
      "source": [
        "import torch\n",
        "a = torch.zeros(64,1,32,32)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umD_ttXJEKzx",
        "outputId": "dbd46458-4af8-493d-9f8a-a4f169afbc23"
      },
      "source": [
        "b = model(a)\n",
        "b.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 256, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "RSt__yVqEOXC",
        "outputId": "e9dad467-3a33-4ed7-8192-39f19519c234"
      },
      "source": [
        "'''\n",
        "Code by Hrituraj Singh\n",
        "Indian Institute of Technology Roorkee\n",
        "'''\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils import data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "#from utils import *\n",
        "#from Model import PixelCNN\n",
        "\n",
        "\n",
        "def main(config_file):\n",
        "\tconfig = parse_config(config_file)\n",
        "\tdata_ = config['data']\n",
        "\tnetwork = config['network']\n",
        "\n",
        "\tpath = data_.get('path', 'Data') #Path where the data after loading is to be saved\n",
        "\tdata_name = data_.get('data_name','MNIST') #What data type is to be loaded ex - MNIST, CIFAR\n",
        "\tbatch_size = data_.get('batch_size', 144)\n",
        "\n",
        "\tlayers = network.get('no_layers', 8) #Number of layers in the network\n",
        "\tkernel = network.get('kernel', 7) #Kernel size\n",
        "\tchannels = network.get('channels', 64) #Depth of the intermediate layers\n",
        "\tepochs = network.get('epochs', 25) #No of epochs\n",
        "\tsave_path = network.get('save_path', 'Models') #path where the models are to be saved\n",
        "\t#Loading Data\n",
        "\tif (data_name=='MNIST'):\n",
        "\t\ttrain, test = get_MNIST(path)\n",
        "\n",
        "\ttrain = data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers =1, pin_memory = True)\n",
        "\ttest = data.DataLoader(train, batch_size=batch_size, shuffle=False, num_workers =1, pin_memory = True)\n",
        "\t#Defining the model and training it on loss function\n",
        "\tdevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tnet = PixelCNN().to(device)\n",
        "\tif torch.cuda.device_count() > 1: # If more than one GPU available, accelerate the training using multiple GPUs\n",
        "\t\tprint(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "\t\tnet = nn.DataParallel(net)\n",
        "\t\n",
        "\toptimizer = optim.Adam(net.parameters())\n",
        "\tcriterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\tloss_overall = []\n",
        "\ttime_start = time.time()\n",
        "\tprint('Training Started')\n",
        "\n",
        "\tfor i in range(epochs):\n",
        "\t\tnet.train(True)\n",
        "\t\tstep = 0\n",
        "\t\tloss_= 0\n",
        "\t\t\n",
        "\t\tfor images, labels in train:\n",
        "\t\t\ttarget = Variable(images[:,0,:,:]*255).long()\n",
        "\t\t\timages = images.to(device)\n",
        "\t\t\ttarget = target.to(device)\n",
        "\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\tprint('image.shape',images.shape)\n",
        "\t\t\toutput = net(images)\n",
        "\t\t\tprint('output.shape',output.shape)\n",
        "\t\t\tprint('target.shape',target.shape)\n",
        "\t\t\tprint(torch.sum(target))\n",
        "\t\t\tloss = criterion(output, target)\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()\n",
        "\t\t\tloss_+=loss\n",
        "\t\t\tstep+=1\n",
        "\n",
        "\t\t\tif(step%100 == 0):\n",
        "\t\t\t\tprint('Epoch:'+str(i)+'\\t'+ str(step) +'\\t Iterations Complete \\t'+'loss: ', loss.item()/1000.0)\n",
        "\t\t\t\tloss_overall.append(loss_/1000.0)\n",
        "\t\t\t\tloss_=0\n",
        "\t\tprint('Epoch: '+str(i)+' Over!')\n",
        "\n",
        "\t\t#Saving the model\n",
        "\t\tif not os.path.exists(save_path):\n",
        "\t\t\tos.makedirs(save_path)\n",
        "\t\tprint(\"Saving Checkpoint!\")\n",
        "\t\tif(i==epochs-1):\n",
        "\t\t\ttorch.save(net.state_dict(), save_path+'/Model_Checkpoint_'+'Last'+'.pt')\n",
        "\t\telse:\n",
        "\t\t\ttorch.save(net.state_dict(), save_path+'/Model_Checkpoint_'+str(i)+'.pt')\n",
        "\t\tprint('Checkpoint Saved')\n",
        "  \n",
        "\n",
        "#print('Training Finished! Time Taken: ', time.time()-time_start)\n",
        "\n",
        "\n",
        "#if __name__==\"__main__\":\n",
        "config_file = 'config/config_train.txt'\n",
        "assert os.path.exists(config_file), \"Configuration file does not exit!\"\n",
        "main(config_file)\n",
        "\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data path Data Data\n",
            "network no_layers 8 8\n",
            "network kernel 7 7\n",
            "network channels 64 64\n",
            "Training Started\n",
            "image.shape torch.Size([144, 1, 28, 28])\n",
            "output.shape torch.Size([144, 256, 28, 28])\n",
            "target.shape torch.Size([144, 28, 28])\n",
            "tensor(3940184)\n",
            "image.shape torch.Size([144, 1, 28, 28])\n",
            "output.shape torch.Size([144, 256, 28, 28])\n",
            "target.shape torch.Size([144, 28, 28])\n",
            "tensor(3821921)\n",
            "image.shape torch.Size([144, 1, 28, 28])\n",
            "output.shape torch.Size([144, 256, 28, 28])\n",
            "target.shape torch.Size([144, 28, 28])\n",
            "tensor(3788349)\n",
            "image.shape torch.Size([144, 1, 28, 28])\n",
            "output.shape torch.Size([144, 256, 28, 28])\n",
            "target.shape torch.Size([144, 28, 28])\n",
            "tensor(3888760)\n",
            "image.shape torch.Size([144, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-147db43ab1e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'config/config_train.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Configuration file does not exit!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-147db43ab1e3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config_file)\u001b[0m\n\u001b[1;32m     62\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image.shape'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output.shape'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target.shape'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-4bed8bc2f386>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-4bed8bc2f386>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m*=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaskedCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bByuJYguGQYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1617f5d-b52d-4ad5-88c7-5f576e56813d"
      },
      "source": [
        "print((144*256*28*28-3936197)/(144*256*28*28))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8638058963005775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOYWNCU7ScMf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}