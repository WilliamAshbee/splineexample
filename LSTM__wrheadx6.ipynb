{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_-wrheadx6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrAuqbsG7I5oCZQNgnPme1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/LSTM__wrheadx6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GuTzOJ5E0oN"
      },
      "source": [
        "With progressive growing of the sequence, the loss drops more stably. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp7036kWzHdc"
      },
      "source": [
        "#TODO:TEST A DIFFERENT TYPE OF WRITE HEAD (ADD A SECOND LTM MEMORY MODULE)\n",
        "#TODO:TEST A DIFFERENT TYPE OF LOSS TO SMOOTH OUT THE BLURRY READ/WRITE."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E5VVeE0nEn4"
      },
      "source": [
        "https://r2rt.com/non-zero-initial-states-for-recurrent-neural-networks.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPJLPR-jCBtx"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from skimage import filters\n",
        "import math\n",
        "\n",
        "global numpoints\n",
        "numpoints = 1000\n",
        "side = 32\n",
        "\n",
        "rows = torch.zeros(32,32)\n",
        "columns = torch.zeros(32,32)\n",
        "\n",
        "\n",
        "for i in range(32):\n",
        "    columns[:,i] = i\n",
        "    rows[i,:] = i\n",
        "\n",
        "\n",
        "def donut_matrix(length = 10):\n",
        "\n",
        "    radiusMax = side /3\n",
        "    w = 1\n",
        "    sigmas = [None, 1]\n",
        "    \n",
        "    canvas = torch.zeros((length,side, side))\n",
        "    r0 = torch.tensor(np.random.uniform(side/4, side/3, length))\n",
        "\n",
        "    radii = torch.zeros((length,numpoints))\n",
        "    radii[:, :] = r0.unsqueeze(1)\n",
        "    \n",
        "    ind = [x for x in range(numpoints)]\n",
        "\n",
        "    theta = torch.FloatTensor(ind)\n",
        "    theta *= math.pi*2.0/(float)(numpoints)\n",
        "    \n",
        "    for i in range(1,length):\n",
        "        a = np.random.uniform(1.0,3.0)*torch.sin(np.random.uniform(20.0)*theta+np.random.uniform(1000.0))\n",
        "        #a = 4.0*torch.sin(10.0*theta)\n",
        "        #print(a.shape,torch.max(a))\n",
        "        radii[i,:] += a\n",
        "        #print(radii.shape, torch.max(radii))\n",
        "    \n",
        "    assert torch.min(radii)>0\n",
        "    #print(radii.max(axis = 0)[0].shape)\n",
        "    rmaxs = radii.max(axis = 1)[0]\n",
        "    pmins = rmaxs+1.0\n",
        "    pmaxs = side-rmaxs-1.0\n",
        "    x0 = np.random.uniform(pmins,pmaxs)\n",
        "    y0 = np.random.uniform(pmins,pmaxs)\n",
        "    x0[:]=side/2\n",
        "    y0[:]=side/2\n",
        "    x0 = torch.tensor(x0)\n",
        "    y0 = torch.tensor(y0)\n",
        "    \n",
        "    x0 = x0.unsqueeze(1)\n",
        "    y0 = y0.unsqueeze(1)\n",
        "    #radii = torch.from_numpy(radii)\n",
        "    xrfactors = torch.cos(theta).unsqueeze(0)\n",
        "    yrfactors = torch.sin(theta).unsqueeze(0)\n",
        "    \n",
        "    print('x0_y0_r_xrf_yrf',x0.shape,y0.shape,radii.shape,xrfactors.shape,yrfactors.shape)\n",
        "\n",
        "    x = (x0+(xrfactors*radii))\n",
        "    y = (y0+(yrfactors*radii))\n",
        "    assert x.shape == (length,numpoints)\n",
        "    assert y.shape == (length,numpoints)\n",
        "    assert torch.sum(x[x>(side-1)])==0 \n",
        "    assert torch.sum(x[x<0])==0 \n",
        "    assert torch.sum(y[y>(side-1)])==0 \n",
        "    assert torch.sum(y[y<0])==0 \n",
        "    \n",
        "    points = torch.zeros(length,numpoints,2)\n",
        "    for l in range(length):\n",
        "        canvas[l,y[l,:].type(torch.LongTensor),x[l,:].type(torch.LongTensor)]=1.0\n",
        "        points[l,:,0] = x[l,:]#modified for lstm discriminator\n",
        "        points[l,:,1] = y[l,:]#modified for lstm discriminator \n",
        "    \n",
        "    \n",
        "    return {\n",
        "        'canvas': canvas, \n",
        "        'points':points.type(torch.FloatTensor)}\n",
        "\n",
        "def plot_all_model( sample = None, label=None,fig=None,ax=None):\n",
        "    X = label[:,0]\n",
        "    Y = label[:,1]\n",
        "    img = sample[:,:].detach().squeeze().cpu().numpy()\n",
        "    ax.imshow(img, cmap=plt.cm.gray_r)\n",
        "    predres = 1000\n",
        "\n",
        "    s = [.001 for x in range(predres)]\n",
        "    \n",
        "    assert len(s) == predres\n",
        "    c = ['red' for x in range(predres)]\n",
        "    assert len(c) == predres\n",
        "    ax.scatter(X.detach().cpu().numpy(),Y.detach().cpu().numpy(),s = s,c = c)\n",
        "\n",
        "\n",
        "def getXYs(model=None,loader_disp = None):\n",
        "\n",
        "    outputs = torch.zeros(100,1000,2).cuda()\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    \n",
        "    for samples,labels in loader_disp:\n",
        "      for i in range(38):\n",
        "        optimizer.zero_grad()\n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(samples.cuda(),labels[:,0,:2].cuda(),h0,c0,ind = i)\n",
        "          outputs[:,i*25:(i+1)*25,:] = out.detach()\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(samples.cuda(),labels[:,0,:2].cuda(),h0,c0,ind = i,o = o,output=output)\n",
        "          outputs[:,i*25:(i+1)*25,:] = out.detach()\n",
        "\n",
        "      return samples, outputs\n",
        "\n",
        "\n",
        "          \n",
        "        \n",
        "\n",
        "def plot_all( sample = None, labels = None,fig = None,ax = None):\n",
        "    img = sample[:,:].squeeze().cpu().numpy()\n",
        "    ax.imshow(img, cmap=plt.cm.gray_r)\n",
        "    X = labels[:,0]\n",
        "    Y = labels[:,1]\n",
        "    s = [.001 for x in range(numpoints)]\n",
        "    c = ['red' for x in range(numpoints)]\n",
        "    ax.scatter(X.cpu().numpy(),Y.cpu().numpy(),s = s,c = c)\n",
        "    \n",
        "class DonutDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Donut dataset.\"\"\"\n",
        "    def __init__(self, length = 10):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.length = length\n",
        "        self.values = donut_matrix(length)\n",
        "        assert self.values['canvas'].shape[0] == self.length\n",
        "        assert self.values['points'].shape[0] == self.length\n",
        "        \n",
        "        count = 0\n",
        "        for i in range(self.length):\n",
        "          a = self[i]\n",
        "          c = a[0]\n",
        "          for el in a[1]:\n",
        "            #print(c[(int)(el[1]),(int)(el[0])].item())\n",
        "            #assert c[(int)(el[1]),(int)(el[0])].item() == 1\n",
        "            y,x = (int)(el[1]),(int)(el[0])\n",
        "            if x < side-2 and x > 2 and y < side-2 and y > 2: \n",
        "              if c[y,x] != 1 and \\\n",
        "                c[y+1,x] != 1 and c[y+1,-1+x] != 1 and c[y+1,1+x] != 1 and \\\n",
        "                c[y-1,x] != 1 and c[y,-1+x] != 1 and c[y,1+x] != 1:\n",
        "                count+=1\n",
        "        assert count ==0\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        canvas = self.values[\"canvas\"]\n",
        "        \n",
        "        canvas = canvas[idx,:,:]\n",
        "        assert canvas.shape == (side,side)\n",
        "        \n",
        "        points = self.values[\"points\"]\n",
        "        points = points[idx,:]\n",
        "        #points = points.unsqueeze(1)\n",
        "        #z = torch.zeros(numpoints,1)\n",
        "        #print(z.shape)\n",
        "        #points = torch.cat([points,z], dim = 1)\n",
        "        \n",
        "        #print('points', points.shape)\n",
        "        return canvas, points\n",
        "    \n",
        "    @staticmethod\n",
        "    def displayCanvas(title,ddataset, model):\n",
        "        #model.setBatchSize(batch_size = 1)\n",
        "        fig = plt.figure()\n",
        "          \n",
        "        if model != None:\n",
        "          #model = model.eval()\n",
        "          loader_disp = data.DataLoader(\n",
        "            ddataset, \n",
        "            batch_size=100,\n",
        "            num_workers=2)\n",
        "          samples, outputs = getXYs(model=model,loader_disp = loader_disp)\n",
        "          for i in range(100):\n",
        "            ax = fig.add_subplot(10,10,i+1)\n",
        "            plot_all_model(samples[i,:,:],outputs[i,:,:],fig=fig,ax=ax)\n",
        "            plt.axis('off')\n",
        "\n",
        "        else:\n",
        "          for i in range(100):\n",
        "            sample, labels = dataset[i]\n",
        "            ax = fig.add_subplot(10,10,i+1)\n",
        "            plot_all(sample = sample,labels = labels,fig = fig, ax= ax)\n",
        "            plt.axis('off')\n",
        "\n",
        "        fig.savefig(title,dpi=450)\n",
        "        plt.close(fig) #where f is the figure\n",
        "        plt.clf()\n",
        "        plt.cla()\n",
        "        plt.close()#should free memory\n",
        "        print('open file: ',title)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xHhbWDJ7UUX"
      },
      "source": [
        "dataset = DonutDataset(length = 100)\n",
        "\n",
        "DonutDataset.displayCanvas('donut.png',dataset, model = None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhiJIwh0PvXT"
      },
      "source": [
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 100\n",
        "dataset = DonutDataset(length = 100*20)\n",
        "loader_train = data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=dataset),\n",
        "    num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxcdCGtH0ps1"
      },
      "source": [
        "mini_batch = 100\n",
        "test_dataset = DonutDataset(length = 1000)\n",
        "loader_test = data.DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=test_dataset),\n",
        "    num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGogHY1o699q"
      },
      "source": [
        "pred_dataset = DonutDataset(length = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHTtTB_x75NA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.track = 0\n",
        "        # define the properties\n",
        "        self.embed_size = 2\n",
        "        self.hidden_size = 256\n",
        "        self.num_layers = 2\n",
        "        self.seq_len = 25\n",
        "        self.full_len = 1000\n",
        "        self.longmem_len = int(self.full_len/self.seq_len)\n",
        "        self.longtermMem = None\n",
        "        self.longtermMemP = None\n",
        "        self.lstm_cell = nn.LSTM(self.hidden_size*2, self.hidden_size,self.num_layers)\n",
        "\n",
        "        self.inject_image =  nn.Sequential(\n",
        "            nn.Linear(2*1000+1024+9*self.hidden_size,self.hidden_size*2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        \n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Linear(2+self.hidden_size*11,10000),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(10000,2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.hi_1 = nn.Sequential(\n",
        "            nn.Linear(3*self.hidden_size,self.hidden_size),\n",
        "        )\n",
        "        self.hi_2 = nn.Sequential(\n",
        "            nn.Linear(3*self.hidden_size,self.hidden_size),\n",
        "        )\n",
        "\n",
        "        self.ci_1 = nn.Sequential(\n",
        "            nn.Linear(3*self.hidden_size,self.hidden_size),\n",
        "        )\n",
        "        self.ci_2 = nn.Sequential(\n",
        "            nn.Linear(3*self.hidden_size,self.hidden_size),\n",
        "        )\n",
        "\n",
        "        self.alpha_1 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2,self.seq_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        \n",
        "        self.alpha_long1 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2,self.longmem_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        \n",
        "        self.alpha_long2 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2,self.longmem_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        \n",
        "        self.alpha_long3 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2,self.longmem_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        self.alpha_long4 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2,self.longmem_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        self.alpha_long5 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2,self.longmem_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        self.alpha_long6 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2,self.longmem_len),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        \n",
        "        self.long_term_write = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*(self.seq_len+1),self.hidden_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "\n",
        "        self.embs = None #= torch.empty((self.batch_size, 1000, self.hidden_size)).cuda()\n",
        "        self.ltm_temp = None\n",
        "        \n",
        "\n",
        "            \n",
        "        \n",
        "    def forward(self, features, p0,h0 = None, c0= None, ind = 0, o = None,output = None):\n",
        "        #print('a')\n",
        "        assert features != None\n",
        "        self.track +=1\n",
        "        batch_size = features.size(0)\n",
        "        \n",
        "\n",
        "        \n",
        "        \n",
        "        if o == None:\n",
        "          out = p0\n",
        "          self.longtermMem = torch.zeros(batch_size,self.longmem_len,self.hidden_size).cuda()\n",
        "          self.embs = torch.empty((batch_size, self.seq_len, self.hidden_size)).cuda()\n",
        "          self.longtermMemP = torch.zeros(batch_size,1000,2).cuda()\n",
        "          self.ltm_temp = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "        else:\n",
        "\n",
        "          self.ltm_temp = self.long_term_write(torch.cat([torch.flatten(self.embs,start_dim=1),output.squeeze()],dim=1))\n",
        "          self.longtermMem[:, ind-1, :] = self.ltm_temp\n",
        "        \n",
        "          self.embs = torch.empty((batch_size, self.seq_len, self.hidden_size)).cuda()\n",
        "          \n",
        "          out = o\n",
        "\n",
        "        #print('c')\n",
        "        outputs = torch.empty((batch_size, self.seq_len, 2)).cuda()\n",
        "        \n",
        "        output = None\n",
        "        #print('b')\n",
        "        for t in range(self.seq_len):\n",
        "        \n",
        "            # for the first time step the input is the feature vector\n",
        "            if output == None:\n",
        "              output = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              outesread1 = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              outesreadl1 = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              outesreadl2 = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              outesreadl3 = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              outesreadl4 = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              outesreadl5 = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              outesreadl6 = torch.zeros(batch_size,self.hidden_size).cuda()\n",
        "              \n",
        "            combin_lstm = torch.cat([torch.flatten(features,start_dim=1),torch.flatten(self.longtermMemP,start_dim=1),output.squeeze(),outesread1,outesreadl1,outesreadl2,outesreadl3,outesreadl4,outesreadl5,outesreadl6,self.ltm_temp],dim=1)\n",
        "            combin_lstm = self.inject_image(combin_lstm)\n",
        "            \n",
        "            if h0 == None and c0 == None:\n",
        "              combin_init = torch.cat([combin_lstm,torch.zeros(batch_size,self.hidden_size).cuda()],dim=1)\n",
        "              h_0_1 = self.hi_1(combin_init)  \n",
        "              h_0_2 = self.hi_2(combin_init)  \n",
        "              c_0_1 = self.ci_1(combin_init)  \n",
        "              c_0_2 = self.ci_2(combin_init)  \n",
        "              \n",
        "              h0 = torch.stack([h_0_1,h_0_2],dim = 0)\n",
        "              c0 = torch.stack([c_0_1,c_0_2],dim = 0)\n",
        "              \n",
        "              hidden_state = h0\n",
        "              cell_state = c0\n",
        "            \n",
        "            elif t==0:\n",
        "              #combin_init = torch.cat([torch.flatten(features,start_dim=1),out,output.squeeze(),h0[0,:,:]],dim=1)\n",
        "              combin_init = torch.cat([combin_lstm,h0[0,:,:]],dim=1)\n",
        "              \n",
        "              h_0_1 = self.hi_1(combin_init)  \n",
        "              \n",
        "              #combin_init = torch.cat([torch.flatten(features,start_dim=1),out,output.squeeze(),h0[1,:,:]],dim=1)\n",
        "              combin_init = torch.cat([combin_lstm,h0[1,:,:]],dim=1)\n",
        "              h_0_2 = self.hi_2(combin_init)  \n",
        "              \n",
        "              #combin_init = torch.cat([torch.flatten(features,start_dim=1),out,output.squeeze(),c0[0,:,:]],dim=1)\n",
        "              combin_init = torch.cat([combin_lstm,c0[0,:,:]],dim=1)\n",
        "              c_0_1 = self.ci_1(combin_init)  \n",
        "              \n",
        "              #combin_init = torch.cat([torch.flatten(features,start_dim=1),out,output.squeeze(),c0[1,:,:]],dim=1)\n",
        "              combin_init = torch.cat([combin_lstm,c0[1,:,:]],dim=1)\n",
        "              c_0_2 = self.ci_2(combin_init)\n",
        "              \n",
        "              h0 = torch.stack([h_0_1,h_0_2],dim = 0)\n",
        "              c0 = torch.stack([c_0_1,c_0_2],dim = 0)\n",
        "        \n",
        "\n",
        "              hidden_state = h0\n",
        "              cell_state = c0\n",
        "              \n",
        "\n",
        "\n",
        "            a1 = self.alpha_1(combin_lstm)\n",
        "            outesreada1 = self.embs.clone()*a1.unsqueeze(2)#clone\n",
        "            outesread1 = torch.sum(outesreada1,dim=1)\n",
        "            \n",
        "            \n",
        "            \n",
        "            output, (hidden_state, cell_state) = self.lstm_cell(combin_lstm.unsqueeze(0), (hidden_state, cell_state))\n",
        "\n",
        "            outputs[:, t, :] = out\n",
        "            self.longtermMemP[:,self.seq_len*ind+t,:] = out.detach()\n",
        "            \n",
        "            self.embs[:, t, :] = output.squeeze().clone().detach()\n",
        "            \n",
        "\n",
        "            a1 = self.alpha_1(combin_lstm)\n",
        "            outesreada1 = self.embs.clone()*a1.unsqueeze(2)#clone\n",
        "            outesread1 = torch.sum(outesreada1,dim=1)\n",
        "            \n",
        "            \n",
        "            #print('d')\n",
        "            al1 = self.alpha_long1(combin_lstm)\n",
        "            outesreadal1 = self.longtermMem.detach()*al1.unsqueeze(2)#clone\n",
        "            outesreadl1 = torch.sum(outesreadal1,dim=1)\n",
        "            \n",
        "            al2 = self.alpha_long2(combin_lstm)\n",
        "            outesreadal2 = self.longtermMem.detach()*al2.unsqueeze(2)#clone\n",
        "            outesreadl2 = torch.sum(outesreadal2,dim=1)\n",
        "            \n",
        "            al3 = self.alpha_long3(combin_lstm)\n",
        "            outesreadal3 = self.longtermMem.detach()*al3.unsqueeze(2)#clone\n",
        "            outesreadl3 = torch.sum(outesreadal3,dim=1)\n",
        "            \n",
        "            al4 = self.alpha_long4(combin_lstm)\n",
        "            outesreadal4 = self.longtermMem.detach()*al4.unsqueeze(2)#clone\n",
        "            outesreadl4 = torch.sum(outesreadal4,dim=1)\n",
        "            \n",
        "            al5 = self.alpha_long4(combin_lstm)\n",
        "            outesreadal5 = self.longtermMem.detach()*al5.unsqueeze(2)#clone\n",
        "            outesreadl5 = torch.sum(outesreadal5,dim=1)\n",
        "            \n",
        "            al6 = self.alpha_long6(combin_lstm)\n",
        "            outesreadal6 = self.longtermMem.detach()*al6.unsqueeze(2)#clone\n",
        "            outesreadl6 = torch.sum(outesreadal6,dim=1)\n",
        "            \n",
        "\n",
        "            combOut = torch.cat([combin_lstm, output.squeeze(),out,outesread1,outesreadl1,outesreadl2,outesreadl3,outesreadl4,outesreadl5,outesreadl6,self.ltm_temp],dim=1)#,outesread],dim=1)\n",
        "            \n",
        "\n",
        "            out = self.fc_out(combOut)\n",
        "            out = out*32.0\n",
        "            # build the output tensor\n",
        "            \n",
        "        \n",
        "            \n",
        "        #self.embs = self.embs.detach().clone()\n",
        "        return outputs, hidden_state.detach(), cell_state.detach(), out.detach(),output.detach()#, captions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50cqsTMxQXEm"
      },
      "source": [
        "model = DecoderRNN().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32G-MJC_QcKP"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, betas = (.9,.999))#ideal\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60xL8p9QeQc-"
      },
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjpFwX8MQlPe"
      },
      "source": [
        "for seql in range(3,23,2):\n",
        "  #seql = 19\n",
        "  for epoch in range (6):\n",
        "    loss = None\n",
        "    #model = model.train()\n",
        "\n",
        "    for x,y in loader_train:\n",
        "      h0 = None\n",
        "      c0 = None\n",
        "      for i in range(seql):\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "        loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        #writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      #print(y[:,0,:2])\n",
        "      print('epoch',epoch,'seql',seql)\n",
        "      print('train loss', loss)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      #model = model.eval()\n",
        "      for x,y in loader_test:\n",
        "        h0 = None\n",
        "        c0 = None\n",
        "        for i in range(seql):\n",
        "          x = x.cuda()\n",
        "          y = y.cuda()\n",
        "          \n",
        "          if i == 0:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "          else:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "          \n",
        "          loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        \n",
        "          assert not torch.any(torch.isnan(out)).item()\n",
        "          assert not torch.any(torch.isnan(y)).item()\n",
        "        \n",
        "        print('epoch',epoch,'seql',seql)\n",
        "        print('testloss',loss)\n",
        "  \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeBFueVv7BDD"
      },
      "source": [
        "with torch.no_grad():\n",
        "  #model = model.eval()\n",
        "  DonutDataset.displayCanvas('intermediate1.png',pred_dataset, model = model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWZWJn4i_R5x"
      },
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, betas = (.9,.999))#ideal\n",
        "\n",
        "for g in optimizer.param_groups:\n",
        "    g['lr'] = 0.0001\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV5RNgqjYMgZ"
      },
      "source": [
        "#for seql in range(15,20,4):\n",
        "seql = 23\n",
        "for epoch in range (20):\n",
        "  #model = model.train()\n",
        "  loss = None\n",
        "  for x,y in loader_train:\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    for i in range(seql):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      if i == 0:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "      else:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "      loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "      writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #print(y[:,0,:2])\n",
        "    print('epoch',epoch,'seql',seql)\n",
        "    print(loss)\n",
        "  with torch.no_grad():\n",
        "    #model = model.eval()\n",
        "    for x,y in loader_test:\n",
        "      h0 = None\n",
        "      c0 = None\n",
        "      for i in range(seql):\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "        \n",
        "        loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "      \n",
        "        assert not torch.any(torch.isnan(out)).item()\n",
        "        assert not torch.any(torch.isnan(y)).item()\n",
        "      \n",
        "      print('epoch',epoch,'seql',seql)\n",
        "      print('testloss',loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XXOA0SE7-i6"
      },
      "source": [
        "with torch.no_grad():\n",
        "  #model = model.eval()\n",
        "  DonutDataset.displayCanvas('intermediate2.png',pred_dataset, model = model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuGEdcCjYLK5"
      },
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(),lr = 0.00001, betas = (.9,.999))#ideal\n",
        "for g in optimizer.param_groups:\n",
        "    g['lr'] = 0.00001\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXg-Ue7XkTAO"
      },
      "source": [
        "\n",
        "#model = model.train()\n",
        "#for seql in range(15,20,4):\n",
        "seql = 23\n",
        "for epoch in range (20):\n",
        "  loss = None\n",
        "  #model = model.train()\n",
        "  for x,y in loader_train:\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    for i in range(seql):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      if i == 0:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "      else:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "      loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "      writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #print(y[:,0,:2])\n",
        "    print('epoch',epoch,'seql',seql)\n",
        "    print(loss)\n",
        "  with torch.no_grad():\n",
        "      #model = model.eval()\n",
        "      for x,y in loader_test:\n",
        "        h0 = None\n",
        "        c0 = None\n",
        "        for i in range(seql):\n",
        "          x = x.cuda()\n",
        "          y = y.cuda()\n",
        "          \n",
        "          if i == 0:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "          else:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "          \n",
        "          loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        \n",
        "          assert not torch.any(torch.isnan(out)).item()\n",
        "          assert not torch.any(torch.isnan(y)).item()\n",
        "        \n",
        "        print('epoch',epoch,'seql',seql)\n",
        "        print('testloss',loss)\n",
        "  \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgEufDA30RNU"
      },
      "source": [
        "ran so well, interrupted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taID_tz2DAuw"
      },
      "source": [
        "with torch.no_grad():\n",
        "  #model = model.eval()\n",
        "  DonutDataset.displayCanvas('intermediate3.png',pred_dataset, model = model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRI_enzc88XE"
      },
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(),lr = 0.00001, betas = (.9,.999))#ideal\n",
        "for g in optimizer.param_groups:\n",
        "    g['lr'] = 0.0001\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEbUCPrW88iJ"
      },
      "source": [
        "for seql in range(23,39,2):\n",
        "  #seql = 19\n",
        "  for epoch in range (6):\n",
        "    loss = None\n",
        "    #model = model.train()\n",
        "\n",
        "    for x,y in loader_train:\n",
        "      h0 = None\n",
        "      c0 = None\n",
        "      for i in range(seql):\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "        loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        #writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      #print(y[:,0,:2])\n",
        "      print('epoch',epoch,'seql',seql)\n",
        "      print('train loss', loss)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      #model = model.eval()\n",
        "      for x,y in loader_test:\n",
        "        h0 = None\n",
        "        c0 = None\n",
        "        for i in range(seql):\n",
        "          x = x.cuda()\n",
        "          y = y.cuda()\n",
        "          \n",
        "          if i == 0:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "          else:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "          \n",
        "          loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        \n",
        "          assert not torch.any(torch.isnan(out)).item()\n",
        "          assert not torch.any(torch.isnan(y)).item()\n",
        "        \n",
        "        print('epoch',epoch,'seql',seql)\n",
        "        print('testloss',loss)\n",
        "  \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soW6YQjMPBFm"
      },
      "source": [
        "with torch.no_grad():\n",
        "  #model = model.eval()\n",
        "  DonutDataset.displayCanvas('intermediate4.png',pred_dataset, model = model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5DFKctZN2Zi"
      },
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(),lr = 0.00001, betas = (.9,.999))#ideal\n",
        "for g in optimizer.param_groups:\n",
        "    g['lr'] = 0.0001\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOTSCWyHNxed"
      },
      "source": [
        "#for seql in range(15,20,4):\n",
        "seql = 38\n",
        "for epoch in range (20):\n",
        "  #model = model.train()\n",
        "  loss = None\n",
        "  for x,y in loader_train:\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    for i in range(seql):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      if i == 0:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "      else:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "      loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "      writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #print(y[:,0,:2])\n",
        "    print('epoch',epoch,'seql',seql)\n",
        "    print(loss)\n",
        "  with torch.no_grad():\n",
        "    #model = model.eval()\n",
        "    for x,y in loader_test:\n",
        "      h0 = None\n",
        "      c0 = None\n",
        "      for i in range(seql):\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        if i == 0:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "        else:\n",
        "          out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "        \n",
        "        loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "      \n",
        "        assert not torch.any(torch.isnan(out)).item()\n",
        "        assert not torch.any(torch.isnan(y)).item()\n",
        "      \n",
        "      print('epoch',epoch,'seql',seql)\n",
        "      print('testloss',loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro65sGgUQrbJ"
      },
      "source": [
        "with torch.no_grad():\n",
        "  #model = model.eval()\n",
        "  DonutDataset.displayCanvas('intermediate5.png',pred_dataset, model = model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swfai-2h9INi"
      },
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(),lr = 0.00001, betas = (.9,.999))#ideal\n",
        "for g in optimizer.param_groups:\n",
        "    g['lr'] = 0.00001\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0JuizI-9JXP"
      },
      "source": [
        "\n",
        "#model = model.train()\n",
        "#for seql in range(15,20,4):\n",
        "seql = 38\n",
        "for epoch in range (120):\n",
        "  loss = None\n",
        "  #model = model.train()\n",
        "  for x,y in loader_train:\n",
        "    h0 = None\n",
        "    c0 = None\n",
        "    for i in range(seql):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      if i == 0:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "      else:\n",
        "        out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "      loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "      writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #print(y[:,0,:2])\n",
        "    print('epoch',epoch,'seql',seql)\n",
        "    print(loss)\n",
        "  with torch.no_grad():\n",
        "      #model = model.eval()\n",
        "      for x,y in loader_test:\n",
        "        h0 = None\n",
        "        c0 = None\n",
        "        for i in range(seql):\n",
        "          x = x.cuda()\n",
        "          y = y.cuda()\n",
        "          \n",
        "          if i == 0:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "          else:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "          \n",
        "          loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        \n",
        "          assert not torch.any(torch.isnan(out)).item()\n",
        "          assert not torch.any(torch.isnan(y)).item()\n",
        "        \n",
        "        print('epoch',epoch,'seql',seql)\n",
        "        print('testloss',loss)\n",
        "  \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AZseYD-Qotc"
      },
      "source": [
        "writer.flush()\n",
        "writer.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qtXdY1gAgc"
      },
      "source": [
        "#%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7IqU3hQfmMa"
      },
      "source": [
        "#!kill 3285\n",
        "#%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgr2Hthdsoak"
      },
      "source": [
        "#!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8vn01RqKGky"
      },
      "source": [
        "with torch.no_grad():\n",
        "  #model = model.eval()\n",
        "  DonutDataset.displayCanvas('lstmpredictions.png',pred_dataset, model = model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j28U5Ae-LlZH"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWSvK_N0GvaF"
      },
      "source": [
        "with torch.no_grad():\n",
        "      #model = model.eval()\n",
        "      for x,y in loader_test:\n",
        "        h0 = None\n",
        "        c0 = None\n",
        "        for i in range(seql):\n",
        "          x = x.cuda()\n",
        "          y = y.cuda()\n",
        "          \n",
        "          if i == 0:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i)\n",
        "          else:\n",
        "            out, h0, c0,o,output = model(x,y[:,0,:2],h0,c0,ind = i,o = o,output=output)\n",
        "          \n",
        "          loss = torch.mean((out-y[:,1+(25*i):1+(25*(i+1)),:2])**2)\n",
        "        \n",
        "          assert not torch.any(torch.isnan(out)).item()\n",
        "          assert not torch.any(torch.isnan(y)).item()\n",
        "        \n",
        "        print('epoch',epoch,'seql',seql)\n",
        "        print('testloss',loss)\n",
        "  \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI9hjy7IZCSx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}