{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimplestToyProblem.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKvpeQh0k4aUhJVD3RJp9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/SimplestToyProblem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "lriVEWYxBqQJ",
        "outputId": "d60d6c9e-5411-4c3f-95e2-03e0badb623d"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from skimage import filters\n",
        "import math\n",
        "\n",
        "global numpoints\n",
        "numpoints = 1\n",
        "side = 32\n",
        "\n",
        "rows = torch.zeros(32,32)\n",
        "columns = torch.zeros(32,32)\n",
        "\n",
        "\n",
        "for i in range(32):\n",
        "    columns[:,i] = i\n",
        "    rows[i,:] = i\n",
        "\n",
        "\n",
        "def point_matrix():\n",
        "    length = side**2\n",
        "    canvas = torch.zeros((length,side, side))\n",
        "    \n",
        "\n",
        "    x = torch.zeros(length,numpoints) \n",
        "    y = torch.zeros(length,numpoints)\n",
        "    assert x.shape == (length,numpoints)\n",
        "    assert y.shape == (length,numpoints)\n",
        "    \n",
        "    points = torch.zeros(length,2)\n",
        "    for j in range(side):\n",
        "      for i in range(side):\n",
        "        l = i*32+j\n",
        "        canvas[l,i,j] = 1.0\n",
        "        x[l] = i\n",
        "        y[l] = j\n",
        "\n",
        "        #points[l,:,0] = x[l,:]\n",
        "        #points[l,:,1] = y[l,:]\n",
        "        points[l,0] = i#modified for lstm discriminator\n",
        "        points[l,1] = j#modified for lstm discriminator \n",
        "    \n",
        "    \n",
        "    return {\n",
        "        'canvas': canvas, \n",
        "        'points':points.type(torch.FloatTensor)}\n",
        "\n",
        "\n",
        "def plot_all( sample = None, model = None, labels = None):\n",
        "    img = sample[:,:].squeeze().cpu().numpy()\n",
        "    #img = np.zeros((32,32))\n",
        "    #img[1,1] = 1\n",
        "    #img[31,1] = 1\n",
        "    #img[31,31] = 1\n",
        "    img = img.T\n",
        "    plt.imshow(img, cmap=plt.cm.gray_r)\n",
        "    if model != None:\n",
        "        with torch.no_grad():\n",
        "            global numpoints\n",
        "\n",
        "            print(\"sample\", sample.shape)\n",
        "            sample = sample.cuda()\n",
        "            sample = sample.unsqueeze(0)\n",
        "            print('hello',sample.shape)\n",
        "            pred = model(sample)\n",
        "            print('hello')\n",
        "            \n",
        "            print('pred', pred.shape)\n",
        "            predres = 1\n",
        "            X = pred[:,0]\n",
        "            Y = pred[:,1]\n",
        "            \n",
        "            s = [10 for x in range(predres)]\n",
        "            \n",
        "            assert len(s) == predres\n",
        "            c = ['red' for x in range(predres)]\n",
        "            assert len(c) == predres\n",
        "            Y = Y.cuda()\n",
        "            X = X.cuda()\n",
        "            print(\"type\",type(X))\n",
        "            ascatter = plt.scatter(X.cpu().numpy(),Y.cpu().numpy(),s = s,c = c)\n",
        "            plt.gca().add_artist(ascatter)\n",
        "    else:\n",
        "        #print(labels.shape)\n",
        "\n",
        "        X = labels[0]\n",
        "        Y = labels[1]\n",
        "        #print(X.shape)\n",
        "        #print(Y.shape)\n",
        "        print(X,Y)\n",
        "        s = [.1 for x in range(numpoints)]\n",
        "        #print(len(s))\n",
        "        c = ['red' for x in range(numpoints)]\n",
        "        #print(len(c))\n",
        "        ascatter = plt.scatter(X,Y,s = s,c = c)\n",
        "        plt.gca().add_artist(ascatter)\n",
        "\n",
        "class PointDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Donut dataset.\"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.length = side**2\n",
        "        self.values = point_matrix()\n",
        "        assert self.values['canvas'].shape[0] == self.length\n",
        "        assert self.values['points'].shape[0] == self.length\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        canvas = self.values[\"canvas\"]\n",
        "        \n",
        "        canvas = canvas[idx,:,:]\n",
        "        assert canvas.shape == (side,side)\n",
        "        points = self.values[\"points\"]\n",
        "        points = points[idx,:]\n",
        "        return canvas, points\n",
        "    \n",
        "    @staticmethod\n",
        "    def displayCanvas(title,dataset, model):\n",
        "        #model.setBatchSize(batch_size = 1)\n",
        "        for i in range(36):\n",
        "            sample, labels = dataset[i]\n",
        "            plt.subplot(6,6,i+1)\n",
        "            plot_all(sample = sample,model=model, labels = labels)\n",
        "            plt.axis('off')\n",
        "        plt.savefig(title,dpi=600)\n",
        "\n",
        "dataset = PointDataset()\n",
        "PointDataset.displayCanvas('donut.png',dataset, model = None)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.) tensor(0.)\n",
            "tensor(0.) tensor(1.)\n",
            "tensor(0.) tensor(2.)\n",
            "tensor(0.) tensor(3.)\n",
            "tensor(0.) tensor(4.)\n",
            "tensor(0.) tensor(5.)\n",
            "tensor(0.) tensor(6.)\n",
            "tensor(0.) tensor(7.)\n",
            "tensor(0.) tensor(8.)\n",
            "tensor(0.) tensor(9.)\n",
            "tensor(0.) tensor(10.)\n",
            "tensor(0.) tensor(11.)\n",
            "tensor(0.) tensor(12.)\n",
            "tensor(0.) tensor(13.)\n",
            "tensor(0.) tensor(14.)\n",
            "tensor(0.) tensor(15.)\n",
            "tensor(0.) tensor(16.)\n",
            "tensor(0.) tensor(17.)\n",
            "tensor(0.) tensor(18.)\n",
            "tensor(0.) tensor(19.)\n",
            "tensor(0.) tensor(20.)\n",
            "tensor(0.) tensor(21.)\n",
            "tensor(0.) tensor(22.)\n",
            "tensor(0.) tensor(23.)\n",
            "tensor(0.) tensor(24.)\n",
            "tensor(0.) tensor(25.)\n",
            "tensor(0.) tensor(26.)\n",
            "tensor(0.) tensor(27.)\n",
            "tensor(0.) tensor(28.)\n",
            "tensor(0.) tensor(29.)\n",
            "tensor(0.) tensor(30.)\n",
            "tensor(0.) tensor(31.)\n",
            "tensor(1.) tensor(0.)\n",
            "tensor(1.) tensor(1.)\n",
            "tensor(1.) tensor(2.)\n",
            "tensor(1.) tensor(3.)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci_oKFKxBubp"
      },
      "source": [
        "d = dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaEIxbzWHl2V",
        "outputId": "3b4f6d23-5079-4a17-81de-dacc1b6f98f1"
      },
      "source": [
        "l=2\n",
        "c = d[l][0]\n",
        "print(d[l][1][0],d[l][1][1])\n",
        "i= (int)(d[l][1][0].item())\n",
        "j=(int)(d[l][1][1].item())\n",
        "print(i,j)\n",
        "\n",
        "print(c[i,j])\n",
        "print(d[l][1])\n",
        "print(c)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.) tensor(2.)\n",
            "0 2\n",
            "tensor(1.)\n",
            "tensor([0., 2.])\n",
            "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7eBMvDeM-7_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.input_dim = 1*32*32\n",
        "        self.hidden_dim = 2**11\n",
        "        self.midl=1\n",
        "        \n",
        "        self.inLayer = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, (int)(self.input_dim/2)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "         )\n",
        "        self.midLayers1 = nn.Sequential(\n",
        "            nn.Linear((int)(self.input_dim/2)+self.input_dim, (int)(self.input_dim/4)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        )        \n",
        "        self.midLayers2 = nn.Sequential(\n",
        "            nn.Linear((int)(self.input_dim/4)+self.input_dim, (int)(self.input_dim/8)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        )        \n",
        "        self.midLayers3 = nn.Sequential(\n",
        "            nn.Linear((int)(self.input_dim/8)+self.input_dim, (int)(self.input_dim/16)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        )        \n",
        "        self.out_layer = nn.Sequential(\n",
        "           nn.Linear((int)(self.input_dim/16)+self.input_dim, 2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.squeeze()\n",
        "        x = torch.flatten(x,start_dim=1)\n",
        "        \n",
        "        #assert x.shape == (mini_batch,self.hidden_dim)\n",
        "        out = self.inLayer(x)\n",
        "        \n",
        "        out = torch.cat([out,x],dim = 1)\n",
        "        out = self.midLayers1(out)\n",
        "        \n",
        "        out = torch.cat([out,x],dim = 1)\n",
        "        out = self.midLayers2(out)\n",
        "        \n",
        "        out = torch.cat([out,x],dim = 1)\n",
        "        out = self.midLayers3(out)\n",
        "\n",
        "        out = torch.cat([out,x],dim = 1)\n",
        "        out = self.out_layer(out)\n",
        "        \n",
        "        return 32.0*out\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYKNN1XTuMO1"
      },
      "source": [
        "model = MLP().cuda()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QreZ-k6dtTx"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, betas = (.9,.999))"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PfBoCUFuTkh",
        "outputId": "8302a44d-712b-4d36-b475-ae505815fa3b"
      },
      "source": [
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 128\n",
        "dataset = PointDataset()\n",
        "loader_train = data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=dataset),\n",
        "    num_workers=4)\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJz942ZhumMq",
        "outputId": "62f399cc-2e87-465e-c48c-75e0ad20bb3c"
      },
      "source": [
        "epoch = 200\n",
        "for e in range(epoch):\n",
        "  for xin,yin in loader_train:\n",
        "    if xin.shape[0] != mini_batch:\n",
        "      print(xin.shape)\n",
        "      continue\n",
        "    xin = xin.cuda()\n",
        "    yin = yin.cuda()\n",
        "    out = model(xin)\n",
        "    loss = torch.mean((out-yin)**2)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  print(e,'\\t', loss)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 \t tensor(86.6431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "1 \t tensor(88.1059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "2 \t tensor(77.8254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "3 \t tensor(83.0647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "4 \t tensor(80.1392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "5 \t tensor(80.4987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "6 \t tensor(90.2868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "7 \t tensor(86.5005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "8 \t tensor(82.4749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "9 \t tensor(74.4355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "10 \t tensor(84.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "11 \t tensor(87.4651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "12 \t tensor(74.8200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "13 \t tensor(79.3667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "14 \t tensor(77.8139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "15 \t tensor(71.2943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "16 \t tensor(69.6637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "17 \t tensor(67.9741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "18 \t tensor(60.0844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "19 \t tensor(56.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "20 \t tensor(57.9487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "21 \t tensor(64.9483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "22 \t tensor(47.2135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "23 \t tensor(51.3509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "24 \t tensor(51.4076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "25 \t tensor(54.0315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "26 \t tensor(54.2100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "27 \t tensor(45.8547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "28 \t tensor(44.1418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "29 \t tensor(37.2417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "30 \t tensor(45.0915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "31 \t tensor(38.3847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "32 \t tensor(28.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "33 \t tensor(28.5340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "34 \t tensor(28.7945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "35 \t tensor(29.9583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "36 \t tensor(37.9613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "37 \t tensor(36.8704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "38 \t tensor(35.6328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "39 \t tensor(37.3845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "40 \t tensor(37.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "41 \t tensor(26.6170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "42 \t tensor(26.3424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "43 \t tensor(21.7944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "44 \t tensor(17.9767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "45 \t tensor(17.3580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "46 \t tensor(19.1719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "47 \t tensor(17.8712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "48 \t tensor(17.8324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "49 \t tensor(16.4579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "50 \t tensor(21.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "51 \t tensor(21.4338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "52 \t tensor(22.5684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "53 \t tensor(19.4294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "54 \t tensor(21.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "55 \t tensor(19.8365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "56 \t tensor(18.5772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "57 \t tensor(21.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "58 \t tensor(18.9062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "59 \t tensor(19.1196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "60 \t tensor(17.9594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "61 \t tensor(18.4328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "62 \t tensor(15.4175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "63 \t tensor(14.0163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "64 \t tensor(13.3552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "65 \t tensor(10.0664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "66 \t tensor(10.5436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "67 \t tensor(11.4524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "68 \t tensor(11.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "69 \t tensor(9.3144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "70 \t tensor(13.5411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "71 \t tensor(10.6111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "72 \t tensor(10.7233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "73 \t tensor(10.7791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "74 \t tensor(11.7849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "75 \t tensor(12.4557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "76 \t tensor(12.6187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "77 \t tensor(14.4640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "78 \t tensor(11.3953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "79 \t tensor(13.4813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "80 \t tensor(13.6836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "81 \t tensor(9.7876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "82 \t tensor(11.1990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "83 \t tensor(11.6901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "84 \t tensor(9.7778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "85 \t tensor(10.4070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "86 \t tensor(8.8701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "87 \t tensor(11.6799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "88 \t tensor(8.7568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "89 \t tensor(9.0953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "90 \t tensor(10.3013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "91 \t tensor(10.5716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "92 \t tensor(11.0440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "93 \t tensor(7.3933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "94 \t tensor(7.4738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "95 \t tensor(7.8285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "96 \t tensor(12.1692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "97 \t tensor(7.9947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "98 \t tensor(8.7515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "99 \t tensor(10.0435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "100 \t tensor(8.8482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "101 \t tensor(9.0356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "102 \t tensor(9.1716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "103 \t tensor(8.2964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "104 \t tensor(10.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "105 \t tensor(10.6656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "106 \t tensor(8.6856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "107 \t tensor(10.6227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "108 \t tensor(8.7718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "109 \t tensor(10.2879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "110 \t tensor(9.2698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "111 \t tensor(8.0192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "112 \t tensor(7.5497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "113 \t tensor(8.5241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "114 \t tensor(7.9671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "115 \t tensor(6.5002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "116 \t tensor(6.2250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "117 \t tensor(6.3265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "118 \t tensor(7.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "119 \t tensor(6.0806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "120 \t tensor(5.4133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "121 \t tensor(6.1863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "122 \t tensor(6.5200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "123 \t tensor(8.0200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "124 \t tensor(5.9779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "125 \t tensor(6.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "126 \t tensor(5.5559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "127 \t tensor(5.1807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "128 \t tensor(6.0656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "129 \t tensor(5.6042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "130 \t tensor(7.5913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "131 \t tensor(7.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "132 \t tensor(4.7655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "133 \t tensor(7.2586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "134 \t tensor(6.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "135 \t tensor(6.3071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "136 \t tensor(6.3713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "137 \t tensor(6.6797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "138 \t tensor(7.2095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "139 \t tensor(5.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "140 \t tensor(6.1914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "141 \t tensor(5.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "142 \t tensor(5.4514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "143 \t tensor(7.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "144 \t tensor(5.4590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "145 \t tensor(5.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "146 \t tensor(5.1618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "147 \t tensor(4.6159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "148 \t tensor(6.3944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "149 \t tensor(4.8974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "150 \t tensor(4.7297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "151 \t tensor(4.3800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "152 \t tensor(5.6997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "153 \t tensor(5.5648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "154 \t tensor(6.8766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "155 \t tensor(5.8122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "156 \t tensor(6.4499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "157 \t tensor(5.8167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "158 \t tensor(6.9023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "159 \t tensor(5.4710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "160 \t tensor(5.8032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "161 \t tensor(5.7655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "162 \t tensor(5.6106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "163 \t tensor(6.2643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "164 \t tensor(4.7522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "165 \t tensor(5.6449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "166 \t tensor(4.4013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "167 \t tensor(5.9261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "168 \t tensor(5.5321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "169 \t tensor(4.6858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "170 \t tensor(4.6656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "171 \t tensor(5.4218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "172 \t tensor(4.3824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "173 \t tensor(4.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "174 \t tensor(5.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "175 \t tensor(4.9811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "176 \t tensor(3.4602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "177 \t tensor(3.9153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "178 \t tensor(5.8470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "179 \t tensor(4.8270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "180 \t tensor(5.3972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "181 \t tensor(4.3751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "182 \t tensor(4.8631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "183 \t tensor(4.6011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "184 \t tensor(4.2571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "185 \t tensor(5.0322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "186 \t tensor(3.9626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "187 \t tensor(4.4039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "188 \t tensor(5.8233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "189 \t tensor(5.4543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "190 \t tensor(4.5424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "191 \t tensor(4.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "192 \t tensor(4.5100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "193 \t tensor(4.9632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "194 \t tensor(4.4947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "195 \t tensor(3.8843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "196 \t tensor(4.7353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "197 \t tensor(4.0266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "198 \t tensor(3.7337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "199 \t tensor(4.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CseZX1-9vKlP"
      },
      "source": [
        "dataset = PointDataset()\n",
        "PointDataset.displayCanvas('donut.png',dataset, model = model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n8xKdlYwjQd"
      },
      "source": [
        "a= torch.zeros(64,3)\n",
        "b = torch.zeros(64,4)\n",
        "c = torch.cat([a,b], dim = 1)\n",
        "print(c.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S8PURbSRrPD"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}