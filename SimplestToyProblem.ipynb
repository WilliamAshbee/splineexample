{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimplestToyProblem.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPaG0pm9ZAlEHv3MtNI5JZI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/SimplestToyProblem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "lriVEWYxBqQJ",
        "outputId": "d60d6c9e-5411-4c3f-95e2-03e0badb623d"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from skimage import filters\n",
        "import math\n",
        "\n",
        "global numpoints\n",
        "numpoints = 1\n",
        "side = 32\n",
        "\n",
        "rows = torch.zeros(32,32)\n",
        "columns = torch.zeros(32,32)\n",
        "\n",
        "\n",
        "for i in range(32):\n",
        "    columns[:,i] = i\n",
        "    rows[i,:] = i\n",
        "\n",
        "\n",
        "def point_matrix():\n",
        "    length = side**2\n",
        "    canvas = torch.zeros((length,side, side))\n",
        "    \n",
        "\n",
        "    x = torch.zeros(length,numpoints) \n",
        "    y = torch.zeros(length,numpoints)\n",
        "    assert x.shape == (length,numpoints)\n",
        "    assert y.shape == (length,numpoints)\n",
        "    \n",
        "    points = torch.zeros(length,2)\n",
        "    for j in range(side):\n",
        "      for i in range(side):\n",
        "        l = i*32+j\n",
        "        canvas[l,i,j] = 1.0\n",
        "        x[l] = i\n",
        "        y[l] = j\n",
        "\n",
        "        #points[l,:,0] = x[l,:]\n",
        "        #points[l,:,1] = y[l,:]\n",
        "        points[l,0] = i#modified for lstm discriminator\n",
        "        points[l,1] = j#modified for lstm discriminator \n",
        "    \n",
        "    \n",
        "    return {\n",
        "        'canvas': canvas, \n",
        "        'points':points.type(torch.FloatTensor)}\n",
        "\n",
        "\n",
        "def plot_all( sample = None, model = None, labels = None):\n",
        "    img = sample[:,:].squeeze().cpu().numpy()\n",
        "    #img = np.zeros((32,32))\n",
        "    #img[1,1] = 1\n",
        "    #img[31,1] = 1\n",
        "    #img[31,31] = 1\n",
        "    img = img.T\n",
        "    plt.imshow(img, cmap=plt.cm.gray_r)\n",
        "    if model != None:\n",
        "        with torch.no_grad():\n",
        "            global numpoints\n",
        "\n",
        "            print(\"sample\", sample.shape)\n",
        "            sample = sample.cuda()\n",
        "            sample = sample.unsqueeze(0)\n",
        "            print('hello',sample.shape)\n",
        "            pred = model(sample)\n",
        "            print('hello')\n",
        "            \n",
        "            print('pred', pred.shape)\n",
        "            predres = 1\n",
        "            X = pred[:,0]\n",
        "            Y = pred[:,1]\n",
        "            \n",
        "            s = [10 for x in range(predres)]\n",
        "            \n",
        "            assert len(s) == predres\n",
        "            c = ['red' for x in range(predres)]\n",
        "            assert len(c) == predres\n",
        "            Y = Y.cuda()\n",
        "            X = X.cuda()\n",
        "            print(\"type\",type(X))\n",
        "            ascatter = plt.scatter(X.cpu().numpy(),Y.cpu().numpy(),s = s,c = c)\n",
        "            plt.gca().add_artist(ascatter)\n",
        "    else:\n",
        "        #print(labels.shape)\n",
        "\n",
        "        X = labels[0]\n",
        "        Y = labels[1]\n",
        "        #print(X.shape)\n",
        "        #print(Y.shape)\n",
        "        print(X,Y)\n",
        "        s = [.1 for x in range(numpoints)]\n",
        "        #print(len(s))\n",
        "        c = ['red' for x in range(numpoints)]\n",
        "        #print(len(c))\n",
        "        ascatter = plt.scatter(X,Y,s = s,c = c)\n",
        "        plt.gca().add_artist(ascatter)\n",
        "\n",
        "class PointDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Donut dataset.\"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.length = side**2\n",
        "        self.values = point_matrix()\n",
        "        assert self.values['canvas'].shape[0] == self.length\n",
        "        assert self.values['points'].shape[0] == self.length\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        canvas = self.values[\"canvas\"]\n",
        "        \n",
        "        canvas = canvas[idx,:,:]\n",
        "        assert canvas.shape == (side,side)\n",
        "        points = self.values[\"points\"]\n",
        "        points = points[idx,:]\n",
        "        return canvas, points\n",
        "    \n",
        "    @staticmethod\n",
        "    def displayCanvas(title,dataset, model):\n",
        "        #model.setBatchSize(batch_size = 1)\n",
        "        for i in range(36):\n",
        "            sample, labels = dataset[i]\n",
        "            plt.subplot(6,6,i+1)\n",
        "            plot_all(sample = sample,model=model, labels = labels)\n",
        "            plt.axis('off')\n",
        "        plt.savefig(title,dpi=600)\n",
        "\n",
        "dataset = PointDataset()\n",
        "PointDataset.displayCanvas('donut.png',dataset, model = None)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.) tensor(0.)\n",
            "tensor(0.) tensor(1.)\n",
            "tensor(0.) tensor(2.)\n",
            "tensor(0.) tensor(3.)\n",
            "tensor(0.) tensor(4.)\n",
            "tensor(0.) tensor(5.)\n",
            "tensor(0.) tensor(6.)\n",
            "tensor(0.) tensor(7.)\n",
            "tensor(0.) tensor(8.)\n",
            "tensor(0.) tensor(9.)\n",
            "tensor(0.) tensor(10.)\n",
            "tensor(0.) tensor(11.)\n",
            "tensor(0.) tensor(12.)\n",
            "tensor(0.) tensor(13.)\n",
            "tensor(0.) tensor(14.)\n",
            "tensor(0.) tensor(15.)\n",
            "tensor(0.) tensor(16.)\n",
            "tensor(0.) tensor(17.)\n",
            "tensor(0.) tensor(18.)\n",
            "tensor(0.) tensor(19.)\n",
            "tensor(0.) tensor(20.)\n",
            "tensor(0.) tensor(21.)\n",
            "tensor(0.) tensor(22.)\n",
            "tensor(0.) tensor(23.)\n",
            "tensor(0.) tensor(24.)\n",
            "tensor(0.) tensor(25.)\n",
            "tensor(0.) tensor(26.)\n",
            "tensor(0.) tensor(27.)\n",
            "tensor(0.) tensor(28.)\n",
            "tensor(0.) tensor(29.)\n",
            "tensor(0.) tensor(30.)\n",
            "tensor(0.) tensor(31.)\n",
            "tensor(1.) tensor(0.)\n",
            "tensor(1.) tensor(1.)\n",
            "tensor(1.) tensor(2.)\n",
            "tensor(1.) tensor(3.)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci_oKFKxBubp"
      },
      "source": [
        "d = dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaEIxbzWHl2V",
        "outputId": "3b4f6d23-5079-4a17-81de-dacc1b6f98f1"
      },
      "source": [
        "l=2\n",
        "c = d[l][0]\n",
        "print(d[l][1][0],d[l][1][1])\n",
        "i= (int)(d[l][1][0].item())\n",
        "j=(int)(d[l][1][1].item())\n",
        "print(i,j)\n",
        "\n",
        "print(c[i,j])\n",
        "print(d[l][1])\n",
        "print(c)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.) tensor(2.)\n",
            "0 2\n",
            "tensor(1.)\n",
            "tensor([0., 2.])\n",
            "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7eBMvDeM-7_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.input_dim = 1*32*32\n",
        "        self.hidden_dim = 2**12\n",
        "        \n",
        "        \n",
        "        self.inLayer = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, self.hidden_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "         )\n",
        "        self.midLayers = [nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim+self.input_dim, self.hidden_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        ).cuda() for i in range(4)] \n",
        "        \n",
        "        self.out_layer = nn.Sequential(\n",
        "           nn.Linear(self.hidden_dim, 2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.squeeze()\n",
        "        x = torch.flatten(x,start_dim=1)\n",
        "        \n",
        "        #assert x.shape == (mini_batch,self.hidden_dim)\n",
        "        out = self.inLayer(x)\n",
        "        \n",
        "        for i in range(4):\n",
        "          out = torch.cat([out,x],dim = 1)\n",
        "          out = self.midLayers[i](out)\n",
        "        \n",
        "        out = self.out_layer(out)\n",
        "        \n",
        "        return 32.0*out\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYKNN1XTuMO1"
      },
      "source": [
        "model = MLP().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, betas = (.9,.999))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PfBoCUFuTkh",
        "outputId": "c947f0f4-efa5-49b5-e34f-6fdd1536b063"
      },
      "source": [
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 128\n",
        "dataset = PointDataset()\n",
        "loader_train = data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=dataset),\n",
        "    num_workers=4)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJz942ZhumMq",
        "outputId": "e208b547-e98e-4e4f-8903-1b94dd790aa8"
      },
      "source": [
        "epoch = 200\n",
        "for e in range(epoch):\n",
        "  for xin,yin in loader_train:\n",
        "    if xin.shape[0] != mini_batch:\n",
        "      print(xin.shape)\n",
        "      continue\n",
        "    xin = xin.cuda()\n",
        "    yin = yin.cuda()\n",
        "    out = model(xin)\n",
        "    loss = torch.mean((out-yin)**2)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  print(e,'\\t', loss)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 \t tensor(86.9042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "1 \t tensor(77.7211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "2 \t tensor(80.3173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "3 \t tensor(84.4484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "4 \t tensor(85.6526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "5 \t tensor(83.1078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "6 \t tensor(86.4249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "7 \t tensor(82.8918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "8 \t tensor(87.7311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "9 \t tensor(91.9375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "10 \t tensor(88.6483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "11 \t tensor(88.9089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "12 \t tensor(81.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "13 \t tensor(83.8860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "14 \t tensor(86.6588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "15 \t tensor(78.7010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "16 \t tensor(87.6364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "17 \t tensor(89.7466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "18 \t tensor(83.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "19 \t tensor(90.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "20 \t tensor(81.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "21 \t tensor(81.1922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "22 \t tensor(83.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "23 \t tensor(85.5070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "24 \t tensor(80.5066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "25 \t tensor(80.8031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "26 \t tensor(82.8020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "27 \t tensor(83.0693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "28 \t tensor(83.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "29 \t tensor(85.4686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "30 \t tensor(85.5300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "31 \t tensor(77.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "32 \t tensor(89.3259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "33 \t tensor(81.3525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "34 \t tensor(85.9095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "35 \t tensor(81.3175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "36 \t tensor(84.6753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "37 \t tensor(76.9957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "38 \t tensor(87.2012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "39 \t tensor(82.7992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "40 \t tensor(89.0273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "41 \t tensor(76.0250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "42 \t tensor(81.5443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "43 \t tensor(81.9457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "44 \t tensor(82.5210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "45 \t tensor(84.6131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "46 \t tensor(80.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "47 \t tensor(81.5314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "48 \t tensor(80.9646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "49 \t tensor(86.6352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "50 \t tensor(75.5262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "51 \t tensor(77.8157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "52 \t tensor(84.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "53 \t tensor(88.5760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "54 \t tensor(76.5346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "55 \t tensor(77.6910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "56 \t tensor(79.9042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "57 \t tensor(79.6883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "58 \t tensor(75.3817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "59 \t tensor(73.7642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "60 \t tensor(90.1727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "61 \t tensor(77.3724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "62 \t tensor(78.7729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "63 \t tensor(69.4801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "64 \t tensor(67.3509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "65 \t tensor(79.2279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "66 \t tensor(72.6839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "67 \t tensor(79.0575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "68 \t tensor(77.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "69 \t tensor(75.0785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "70 \t tensor(75.8014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "71 \t tensor(72.1552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "72 \t tensor(75.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "73 \t tensor(70.1929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "74 \t tensor(76.6547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "75 \t tensor(73.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "76 \t tensor(76.4400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "77 \t tensor(67.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "78 \t tensor(77.5488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "79 \t tensor(72.9018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "80 \t tensor(76.6584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "81 \t tensor(69.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "82 \t tensor(70.3696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "83 \t tensor(67.9522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "84 \t tensor(66.4036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "85 \t tensor(72.2270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "86 \t tensor(61.0814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "87 \t tensor(77.3525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "88 \t tensor(67.2790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "89 \t tensor(74.9538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "90 \t tensor(74.0698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "91 \t tensor(65.8655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "92 \t tensor(62.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "93 \t tensor(69.0133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "94 \t tensor(72.2227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "95 \t tensor(64.4361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "96 \t tensor(64.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "97 \t tensor(56.5572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "98 \t tensor(64.5719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "99 \t tensor(70.1515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "100 \t tensor(63.1018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "101 \t tensor(56.0339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "102 \t tensor(72.2357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "103 \t tensor(69.1552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "104 \t tensor(57.7186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "105 \t tensor(59.6166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "106 \t tensor(61.5583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "107 \t tensor(61.5780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "108 \t tensor(61.1608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "109 \t tensor(58.2240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "110 \t tensor(57.1792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "111 \t tensor(55.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "112 \t tensor(55.1988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "113 \t tensor(54.3015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "114 \t tensor(55.5994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "115 \t tensor(50.0930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "116 \t tensor(51.9547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "117 \t tensor(56.2837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "118 \t tensor(53.7878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "119 \t tensor(48.3124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "120 \t tensor(52.1269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "121 \t tensor(52.4421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "122 \t tensor(53.0112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "123 \t tensor(50.0143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "124 \t tensor(45.2905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "125 \t tensor(57.5827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "126 \t tensor(46.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "127 \t tensor(46.7416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "128 \t tensor(52.3160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "129 \t tensor(45.9226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "130 \t tensor(47.4916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "131 \t tensor(44.4313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "132 \t tensor(43.1124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "133 \t tensor(43.8699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "134 \t tensor(49.3638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "135 \t tensor(49.7574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "136 \t tensor(44.4775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "137 \t tensor(40.3358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "138 \t tensor(39.0878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "139 \t tensor(44.8159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "140 \t tensor(45.4044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "141 \t tensor(42.5077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "142 \t tensor(44.7313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "143 \t tensor(40.2408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "144 \t tensor(41.7307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "145 \t tensor(35.5959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "146 \t tensor(38.4262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "147 \t tensor(36.4471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "148 \t tensor(39.3457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "149 \t tensor(34.8110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "150 \t tensor(41.7297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "151 \t tensor(42.6621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "152 \t tensor(40.2263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "153 \t tensor(40.6559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "154 \t tensor(33.1929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "155 \t tensor(38.9049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "156 \t tensor(35.5922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "157 \t tensor(33.1127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "158 \t tensor(33.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "159 \t tensor(33.3583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "160 \t tensor(32.9298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "161 \t tensor(32.9091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "162 \t tensor(31.0161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "163 \t tensor(33.7391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "164 \t tensor(30.3016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "165 \t tensor(31.2410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "166 \t tensor(32.2853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "167 \t tensor(25.5732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "168 \t tensor(30.6149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "169 \t tensor(28.6831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "170 \t tensor(32.6569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "171 \t tensor(30.3982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "172 \t tensor(33.5971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "173 \t tensor(26.3252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "174 \t tensor(25.2018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "175 \t tensor(27.3897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "176 \t tensor(27.1779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "177 \t tensor(26.7629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "178 \t tensor(27.0838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "179 \t tensor(24.4934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "180 \t tensor(27.8998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "181 \t tensor(25.6303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "182 \t tensor(25.1724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "183 \t tensor(23.8061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "184 \t tensor(23.0291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "185 \t tensor(25.4989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "186 \t tensor(19.6507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "187 \t tensor(21.4312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "188 \t tensor(22.9914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "189 \t tensor(20.2001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "190 \t tensor(19.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "191 \t tensor(21.3618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "192 \t tensor(17.9221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "193 \t tensor(19.5727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "194 \t tensor(22.3587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "195 \t tensor(21.0401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "196 \t tensor(21.4796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "197 \t tensor(19.2621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "198 \t tensor(20.2676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "199 \t tensor(19.2676, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CseZX1-9vKlP",
        "outputId": "db1b5c7a-4a98-4d32-c418-8e1e42a4808e"
      },
      "source": [
        "dataset = PointDataset()\n",
        "PointDataset.displayCanvas('donut.png',dataset, model = model)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n",
            "sample torch.Size([32, 32])\n",
            "hello torch.Size([1, 32, 32])\n",
            "hello\n",
            "pred torch.Size([1, 2])\n",
            "type <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAADnCAYAAAB1wm/GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAKUElEQVR4nO3dXVLCSrcG4JVTZzgwFQZErnFATEXmk+8islE3wtKddJru56miIuWFLNO8/RfCME1TAPDc/239AgBehcAESBKYAEkCEyBJYAIk/f+T32+9hT4U+SPDMG18tUCJOns4lz3UGNFHnVXWaIQZET1cWjUMpd7L0C6B2QmdAvx3ApNm9NApROgYtiQwezeOEfv9fOQl9NAx1NopPNv0oWXjGPH2Nv98uczH02m71wMfau0UjDB7dj4/fg588ffANJV7fYfD4+e8Bu/FYv42JTeVa8P1nJ3Pc1g6h6/He7Go4clawf1f7ve3kxMRsdtFvL8v+sI+lL0QeBy3Co9uLwRe2Ncay5/P8heul3svftZte/3bCPNw+HqSWpjK6anb0sv5bPG9WLG/jTAjSvXe5XrsbXrqq2577IX1MPKK6GMkXWV7/fumz+k0N8BWem0bIG3p6Xy29l78rLINLddhXtkAaYvz+foqXFb5+5S8DHd/WY4a16e9LqfKZTIXrgN1qnBZxZQcqFOFyyqm5LMe6lTj+rTX5VRZoyk5QJLABEgSmABJAhMgSWACJAlMgCSBCZAkMAGSBCZAksAESBKYAEkCEyBJYAIkPbtbEQAfjDABkgQmQJLABEgSmABJAhMgSWACJD371sitrznypVLLUeP6tNflVFmjESZAksAESBKYAEkCEyDpYWAOww9ru+MYsd/Px5a0WhewiIe75HdvzDGOEW9v88+Xy3w8nZZ+XUUNwxDT8dhcXcCyfj8lP58fP39B0zQ1WddnP84WWmSmwEp+H5iHw+Pnr6rVuj70cBu/YRhuM6DLZT62HJo6hvKmaXr0uO94nKbdbj6u69nrW+pRuq7vytV4Vb7WMjXudtMUcXvsdoXKm6YV6rn7iIj5vH2us2ybLd9ey7v/v//pF1PFL3qFx9bK1rjNm61Mje0HyVxn4x3DPJbb1N3X5bKiHrW8Xns6RRyPEbvdfGx14663JaRKlh+efZacFh0OtysBrs9bcjq1G5RX1/rO5/n8tVxvRVfmPPtOn613CtzMYDlfaxzH0m+2bm/YsIIe6rzVuN9/7eB3u4j397X//t0ajTB71cMojDZUNCMSmEDdKlp+MCWf9VCnGtenvS6nyhrtkgMkCUyAJIEJkCQwAZIEJkCSwARIEpgASQITIElgAiQJTIAkgQmQJDABkgQmQJLABEh6dns3AD4YYQIkCUyAJIEJkCQwAZIEJkDSs2+N3HoL3ZdKLUeN69Nel1NljUaYAEkCEyBJYAIkCUyAJIEJkCQwAZL+HpjjGLHfz0eADjy7DvO+cYx4e5t/vlzm4+m00EsCqNPfRpjn8+PnwHbM/lbzt8A8HB4/f2UaG6/sOvu7XOajdryohzcQHoZh+vH34ziPLA+HNafjZT9q9nmpISLieCy11NDtR80W1kONEY/q3O9vy2QREbtdxPv70n+/23P5cIT58G7sp9N8IhpYuxyGj/9NL0sNvY2ie6q35dlfBf626dOYfzqGw+Fr79xQYxuGYa6ztw273uq91rb+7K9Lz77Tp8ph8QpudZZZaviu3BSnzJTtntVrvLuEVLbe7afkZZiS86GhpYa7Gp6y3e38G6z3nyUkijMl701vU7YG6+3hm17/WUKK2GrWd/91mZJHRB91qnF92utyqrxyxZQcqFdlV64ITKBela1BW8ME6lXZGrQ1zFkPdapxfdrrcqqs0ZQcIElgAiQJTIAkgQmQJDABkgQmQJLABEgSmABJAhMg6dknfQD4YIQJkCQwAZIEJkCSwARIEpgASc9uILz1Frr7Cy5HjevTXpdTZY1GmABJAhMgSWACJAlMgCSBCZAkMAGSBCZAksAESBKYAEkCEyBJYAIkCUyAJIEJkCQwAZJ+H5jjGLHfz0eAjvwuMMcx4u0t4nKZjy2Hpo6BV6Tdrmuaph8f868/2e2mKeL22O2mlT18fQs+vjoev9Z5PK5X4WybGne7ErVdla+xvG3a61W5dtvtuXw4wpymbzc9PhweP39Rw/Dt5srn8+Pnr66nmUJEP6Ou1tvtTwqe32dfUfHV6TQfz+c5LK/PX9zdjuFy+fr8xQ3DcKvz3hurkXP5L9fOIeJ2TluttcF2+1Tp8/vT0HOqeFi8wuPfyk5Zy9ZYfslhWqGefz3i+xLSNJVeRtquvV6Vabfb1vjZeuf37uv63QizJ6dTuyORXmYKEU2Our7MFr5rud3eU/j8Dj/+42dVfnPbCnqos98ax7FU56C9LvUHhmF6kk0365zfuzUKzFkPdapxfdrrcqqs0Sd9AJIEJkCSwARIEpgASQITIElgAiQJTICkZ9dhAvDBCBMgSWACJAlMgCSBCZAkMAGSnt0Pc+stdHd/WY4a16e9LqfKGo0wAZIEJkCSwARIEpgASQITIElgAiQJTIAkgQmQJDABkgQmQJLABEgSmPDqxjFiv5+PrOrZzTeAmo1jxNvb/PPlMh9Pp+1eT+OMMO/RY/MqzufHz3tR6D1rhPmdHptXcjjc2un1eW8KvmeffWtklfekW8Gtzv3+awPc7SLe39f++93eX3BhPdQY8b3OcZxHlodDqc69rnO5znvW/TBTvvfQPfbYLWp5meV0mgOi15lQwfesKfl310ZXtsdmTZZZ2lbwPWtKPuuhzn6nceWWWbTX5VRZ4++n5C1PbXpxHXFdLvOx9XNpmYWF/G6E+XlqExFxPK49OtFjL6fvja0yI2rtdTlV1vi7EaZrvtrQ44ir940RFvG7TR/XfLXBxhb8ycMp+TAM079+X3azwBRnOWpcn/a6nCprtEseP3QMZXXbABfWQ40RfdRZZY0uXI+IjcOyiGEo9V6GdgnMTugU4L8TmDSjh04hQsewJYEJL6aHjqHWTkFgAtWptVMQmABJzy4rAuCDESZAksAESBKYAEkCEyBJYAIkPbu929Zb6G5msJwuahyGYctr+LTX5VRZoxEmTenlMrlaPwnTOoEJL6iHjqHGTkFgAlWqsVMQmABJAhMgSWACr2Ec56+IHsfNXsLvvjUSqFPZLycsbxwj3t7mn6/fXLtBnUaY3FTQg/MH1zC5XOZji+fvfH78vBCByayHN12rKgmTVR0Oj58XIjCZ9fCma1UlYbKq0ynieIzY7ebjRssO1jCZHQ63taHrc17DNTxaXsOMmOvauLZnd1zf+spRn81dzvMa1904qKPGq3Vq1V6XU2WNAnPWQ51qvPq84xqx5BRPe11OlTVaw6Q/1mv5I4FJf3rYJGEVNn3oTy+bJCzOGubs93Uuu2nQ7ZrQwnqoMaKPOquscbkRZusfzfqsko9pAWUtM8Lsbddxv/96zeJuF/H+/l/+frc99sJ6qDGijzqrrHGZTZ/edh1tGkCXlpmS9/YpEZsG0KXlNn18cuK/6HaKs7Aeaozoo84qa7RLPuuhTjWuT3tdTpU1unAdIElgAiQJTIAkgQmQJDABkh4G5jCU2vQDqN/DwHxyyVEzdAxAxrPrMAH4YA0TIElgAiQJTIAkgQmQJDABkgQmQNL/APHzsxn+3cxTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n8xKdlYwjQd",
        "outputId": "d0b0f526-35bf-40a2-9b04-6ec21e8cbcd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a= torch.zeros(64,3)\n",
        "b = torch.zeros(64,4)\n",
        "c = torch.cat([a,b], dim = 1)\n",
        "print(c.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S8PURbSRrPD"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}