{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimplestToyProblem.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMjWP8d9Ka+X6HqWq7jaFO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/SimplestToyProblem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "lriVEWYxBqQJ",
        "outputId": "d60d6c9e-5411-4c3f-95e2-03e0badb623d"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from skimage import filters\n",
        "import math\n",
        "\n",
        "global numpoints\n",
        "numpoints = 1\n",
        "side = 32\n",
        "\n",
        "rows = torch.zeros(32,32)\n",
        "columns = torch.zeros(32,32)\n",
        "\n",
        "\n",
        "for i in range(32):\n",
        "    columns[:,i] = i\n",
        "    rows[i,:] = i\n",
        "\n",
        "\n",
        "def point_matrix():\n",
        "    length = side**2\n",
        "    canvas = torch.zeros((length,side, side))\n",
        "    \n",
        "\n",
        "    x = torch.zeros(length,numpoints) \n",
        "    y = torch.zeros(length,numpoints)\n",
        "    assert x.shape == (length,numpoints)\n",
        "    assert y.shape == (length,numpoints)\n",
        "    \n",
        "    points = torch.zeros(length,2)\n",
        "    for j in range(side):\n",
        "      for i in range(side):\n",
        "        l = i*32+j\n",
        "        canvas[l,i,j] = 1.0\n",
        "        x[l] = i\n",
        "        y[l] = j\n",
        "\n",
        "        #points[l,:,0] = x[l,:]\n",
        "        #points[l,:,1] = y[l,:]\n",
        "        points[l,0] = i#modified for lstm discriminator\n",
        "        points[l,1] = j#modified for lstm discriminator \n",
        "    \n",
        "    \n",
        "    return {\n",
        "        'canvas': canvas, \n",
        "        'points':points.type(torch.FloatTensor)}\n",
        "\n",
        "\n",
        "def plot_all( sample = None, model = None, labels = None):\n",
        "    img = sample[:,:].squeeze().cpu().numpy()\n",
        "    #img = np.zeros((32,32))\n",
        "    #img[1,1] = 1\n",
        "    #img[31,1] = 1\n",
        "    #img[31,31] = 1\n",
        "    img = img.T\n",
        "    plt.imshow(img, cmap=plt.cm.gray_r)\n",
        "    if model != None:\n",
        "        with torch.no_grad():\n",
        "            global numpoints\n",
        "\n",
        "            print(\"sample\", sample.shape)\n",
        "            sample = sample.cuda()\n",
        "            sample = sample.unsqueeze(0)\n",
        "            print('hello',sample.shape)\n",
        "            pred = model(sample)\n",
        "            print('hello')\n",
        "            \n",
        "            print('pred', pred.shape)\n",
        "            predres = 1\n",
        "            X = pred[:,0]\n",
        "            Y = pred[:,1]\n",
        "            \n",
        "            s = [10 for x in range(predres)]\n",
        "            \n",
        "            assert len(s) == predres\n",
        "            c = ['red' for x in range(predres)]\n",
        "            assert len(c) == predres\n",
        "            Y = Y.cuda()\n",
        "            X = X.cuda()\n",
        "            print(\"type\",type(X))\n",
        "            ascatter = plt.scatter(X.cpu().numpy(),Y.cpu().numpy(),s = s,c = c)\n",
        "            plt.gca().add_artist(ascatter)\n",
        "    else:\n",
        "        #print(labels.shape)\n",
        "\n",
        "        X = labels[0]\n",
        "        Y = labels[1]\n",
        "        #print(X.shape)\n",
        "        #print(Y.shape)\n",
        "        print(X,Y)\n",
        "        s = [.1 for x in range(numpoints)]\n",
        "        #print(len(s))\n",
        "        c = ['red' for x in range(numpoints)]\n",
        "        #print(len(c))\n",
        "        ascatter = plt.scatter(X,Y,s = s,c = c)\n",
        "        plt.gca().add_artist(ascatter)\n",
        "\n",
        "class PointDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Donut dataset.\"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.length = side**2\n",
        "        self.values = point_matrix()\n",
        "        assert self.values['canvas'].shape[0] == self.length\n",
        "        assert self.values['points'].shape[0] == self.length\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        canvas = self.values[\"canvas\"]\n",
        "        \n",
        "        canvas = canvas[idx,:,:]\n",
        "        assert canvas.shape == (side,side)\n",
        "        points = self.values[\"points\"]\n",
        "        points = points[idx,:]\n",
        "        return canvas, points\n",
        "    \n",
        "    @staticmethod\n",
        "    def displayCanvas(title,dataset, model):\n",
        "        #model.setBatchSize(batch_size = 1)\n",
        "        for i in range(36):\n",
        "            sample, labels = dataset[i]\n",
        "            plt.subplot(6,6,i+1)\n",
        "            plot_all(sample = sample,model=model, labels = labels)\n",
        "            plt.axis('off')\n",
        "        plt.savefig(title,dpi=600)\n",
        "\n",
        "dataset = PointDataset()\n",
        "PointDataset.displayCanvas('donut.png',dataset, model = None)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.) tensor(0.)\n",
            "tensor(0.) tensor(1.)\n",
            "tensor(0.) tensor(2.)\n",
            "tensor(0.) tensor(3.)\n",
            "tensor(0.) tensor(4.)\n",
            "tensor(0.) tensor(5.)\n",
            "tensor(0.) tensor(6.)\n",
            "tensor(0.) tensor(7.)\n",
            "tensor(0.) tensor(8.)\n",
            "tensor(0.) tensor(9.)\n",
            "tensor(0.) tensor(10.)\n",
            "tensor(0.) tensor(11.)\n",
            "tensor(0.) tensor(12.)\n",
            "tensor(0.) tensor(13.)\n",
            "tensor(0.) tensor(14.)\n",
            "tensor(0.) tensor(15.)\n",
            "tensor(0.) tensor(16.)\n",
            "tensor(0.) tensor(17.)\n",
            "tensor(0.) tensor(18.)\n",
            "tensor(0.) tensor(19.)\n",
            "tensor(0.) tensor(20.)\n",
            "tensor(0.) tensor(21.)\n",
            "tensor(0.) tensor(22.)\n",
            "tensor(0.) tensor(23.)\n",
            "tensor(0.) tensor(24.)\n",
            "tensor(0.) tensor(25.)\n",
            "tensor(0.) tensor(26.)\n",
            "tensor(0.) tensor(27.)\n",
            "tensor(0.) tensor(28.)\n",
            "tensor(0.) tensor(29.)\n",
            "tensor(0.) tensor(30.)\n",
            "tensor(0.) tensor(31.)\n",
            "tensor(1.) tensor(0.)\n",
            "tensor(1.) tensor(1.)\n",
            "tensor(1.) tensor(2.)\n",
            "tensor(1.) tensor(3.)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAADnCAYAAAB1wm/GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAG5UlEQVR4nO3dTY7jyBWF0RdGrkLqHZi9Dq1Z6xC9g9pHeKAaGIZBXhj8q+A5QCMHGhQfkv1FkExJrfdeAKz7x9kHAPCnEEyAkGAChAQTICSYAKGfldd7zXPVNB1yMP9DO+Qfaa2f/NcCR8x59p9DmHE7d5jzkjMu7zDnuer1+v4cWP98zj6E3bV21P/LMK7lYE5T1ft95g7zGBaFIVgU2Nv6PczRY1llURhE7334GassDGfy0Kdq/FhW3WNRcAtpGFddFNrKw45L3njdwR3mvMeMN3hIWc9nP3kBvO3v0g6TsYy+i65ytXAiO8yvO8xpxv05X7dzyR2mYH7dYU4z7s/5up1LzuiSHCAkmAAhwQQICSZASDABQoIJEBJMgJBgAoQEEyAkmAAhwQQICSZASDABQoIJEBJMgJBgAoQEEyAkmAAhwQQICSZASDABQoIJEFr7ml0AfrPDBAgJJkBIMAFCggkQEkyAkGAChH5WXj/7b47aQf/OHeY04/6cr9u55Ix2mAAhwQQICSZASDABQovBbK1VzfNRxwJwaYvB7J9P1es1fDSndtTDTeBPtnxJPk1V7/f358Dmx8OiAKxav4c5eCyryqIwCLeQ2JuHPlXDx7KqbrEouIXE3tY+QPiSf22/gzvMeY8Z5/nMheGY8/X57CcvgLvP2Vrr/fO53Ix2mIxl8F10VblaOJEd5tcd5jTj/pyv27nk1YJgft1hTjPuz/m6nUvO6JIcICSYACHBBAgJJkBIMAFCggkQEkyAkGAChAQTICSYACHBBAgJJkBIMAFCggkQEkyAkGAChAQTILT2iesA/GaHCRASTICQYAKEBBMgJJgAoZ+V189+hO57nrdjxv05X7dzyRntMAFCggkQEkyAkGAChAQTICSYACHBBAgJJkBIMAFCggkQWgxma61qno86FoBLWwxm/3yqXq/hozm1o94CDPzJli/Jp6nq/f7+HNj8eFgUgFXr9zAHj2VVWRQG4RYSe/PQp2r4WFbVLRYFt5DY29q3Rl7yM+l2cIc57zHjPJ+5MBxzvj6f/eQFcPc5W2u9fz6Xm9EOk7EMvouuKlcLJ7LD/LrDnGbcn/N1O5e8WhDMrzvMacb9OV+3c8kZXZIDhAQTICSYACHBBAgJJkBIMAFCggkQEkyAkGAChAQTICSYAKG195ID8JsdJkBIMAFCggkQEkyAkGAChH5WXj/7EbpPsN6OGffnfN3OJWe0wwQICSZASDABQoIJEBJMgJBgAoQEEyAkmAAhwQQICSZASDABQoIJEBJMgJBgAoQEEyAkmAChxWC21qrm+ahjAbi0xWD2z6fq9Ro+mlM76oOygT/Z8iX5NFW939+fA5sfD4sCsGr9Hubgsawqi8Ig3EJibx76VA0fy6q6xaLgFhJ7a70vfjnbJb+5bQd3mPMeM87zmQvDMefr89lPXgB3n7O11vvnc7kZ7TAZy+C76KpytXAiO8yvO8xpxv05X7dzyasFwfy6w5xm3J/zdTuXnNElOUBIMAFCggkQEkyAkGAChNaekgPwmx0mQEgwAUKCCRASTICQYAKEflZeP/sRuvfmbseM+3O+bueSM9phAoQEEyAkmAAhwQQICSZASDABQoIJEBJMgJBgAoQEEyAkmAAhwQQICSZASDABQoIJEBJMgJBgAoQEEyAkmAAhwQQICSZASDABQuvBnOcDDgPg+haDObVW9XqNH83R5wM2sRjMufeq97tqmo46nlP8+vvv8aM5+nxwgPVL8sFjWVX11+cz/Jy3WBSq7jEjp/HQp2r4WFbdY1FwC4m9td770uuLLx6gHfTv3GHOe8w4z2cuDIecr79a6ycvgLf9XQrm1x3mNOP+jjlf57mffLWw+5xTa31+PM58hiKYC+4wpxn353zdjh3m/8EJuB0z7s/5up1LzrgWTAB+85QcICSYACHBBAgJJkBIMAFCa8HsJ/93lPHnnOdez2eveR53xqreWht9xjpgjivMeckZ7TDvYppu8clT/fO5xfvJp3bUn3zynwTzTgaPZVXdY2GY55ofj+EXhdba5Wb0Tp+vO8xpxv0dd75e8G2DG/vO+HqdtQB6a+SCO8xpxv05X7fznfG8hUEwF9xhTjPuz/m6nUvO6B4mQEgwAUKCCRASTICQYAKEBBMgJJgAIcEECAkmQEgwAUKCCRASTICQYAKEBBMgJJgAIcEECAkmQEgwAUKCCRASTICQYAKEBBMgtB7MeT7gMACubzGYU2tVr9f40Rx9PmATrffF70vvNc9V03TU8fy3I74wvn611v/6fEafc/EXfQAzbucOc15yxrVg3kNr/6ze/3X2YQDXJpgAIU/JAUKCCRASTICQYAKEBBMg9G80L63prVnX4wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci_oKFKxBubp"
      },
      "source": [
        "d = dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaEIxbzWHl2V",
        "outputId": "3b4f6d23-5079-4a17-81de-dacc1b6f98f1"
      },
      "source": [
        "l=2\n",
        "c = d[l][0]\n",
        "print(d[l][1][0],d[l][1][1])\n",
        "i= (int)(d[l][1][0].item())\n",
        "j=(int)(d[l][1][1].item())\n",
        "print(i,j)\n",
        "\n",
        "print(c[i,j])\n",
        "print(d[l][1])\n",
        "print(c)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.) tensor(2.)\n",
            "0 2\n",
            "tensor(1.)\n",
            "tensor([0., 2.])\n",
            "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7eBMvDeM-7_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.input_dim = 1*32*32\n",
        "        self.hidden_dim = 2**11\n",
        "        self.midl=1\n",
        "        \n",
        "        self.inLayer = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, (int)(self.input_dim/2)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "         )\n",
        "        self.midLayers1 = nn.Sequential(\n",
        "            nn.Linear((int)(self.input_dim/2), (int)(self.input_dim/4)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        )        \n",
        "        self.midLayers2 = nn.Sequential(\n",
        "            nn.Linear((int)(self.input_dim/4), (int)(self.input_dim/8)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        )        \n",
        "        self.midLayers3 = nn.Sequential(\n",
        "            nn.Linear((int)(self.input_dim/8), (int)(self.input_dim/16)),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        )        \n",
        "        self.out_layer = nn.Sequential(\n",
        "           nn.Linear((int)(self.input_dim/16), 2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.squeeze()\n",
        "        x = torch.flatten(x,start_dim=1)\n",
        "        \n",
        "        #assert x.shape == (mini_batch,self.hidden_dim)\n",
        "        out = self.inLayer(x)\n",
        "        \n",
        "        #out = torch.cat([out,x],dim = 1)\n",
        "        out = self.midLayers1(out)\n",
        "        out = self.midLayers2(out)\n",
        "        out = self.midLayers3(out)\n",
        "        out = self.out_layer(out)\n",
        "        \n",
        "        return 32.0*out\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYKNN1XTuMO1"
      },
      "source": [
        "model = MLP().cuda()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QreZ-k6dtTx"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.00001, betas = (.9,.999))"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PfBoCUFuTkh",
        "outputId": "615dcfcc-6029-434b-f85b-362f4376ce13"
      },
      "source": [
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 128\n",
        "dataset = PointDataset()\n",
        "loader_train = data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=dataset),\n",
        "    num_workers=4)\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJz942ZhumMq",
        "outputId": "87d60097-b166-45b7-aa7e-0088f7b306b0"
      },
      "source": [
        "epoch = 200\n",
        "for e in range(epoch):\n",
        "  for xin,yin in loader_train:\n",
        "    if xin.shape[0] != mini_batch:\n",
        "      print(xin.shape)\n",
        "      continue\n",
        "    xin = xin.cuda()\n",
        "    yin = yin.cuda()\n",
        "    out = model(xin)\n",
        "    loss = torch.mean((out-yin)**2)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  print(e,'\\t', loss)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 \t tensor(17.3255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "1 \t tensor(17.9818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "2 \t tensor(15.2547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "3 \t tensor(17.5875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "4 \t tensor(17.2686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "5 \t tensor(15.3503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "6 \t tensor(15.3370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "7 \t tensor(18.4393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "8 \t tensor(17.1852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "9 \t tensor(17.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "10 \t tensor(17.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "11 \t tensor(14.9115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "12 \t tensor(16.7434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "13 \t tensor(17.4876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "14 \t tensor(15.9304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "15 \t tensor(15.6067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "16 \t tensor(17.1047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "17 \t tensor(13.7498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "18 \t tensor(17.6948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "19 \t tensor(15.0466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "20 \t tensor(16.7247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "21 \t tensor(18.2745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "22 \t tensor(14.0686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "23 \t tensor(16.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "24 \t tensor(15.7990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "25 \t tensor(16.1982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "26 \t tensor(17.1264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "27 \t tensor(16.5560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "28 \t tensor(16.0664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "29 \t tensor(13.2297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "30 \t tensor(14.4779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "31 \t tensor(15.3087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "32 \t tensor(15.2098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "33 \t tensor(14.7657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "34 \t tensor(12.2575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "35 \t tensor(14.0830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "36 \t tensor(13.1763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "37 \t tensor(13.2808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "38 \t tensor(13.6359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "39 \t tensor(12.6459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "40 \t tensor(12.9583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "41 \t tensor(16.1936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "42 \t tensor(18.8935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "43 \t tensor(13.4123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "44 \t tensor(15.1667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "45 \t tensor(11.4466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "46 \t tensor(15.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "47 \t tensor(11.5881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "48 \t tensor(14.2257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "49 \t tensor(12.9388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "50 \t tensor(16.3738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "51 \t tensor(15.5482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "52 \t tensor(14.9833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "53 \t tensor(16.9127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "54 \t tensor(12.3132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "55 \t tensor(12.4301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "56 \t tensor(16.0215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "57 \t tensor(15.1712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "58 \t tensor(13.7016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "59 \t tensor(10.7442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "60 \t tensor(13.9387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "61 \t tensor(12.1356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "62 \t tensor(13.1939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "63 \t tensor(13.3416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "64 \t tensor(13.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "65 \t tensor(14.0884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "66 \t tensor(13.9941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "67 \t tensor(10.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "68 \t tensor(14.6859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "69 \t tensor(12.0902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "70 \t tensor(13.9748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "71 \t tensor(12.7768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "72 \t tensor(14.3790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "73 \t tensor(12.5523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "74 \t tensor(14.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "75 \t tensor(11.6620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "76 \t tensor(14.9033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "77 \t tensor(11.8934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "78 \t tensor(11.8518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "79 \t tensor(13.3421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "80 \t tensor(14.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "81 \t tensor(12.5492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "82 \t tensor(12.9304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "83 \t tensor(12.8196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "84 \t tensor(13.7340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "85 \t tensor(14.2453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "86 \t tensor(14.3240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "87 \t tensor(12.4949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "88 \t tensor(12.3060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "89 \t tensor(12.2021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "90 \t tensor(12.8083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "91 \t tensor(10.5388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "92 \t tensor(11.3820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "93 \t tensor(11.6991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "94 \t tensor(14.2590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "95 \t tensor(12.1256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "96 \t tensor(12.1226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "97 \t tensor(13.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "98 \t tensor(12.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "99 \t tensor(11.0555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "100 \t tensor(13.0421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "101 \t tensor(11.4192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "102 \t tensor(11.3292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "103 \t tensor(11.9375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "104 \t tensor(11.3730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "105 \t tensor(13.5536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "106 \t tensor(10.8777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "107 \t tensor(11.6877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "108 \t tensor(12.4269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "109 \t tensor(12.7950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "110 \t tensor(9.9584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "111 \t tensor(13.2754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "112 \t tensor(12.3721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "113 \t tensor(11.5879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "114 \t tensor(12.3873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "115 \t tensor(12.5226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "116 \t tensor(10.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "117 \t tensor(12.9245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "118 \t tensor(11.1701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "119 \t tensor(12.7757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "120 \t tensor(11.5142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "121 \t tensor(11.9373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "122 \t tensor(12.1639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "123 \t tensor(12.4254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "124 \t tensor(13.4344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "125 \t tensor(12.5136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "126 \t tensor(12.4508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "127 \t tensor(12.6712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "128 \t tensor(11.3396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "129 \t tensor(9.4031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "130 \t tensor(11.6948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "131 \t tensor(13.3188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "132 \t tensor(12.2890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "133 \t tensor(10.5462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "134 \t tensor(11.9928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "135 \t tensor(12.2735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "136 \t tensor(13.2312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "137 \t tensor(10.7603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "138 \t tensor(10.2793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "139 \t tensor(12.9759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "140 \t tensor(11.8665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "141 \t tensor(11.2520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "142 \t tensor(12.7568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "143 \t tensor(10.8026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "144 \t tensor(12.2986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "145 \t tensor(11.7736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "146 \t tensor(12.0814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "147 \t tensor(12.4866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "148 \t tensor(12.3643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "149 \t tensor(10.3731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "150 \t tensor(11.2511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "151 \t tensor(12.5998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "152 \t tensor(13.1753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "153 \t tensor(13.0827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "154 \t tensor(13.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "155 \t tensor(12.5548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "156 \t tensor(13.6842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "157 \t tensor(13.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "158 \t tensor(11.6477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "159 \t tensor(13.3636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "160 \t tensor(11.8392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "161 \t tensor(11.9372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "162 \t tensor(11.3097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "163 \t tensor(12.5926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "164 \t tensor(11.9440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "165 \t tensor(13.8915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "166 \t tensor(12.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "167 \t tensor(11.8681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "168 \t tensor(12.9384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "169 \t tensor(14.1441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "170 \t tensor(12.1903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "171 \t tensor(12.8389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "172 \t tensor(12.0725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "173 \t tensor(12.3598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "174 \t tensor(12.0650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "175 \t tensor(12.0534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "176 \t tensor(11.4256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "177 \t tensor(12.6349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "178 \t tensor(10.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "179 \t tensor(12.8834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "180 \t tensor(12.3181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "181 \t tensor(12.7439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "182 \t tensor(11.5789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "183 \t tensor(12.1176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "184 \t tensor(10.1437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "185 \t tensor(12.1116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "186 \t tensor(12.9692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "187 \t tensor(10.7655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "188 \t tensor(12.3644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "189 \t tensor(12.9029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "190 \t tensor(12.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "191 \t tensor(9.7713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "192 \t tensor(12.2347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "193 \t tensor(12.0419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "194 \t tensor(11.4740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "195 \t tensor(13.3508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "196 \t tensor(11.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "197 \t tensor(10.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "198 \t tensor(10.3653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "199 \t tensor(11.5293, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CseZX1-9vKlP"
      },
      "source": [
        "dataset = PointDataset()\n",
        "PointDataset.displayCanvas('donut.png',dataset, model = model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n8xKdlYwjQd"
      },
      "source": [
        "a= torch.zeros(64,3)\n",
        "b = torch.zeros(64,4)\n",
        "c = torch.cat([a,b], dim = 1)\n",
        "print(c.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S8PURbSRrPD"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}