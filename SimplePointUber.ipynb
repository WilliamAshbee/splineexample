{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimplePointUber.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPypqYevnJK5obhzSPejkLY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/splineexample/blob/main/SimplePointUber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfhsB4OgAbMm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pQrbKbMAlYc"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    self.input_dim = 3*1024\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(self.input_dim, self.input_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(self.input_dim, self.input_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(self.input_dim, 2),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "        #x = x.squeeze()\n",
        "        x = torch.flatten(x,start_dim=1)\n",
        "        assert x.shape[1]==1024*3\n",
        "                \n",
        "        out = self.layers(x)\n",
        "        \n",
        "        return 32.0*out\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX4-xS45Dn9g"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktaFm6z9E2zX"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eaGdQC1E_TM"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from skimage import filters\n",
        "import math\n",
        "side = 32\n",
        "a = torch.zeros(1024,32,32,3)\n",
        "b = torch.zeros(1024,2)\n",
        "for i in range(32):\n",
        "  for j in range(32):\n",
        "    a[:,i,j,0] = i\n",
        "    a[:,i,j,1] = j\n",
        "\n",
        "for i in range(1024):\n",
        "  for j in range(32):\n",
        "    for k in range(32):\n",
        "      a[i,j,k,2] = 1\n",
        "      b[i,0]=j\n",
        "      b[i,1]=k      \n",
        "\n",
        "\n",
        "def point_matrix():\n",
        "    length = 32**2\n",
        "\n",
        "class PointDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.length = side**2\n",
        "        self.values = a\n",
        "        self.gt = b\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        return a[idx,:,:,:], b[idx,:]\n",
        "    \n",
        "    @staticmethod\n",
        "    def displayCanvas(title,dataset, model):\n",
        "        #model.setBatchSize(batch_size = 1)\n",
        "        for i in range(36):\n",
        "            sample, labels = dataset[i]\n",
        "            plt.subplot(6,6,i+1)\n",
        "            plot_all(sample = sample,model=model, labels = labels)\n",
        "            plt.axis('off')\n",
        "        plt.savefig(title,dpi=600)\n",
        "\n",
        "dataset = PointDataset()\n",
        "#PointDataset.displayCanvas('donut.png',dataset, model = None)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fUZSVC7I3y1",
        "outputId": "93b11ae7-f2f5-4c81-ac28-31ed6018b37b"
      },
      "source": [
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "mini_batch = 64\n",
        "dataset = PointDataset()\n",
        "loader_train = data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=mini_batch,\n",
        "    sampler=RandomSampler(data_source=dataset),\n",
        "    num_workers=4)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS-YQZOVI4Vj",
        "outputId": "0b8bb7e3-5770-4dda-840c-5bb6b831d281"
      },
      "source": [
        "model = MLP().cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.000001, betas = (.9,.999))\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  for x,y in loader_train:\n",
        "    optimizer.zero_grad()\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    out = model(x)\n",
        "    loss = torch.mean((y-out)**2)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(loss)\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(473.5018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(525.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(386.0582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(401.6327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(296.8934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(322.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(352.5598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(279.3042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(304.2860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(242.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(259.5600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(234.8600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(205.2250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(153.8866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(194.7016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(182.2358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(132.9231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(96.5862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(115.5936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(127.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(92.1019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(75.4600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(92.2550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(74.7930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(73.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(55.1143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(39.6070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(61.9162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(20.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(17.8465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(42.2815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(26.4423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(30.7221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(20.1075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(20.3023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(28.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(18.6073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(22.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(24.2753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(6.2830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(20.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.8522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(15.9377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.6271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(12.4368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(12.8468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(6.4472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.5784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.5518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.7880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(15.2863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.4142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.9078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(15.6761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.0097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.9905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(8.8824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(18.2673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(8.4336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(6.6519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.7087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.4227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(13.1554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(11.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.8512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.5267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.1179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.9720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.7048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(11.3704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.0634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.2218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.3439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.9484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.6763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.7281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.3339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.9113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.1364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.7476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.6760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.0485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(16.1147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.3115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.4930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.8767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.1468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.5961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.9689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.0702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.3275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.7605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.7597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.1173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.1191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.7897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.9842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.9697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.6434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(0.9159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.2256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.5704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.3022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.5823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.9747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.4163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(10.3451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.0080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.6375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.2258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.8728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.1549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.3341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.1796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.3841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.9462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.0520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.3838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.3893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.5490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.8957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.5925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.3766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(6.4091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.8324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.2706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.3034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.8550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.4968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(3.0692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(0.9892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.4922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.3187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.0324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.8280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.7848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.7892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.4642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(2.0521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.4945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(1.4050, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ieimw4eQPvKk",
        "outputId": "9164e217-6112-4ce5-a7b6-af7d31e8b3ed"
      },
      "source": [
        "model.layers[6].bias\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 0.0177, -0.0090], device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYC6diKDI53G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTeTf_SFuOJy"
      },
      "source": [
        "This experiment (some results unseen) demonstrated that the uber paper helped in this instance. also that maximum accuracy was 1 pixel in some systematic error way. i checked the bias terms and saw nothing concerning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAHWKgCYufbU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}